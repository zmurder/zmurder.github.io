<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8693861384618000"
     crossorigin="anonymous"></script>
  <meta name="msvalidate.01" content="7EC20DBC74B004C2782077570E15C280">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.14.2","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8693861384618000"
     crossorigin="anonymous"></script>
    <meta name="description" content="4.3 内存访问模式并且多数GPU应用程序容易受内存带宽的限制。因此，最大限度地利用全局内存带宽是调控核函数性能的基本">
<meta property="og:type" content="article">
<meta property="og:title" content="4-3 内存访问模式">
<meta property="og:url" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/index.html">
<meta property="og:site_name" content="奔跑的IC">
<meta property="og:description" content="4.3 内存访问模式并且多数GPU应用程序容易受内存带宽的限制。因此，最大限度地利用全局内存带宽是调控核函数性能的基本">
<meta property="og:locale">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/1-1.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-6.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-8.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-9.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-10.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-11.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-12.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-13.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-14.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-15.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-16.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-17.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-18.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/image-20230421175908809.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-19.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-20.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-21.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-22.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/image-20230423155322864.png">
<meta property="og:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/image-20230423155907675.png">
<meta property="article:published_time" content="2024-12-01T10:13:43.671Z">
<meta property="article:modified_time" content="2024-12-01T10:13:43.687Z">
<meta property="article:author" content="奔跑的IC">
<meta property="article:tag" content="C">
<meta property="article:tag" content="GPU">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/1-1.png">


<link rel="canonical" href="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-Hans","comments":true,"permalink":"http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/","path":"CUDA/CUDA C编程权威指南笔记/4-3 内存访问模式/","title":"4-3 内存访问模式"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>4-3 内存访问模式 | 奔跑的IC</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">奔跑的IC</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-reorder fa-fw"></i>文章列表</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#4-3-%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F"><span class="nav-text">4.3 内存访问模式</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-1-%E5%AF%B9%E9%BD%90%E4%B8%8E%E5%90%88%E5%B9%B6%E8%AE%BF%E9%97%AE"><span class="nav-text">4.3.1 对齐与合并访问</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-2-%E5%85%A8%E5%B1%80%E5%86%85%E5%AD%98%E8%AF%BB%E5%8F%96"><span class="nav-text">4.3.2 全局内存读取</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-2-1-%E7%BC%93%E5%AD%98%E5%8A%A0%E8%BD%BD"><span class="nav-text">4.3.2.1 缓存加载</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-2-2-%E6%B2%A1%E6%9C%89%E7%BC%93%E5%AD%98%E7%9A%84%E5%8A%A0%E8%BD%BD"><span class="nav-text">4.3.2.2 没有缓存的加载</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-2-3-%E9%9D%9E%E5%AF%B9%E9%BD%90%E8%AF%BB%E5%8F%96%E7%9A%84%E7%A4%BA%E4%BE%8B"><span class="nav-text">4.3.2.3 非对齐读取的示例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-2-4-%E5%8F%AA%E8%AF%BB%E7%BC%93%E5%AD%98"><span class="nav-text">4.3.2.4 只读缓存</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-3-%E5%85%A8%E5%B1%80%E5%86%85%E5%AD%98%E5%86%99%E5%85%A5"><span class="nav-text">4.3.3 全局内存写入</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-3-1-%E9%9D%9E%E5%AF%B9%E9%BD%90%E5%86%99%E5%85%A5%E7%9A%84%E7%A4%BA%E4%BE%8B"><span class="nav-text">4.3.3.1 非对齐写入的示例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-4-%E7%BB%93%E6%9E%84%E4%BD%93%E6%95%B0%E7%BB%84%E4%B8%8E%E6%95%B0%E7%BB%84%E7%BB%93%E6%9E%84%E4%BD%93"><span class="nav-text">4.3.4 结构体数组与数组结构体</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-4-1-%E7%A4%BA%E4%BE%8B%EF%BC%9A%E4%BD%BF%E7%94%A8AoS%E6%95%B0%E6%8D%AE%E5%B8%83%E5%B1%80%E7%9A%84%E7%AE%80%E5%8D%95%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97"><span class="nav-text">4.3.4.1 示例：使用AoS数据布局的简单数学运算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-4-2-%E7%A4%BA%E4%BE%8B%EF%BC%9A%E4%BD%BF%E7%94%A8SoA%E6%95%B0%E6%8D%AE%E5%B8%83%E5%B1%80%E7%9A%84%E7%AE%80%E5%8D%95%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97"><span class="nav-text">4.3.4.2 示例：使用SoA数据布局的简单数学运算</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-5-%E6%80%A7%E8%83%BD%E8%B0%83%E6%95%B4"><span class="nav-text">4.3.5 性能调整</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-5-1-%E5%B1%95%E5%BC%80%E6%8A%80%E6%9C%AF"><span class="nav-text">4.3.5.1 展开技术</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-5-2-%E5%A2%9E%E5%A4%A7%E5%B9%B6%E8%A1%8C%E6%80%A7"><span class="nav-text">4.3.5.2 增大并行性</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%99%84%E5%BD%95"><span class="nav-text">附录</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="奔跑的IC"
      src="/images/zyd.gif">
  <p class="site-author-name" itemprop="name">奔跑的IC</p>
  <div class="site-description" itemprop="description">死磕牛角的IT农民工</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">169</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zyd.gif">
      <meta itemprop="name" content="奔跑的IC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="奔跑的IC">
      <meta itemprop="description" content="死磕牛角的IT农民工">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="4-3 内存访问模式 | 奔跑的IC">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          4-3 内存访问模式
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-01 18:13:43" itemprop="dateCreated datePublished" datetime="2024-12-01T18:13:43+08:00">2024-12-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/CUDA/" itemprop="url" rel="index"><span itemprop="name">CUDA</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/CUDA/CUDA-C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">CUDA C编程权威指南笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="4-3-内存访问模式"><a href="#4-3-内存访问模式" class="headerlink" title="4.3 内存访问模式"></a>4.3 内存访问模式</h1><p>并且多数GPU应用程序容易受内存带宽的限制。因此，最大限度地利用全局内存带宽是调控核函数性能的基本</p>
<h2 id="4-3-1-对齐与合并访问"><a href="#4-3-1-对齐与合并访问" class="headerlink" title="4.3.1 对齐与合并访问"></a>4.3.1 对齐与合并访问</h2><p>如图4-6所示，<strong>全局内存通过缓存来实现加载/存储</strong>。全局内存是一个逻辑内存空间，你可以通过核函数访问它。所有的应用程序数据最初存在于DRAM上，即物理设备内存中。<strong>核函数的内存请求通常是在DRAM设备和片上内存间以128字节或32字节内存事务来实现的</strong>。</p>
<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/1-1.png" class="" title="1-1">
<p>所有对全局内存的访问都会通过二级缓存，也有许多访问会通过一级缓存，这取决于访问类型和GPU架构。如果这两级缓存都被用到，那么内存访问是由一个128字节的内存事务实现的。如果只使用了二级缓存，那么这个内存访问是由一个32字节的内存事务实现的。对全局内存缓存其架构，如果允许使用一级缓存，那么可以在编译时选择启用或禁用一级缓存。</p>
<p>因此在优化应用程序时，你需要注意设备内存访问的两个特性：</p>
<ul>
<li><strong>对齐内存访问</strong>：当设备内存事务的第一个地址是用于事务服务的缓存粒度的偶数倍时（32字节的二级缓存或128字节的一级缓存），就会出现<strong>对齐内存访问</strong>。运行非对齐的加载会造成带宽浪费。</li>
<li><strong>合并内存访问</strong>：当一个线程束中全部的32个线程访问一个连续的内存块时，就会出现合并内存访问。</li>
</ul>
<p>需要注意的一点是官方<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses">5.3.2. Device Memory Accesses</a>中的一段话</p>
<p><code>Any address of a variable residing in global memory or returned by  one of the memory allocation routines from the driver or runtime API is  always aligned to at least 256 bytes.</code></p>
<p><strong>我就是我们使用cuda 的API申请的内存都是256字节对齐的，也就是满足对齐内存访问的。</strong></p>
<p>下面是两个图示的例子：</p>
<p>图4-7描述了<strong>对齐与合并</strong>内存的加载操作。在这种情况下，只需要一个128字节的内存事务从设备内存中读取数据。</p>
<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-6.png" class="" title="4-6">
<p>图4-8展示了<strong>非对齐和未合并</strong>的内存访问。在这种情况下，可能需要3个128字节的内存事务来从设备内存中读取数据：一个在偏移量为0的地方开始，读取连续地址之后的数据；一个在偏移量为256的地方开始，读取连续地址之前的数据；另一个在偏移量为128的地方开始读取大量的数据。</p>
<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-8.png" class="" title="4-8">
<h2 id="4-3-2-全局内存读取"><a href="#4-3-2-全局内存读取" class="headerlink" title="4.3.2 全局内存读取"></a>4.3.2 全局内存读取</h2><p>注意我们说的都是读取，也就是加载过程，写或者叫做存储是另外一回事！<br>SM加载数据，根据不同的设备和类型分为三种路径：</p>
<ol>
<li>一级和二级缓存</li>
<li>常量缓存</li>
<li>只读缓存</li>
</ol>
<p>常规的路径是一级和二级缓存，需要使用常量和只读缓存的需要在代码中显式声明。但是提高性能，主要还是要取决于访问模式。<br>控制全局加载操作是否通过一级缓存可以通过编译选项来控制，当然比较老的设备可能就没有一级缓存。<br>编译器禁用一级缓存的选项是：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Xptxas -dlcm=cg</span><br></pre></td></tr></table></figure>
<p>编译器启用一级缓存的选项是：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Xptxas -dlcm=ca</span><br></pre></td></tr></table></figure>
<p>当一级缓存被禁用的时候，对全局内存的加载请求直接进入二级缓存，如果二级缓存缺失，则由DRAM完成请求。<br>每次内存事务可由一个两个或者四个部分执行，每个部分有32个字节，也就是32，64或者128字节一次（注意前面我们讲到是否使用一级缓存决定了读取粒度是128还是32字节，这里增加的64并不在此情况，所以需要注意）。<br>启用一级缓存后，当SM有全局加载请求会首先通过尝试一级缓存，如果一级缓存缺失，则尝试二级缓存，如果二级缓存也没有，那么直接DRAM。<br>在有些设备上一级缓存不用来缓存全局内存访问，而是只用来存储寄存器溢出的本地数据，比如Kepler 的K10,K20。<br>内存加载可以分为两类：</p>
<ul>
<li>缓存加载</li>
<li>没有缓存的加载</li>
</ul>
<p>内存访问有以下特点：</p>
<ul>
<li>是否使用缓存：一级缓存是否介入加载过程</li>
<li>对齐与非对齐的：如果访问的第一个地址是32的倍数</li>
<li>合并与非合并，访问连续数据块则是合并的</li>
</ul>
<h3 id="4-3-2-1-缓存加载"><a href="#4-3-2-1-缓存加载" class="headerlink" title="4.3.2.1 缓存加载"></a>4.3.2.1 缓存加载</h3><p>下面是使用一级缓存的加载过程，图片表达很清楚，我们只用少量文字进行说明：</p>
<ol>
<li>对齐合并的访问，利用率100%<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-9.png" class="" title="4-9"></li>
<li>对齐的，但是不是连续的，每个线程访问的数据都在一个块内，但是位置是交叉的，利用率100%<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-10.png" class="" title="4-10"></li>
<li>连续非对齐的，线程束请求一个连续的非对齐的，32个4字节数据，那么会出现，数据横跨两个块，但是没有对齐，当启用一级缓存的时候，就要两个128字节的事务来完成<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-11.png" class="" title="4-11"></li>
<li>线程束所有线程请求同一个地址，那么肯定落在一个缓存行范围（缓存行的概念没提到过，就是主存上一个可以被一次读到缓存中的一段数据。），那么如果按照请求的是4字节数据来说，使用一级缓存的利用率是 4128=3.125%<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-12.png" class="" title="4-12"></li>
<li>比较坏的情况，前面提到过最坏的，就是每个线程束内的线程请求的都是不同的缓存行内，这里比较坏的情况就是，所有数据分布在 N 个缓存行上，其中 1≤N≤32，那么请求32个4字节的数据，就需要 N 个事务来完成，利用率也是 1N<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-13.png" class="" title="4-13">
</li>
</ol>
<p>CPU和GPU的一级缓存有显著的差异，GPU的一级缓存可以通过编译选项等控制，CPU不可以，而且CPU的一级缓存是的替换算法是有使用频率和时间局部性的，GPU则没有。</p>
<h3 id="4-3-2-2-没有缓存的加载"><a href="#4-3-2-2-没有缓存的加载" class="headerlink" title="4.3.2.2 没有缓存的加载"></a>4.3.2.2 没有缓存的加载</h3><p>没有缓存的加载是指的没有通过一级缓存，二级缓存则是不得不经过的。<br>当不使用一级缓存的时候，内存事务的粒度变为32字节，更细粒度的好处是提高利用率。<br>继续我们的图解：</p>
<ol>
<li>对齐合并访问128字节，不用说，还是最理想的情况，使用4个段，利用率 100%<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-14.png" class="" title="4-14"></li>
<li>对齐不连续访问128字节，都在四个段内，且互不相同，这样的利用率也是  100%<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-15.png" class="" title="4-15"></li>
<li>连续不对齐，一个段32字节，所以，一个连续的128字节的请求，即使不对齐，最多也不会超过五个段，所以利用率是 45=80% ,如果不明白为啥不能超过5个段，请注意前提是连续的，这个时候不可能超过五段<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-16.png" class="" title="4-16"></li>
<li>所有线程访问一个4字节的数据，那么此时的利用率是 432=12.5%<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-17.png" class="" title="4-17"></li>
<li>最欢的情况，所有目标数据分散在内存的各个角落，那么需要 N个内存段， 此时与使用一级缓存的作比较也是有优势的因为 N×128 还是要比 N×32 大不少，这里假设 N 不会因为 128 还是 32 而变的，而实际情况，当使用大粒度的缓存行的时候， N 有可能会减小<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-18.png" class="" title="4-18">
</li>
</ol>
<h3 id="4-3-2-3-非对齐读取的示例"><a href="#4-3-2-3-非对齐读取的示例" class="headerlink" title="4.3.2.3 非对齐读取的示例"></a>4.3.2.3 非对齐读取的示例</h3><p>为了说明核函数中非对齐访问对性能的影响，我们对第3章中使用的向量加法代码进行修改，去掉所有的内存加载操作，来指定一个偏移量。当然也要保障不越界</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">readOffset</span><span class="params">(<span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C, <span class="type">const</span> <span class="type">int</span> n,</span></span><br><span class="line"><span class="params">                           <span class="type">int</span> offset)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> k = i + offset;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (k &lt; n) C[i] = A[k] + B[k];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>完整代码如下</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/common.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * This example demonstrates the impact of misaligned reads on performance by</span></span><br><span class="line"><span class="comment"> * forcing misaligned reads to occur on a float*.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">checkResult</span><span class="params">(<span class="type">float</span> *hostRef, <span class="type">float</span> *gpuRef, <span class="type">const</span> <span class="type">int</span> N)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">double</span> epsilon = <span class="number">1.0E-8</span>;</span><br><span class="line">    <span class="type">bool</span> match = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">abs</span>(hostRef[i] - gpuRef[i]) &gt; epsilon)</span><br><span class="line">        &#123;</span><br><span class="line">            match = <span class="number">0</span>;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;different on %dth element: host %f gpu %f\n&quot;</span>, i, hostRef[i],</span><br><span class="line">                    gpuRef[i]);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!match)  <span class="built_in">printf</span>(<span class="string">&quot;Arrays do not match.\n\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">initialData</span><span class="params">(<span class="type">float</span> *ip,  <span class="type">int</span> size)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; size; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        ip[i] = (<span class="type">float</span>)( rand() &amp; <span class="number">0xFF</span> ) / <span class="number">100.0f</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">sumArraysOnHost</span><span class="params">(<span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C, <span class="type">const</span> <span class="type">int</span> n, <span class="type">int</span> offset)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> idx = offset, k = <span class="number">0</span>; idx &lt; n; idx++, k++)</span><br><span class="line">    &#123;</span><br><span class="line">        C[k] = A[idx] + B[idx];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">warmup</span><span class="params">(<span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C, <span class="type">const</span> <span class="type">int</span> n, <span class="type">int</span> offset)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> k = i + offset;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (k &lt; n) C[i] = A[k] + B[k];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">readOffset</span><span class="params">(<span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C, <span class="type">const</span> <span class="type">int</span> n,</span></span><br><span class="line"><span class="params">                           <span class="type">int</span> offset)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> k = i + offset;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (k &lt; n) C[i] = A[k] + B[k];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// set up device</span></span><br><span class="line">    <span class="type">int</span> dev = <span class="number">0</span>;</span><br><span class="line">    cudaDeviceProp deviceProp;</span><br><span class="line">    CHECK(cudaGetDeviceProperties(&amp;deviceProp, dev));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%s starting reduction at &quot;</span>, argv[<span class="number">0</span>]);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;device %d: %s &quot;</span>, dev, deviceProp.name);</span><br><span class="line">    CHECK(cudaSetDevice(dev));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// set up array size</span></span><br><span class="line">    <span class="type">int</span> nElem = <span class="number">1</span> &lt;&lt; <span class="number">20</span>; <span class="comment">// total number of elements to reduce</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot; with array size %d\n&quot;</span>, nElem);</span><br><span class="line">    <span class="type">size_t</span> nBytes = nElem * <span class="keyword">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// set up offset for summary</span></span><br><span class="line">    <span class="type">int</span> blocksize = <span class="number">512</span>;</span><br><span class="line">    <span class="type">int</span> offset = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (argc &gt; <span class="number">1</span>) offset    = atoi(argv[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (argc &gt; <span class="number">2</span>) blocksize = atoi(argv[<span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// execution configuration</span></span><br><span class="line">    dim3 <span class="title function_">block</span> <span class="params">(blocksize, <span class="number">1</span>)</span>;</span><br><span class="line">    dim3 <span class="title function_">grid</span>  <span class="params">((nElem + block.x - <span class="number">1</span>) / block.x, <span class="number">1</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// allocate host memory</span></span><br><span class="line">    <span class="type">float</span> *h_A = (<span class="type">float</span> *)<span class="built_in">malloc</span>(nBytes);</span><br><span class="line">    <span class="type">float</span> *h_B = (<span class="type">float</span> *)<span class="built_in">malloc</span>(nBytes);</span><br><span class="line">    <span class="type">float</span> *hostRef = (<span class="type">float</span> *)<span class="built_in">malloc</span>(nBytes);</span><br><span class="line">    <span class="type">float</span> *gpuRef  = (<span class="type">float</span> *)<span class="built_in">malloc</span>(nBytes);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//  initialize host array</span></span><br><span class="line">    initialData(h_A, nElem);</span><br><span class="line">    <span class="built_in">memcpy</span>(h_B, h_A, nBytes);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//  summary at host side</span></span><br><span class="line">    sumArraysOnHost(h_A, h_B, hostRef, nElem, offset);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// allocate device memory</span></span><br><span class="line">    <span class="type">float</span> *d_A, *d_B, *d_C;</span><br><span class="line">    CHECK(cudaMalloc((<span class="type">float</span>**)&amp;d_A, nBytes));</span><br><span class="line">    CHECK(cudaMalloc((<span class="type">float</span>**)&amp;d_B, nBytes));</span><br><span class="line">    CHECK(cudaMalloc((<span class="type">float</span>**)&amp;d_C, nBytes));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// copy data from host to device</span></span><br><span class="line">    CHECK(cudaMemcpy(d_A, h_A, nBytes, cudaMemcpyHostToDevice));</span><br><span class="line">    CHECK(cudaMemcpy(d_B, h_A, nBytes, cudaMemcpyHostToDevice));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//  kernel 1:</span></span><br><span class="line">    <span class="type">double</span> iStart = seconds();</span><br><span class="line">    warmup&lt;&lt;&lt;grid, block&gt;&gt;&gt;(d_A, d_B, d_C, nElem, offset);</span><br><span class="line">    CHECK(cudaDeviceSynchronize());</span><br><span class="line">    <span class="type">double</span> iElaps = seconds() - iStart;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;warmup     &lt;&lt;&lt; %4d, %4d &gt;&gt;&gt; offset %4d elapsed %f sec\n&quot;</span>, grid.x,</span><br><span class="line">           block.x, offset, iElaps);</span><br><span class="line">    CHECK(cudaGetLastError());</span><br><span class="line"></span><br><span class="line">    iStart = seconds();</span><br><span class="line">    readOffset&lt;&lt;&lt;grid, block&gt;&gt;&gt;(d_A, d_B, d_C, nElem, offset);</span><br><span class="line">    CHECK(cudaDeviceSynchronize());</span><br><span class="line">    iElaps = seconds() - iStart;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;readOffset &lt;&lt;&lt; %4d, %4d &gt;&gt;&gt; offset %4d elapsed %f sec\n&quot;</span>, grid.x,</span><br><span class="line">           block.x, offset, iElaps);</span><br><span class="line">    CHECK(cudaGetLastError());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// copy kernel result back to host side and check device results</span></span><br><span class="line">    CHECK(cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost));</span><br><span class="line">    checkResult(hostRef, gpuRef, nElem - offset);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// free host and device memory</span></span><br><span class="line">    CHECK(cudaFree(d_A));</span><br><span class="line">    CHECK(cudaFree(d_B));</span><br><span class="line">    CHECK(cudaFree(d_C));</span><br><span class="line">    <span class="built_in">free</span>(h_A);</span><br><span class="line">    <span class="built_in">free</span>(h_B);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// reset device</span></span><br><span class="line">    CHECK(cudaDeviceReset());</span><br><span class="line">    <span class="keyword">return</span> EXIT_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>编译运行如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">zmurder@zmurder:~/chapter04$ ./readSegment 0</span><br><span class="line">./readSegment starting reduction at device 0: Quadro P2000  with array size 1048576</span><br><span class="line">warmup     &lt;&lt;&lt; <span class="string">2048,  512 &gt;&gt;&gt; offset    0 elapsed 0.000201 sec</span></span><br><span class="line"><span class="string">readOffset &lt;&lt;&lt; 2048</span>,  512 &gt;&gt;&gt; offset    0 elapsed 0.000110 sec</span><br><span class="line">zmurder@zmurder:~/chapter04$ ./readSegment 11</span><br><span class="line">./readSegment starting reduction at device 0: Quadro P2000  with array size 1048576</span><br><span class="line">warmup     &lt;&lt;&lt; <span class="string">2048,  512 &gt;&gt;&gt; offset   11 elapsed 0.000199 sec</span></span><br><span class="line"><span class="string">readOffset &lt;&lt;&lt; 2048</span>,  512 &gt;&gt;&gt; offset   11 elapsed 0.000113 sec</span><br><span class="line">zmurder@zmurder:~/chapter04$ ./readSegment 128</span><br><span class="line">./readSegment starting reduction at device 0: Quadro P2000  with array size 1048576</span><br><span class="line">warmup     &lt;&lt;&lt; <span class="string">2048,  512 &gt;&gt;&gt; offset  128 elapsed 0.000196 sec</span></span><br><span class="line"><span class="string">readOffset &lt;&lt;&lt; 2048</span>,  512 &gt;&gt;&gt; offset  128 elapsed 0.000110 sec</span><br></pre></td></tr></table></figure>
<p>查看全局加载效率</p>
<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/image-20230421175908809.png" class="" title="image-20230421175908809">
<h3 id="4-3-2-4-只读缓存"><a href="#4-3-2-4-只读缓存" class="headerlink" title="4.3.2.4 只读缓存"></a>4.3.2.4 只读缓存</h3><p>只读缓存最初是留给纹理内存加载用的，在3.5以上的设备，只读缓存也支持使用全局内存加载代替一级缓存。也就是说3.5以后的设备，可以通过只读缓存从全局内存中读数据了。<br>只读缓存粒度32字节，对于分散读取，细粒度优于一级缓存<br>有两种方法指导内存从只读缓存读取：</p>
<ol>
<li>使用函数 _ldg</li>
<li>在间接引用的指针上使用修饰符</li>
</ol>
<p>代码：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">copyKernel</span><span class="params">(<span class="type">float</span> * in,<span class="type">float</span>* out)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> idx=blockDim*blockIdx.x+threadIdx.x;</span><br><span class="line">    out[idx]=__ldg(&amp;in[idx]);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意函数参数，然后就能强制使用只读缓存了。</p>
<h2 id="4-3-3-全局内存写入"><a href="#4-3-3-全局内存写入" class="headerlink" title="4.3.3 全局内存写入"></a>4.3.3 全局内存写入</h2><p>内存的写入和读取（或者叫做加载）是完全不同的，并且写入相对简单很多。一级缓存不能用在 Fermi 和 Kepler  GPU上进行存储操作，发送到设备前，只经过二级缓存，<strong>存储操作在32个字节的粒度上执行</strong>，内存事物也被分为一段两端或者四段，如果两个地址在一个128字节的段内但不在64字节范围内，则会产生一个四段的事务，其他情况以此类推。<br>我们将内存写入也参考前面的加载分为下面这些情况：</p>
<ol>
<li>对齐的，访问一个连续的128字节范围。存储操作使用一个4段事务完成：<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-19.png" class="" title="4-19"></li>
<li>分散在一个192字节的范围内，不连续，使用3个一段事务来搞定<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-20.png" class="" title="4-20"></li>
<li>对齐的，在一个64字节的范围内，使用一个两段事务完成。<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-21.png" class="" title="4-21">
</li>
</ol>
<h3 id="4-3-3-1-非对齐写入的示例"><a href="#4-3-3-1-非对齐写入的示例" class="headerlink" title="4.3.3.1 非对齐写入的示例"></a>4.3.3.1 非对齐写入的示例</h3><p>修改向量加法核函数。仍然使用两个不同的索引：索引k根据给定的偏移量进行变化，而索引i不变（并因此产生对齐访问）。使用对齐索引i从数组A和数组B中进行加载，以产生良好的内存加载效率。使用偏移量索引x写入数组C，可能会造成非对齐写入，这取决于偏移量的值。</p>
<p>核函数如下</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">writeOffset</span><span class="params">(<span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C, <span class="type">const</span> <span class="type">int</span> n,</span></span><br><span class="line"><span class="params">                            <span class="type">int</span> offset)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> k = i + offset;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (k &lt; n) C[k] = A[i] + B[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="4-3-4-结构体数组与数组结构体"><a href="#4-3-4-结构体数组与数组结构体" class="headerlink" title="4.3.4 结构体数组与数组结构体"></a>4.3.4 结构体数组与数组结构体</h2><p>数组结构体（AoS）</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">innerStruct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="type">float</span> x;</span><br><span class="line">    <span class="type">float</span> y;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">innerStruct</span> <span class="title">myAoS</span>[<span class="title">N</span>];</span></span><br></pre></td></tr></table></figure>
<p>结构体数组（SoA）</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">innerArray</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="type">float</span> x[N];</span><br><span class="line">    <span class="type">float</span> y[N];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">innerArray</span> <span class="title">mySoA</span>;</span></span><br></pre></td></tr></table></figure>
<p>图4-22说明了AoS和SoA方法的内存布局。用AoS模式在GPU上存储示例数据并执行一个<strong>只有x字段的应用程序</strong>，将导致50%的带宽损失，因为y值在每32个字节段或128个字节缓存行上隐式地被加载。</p>
<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/4-22.png" class="" title="4-22">
<p>许多并行编程范式，尤其是SIMD型范式，更倾向于使用SoA。<strong>在CUDA C编程中也普遍倾向于使用SoA.</strong></p>
<h3 id="4-3-4-1-示例：使用AoS数据布局的简单数学运算"><a href="#4-3-4-1-示例：使用AoS数据布局的简单数学运算" class="headerlink" title="4.3.4.1 示例：使用AoS数据布局的简单数学运算"></a>4.3.4.1 示例：使用AoS数据布局的简单数学运算</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> LEN 1&lt;&lt;22</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">innerStruct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="type">float</span> x;</span><br><span class="line">    <span class="type">float</span> y;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> blocksize = <span class="number">128</span>;</span><br><span class="line"><span class="comment">// execution configuration</span></span><br><span class="line">dim3 <span class="title function_">block</span> <span class="params">(blocksize, <span class="number">1</span>)</span>;</span><br><span class="line">dim3 <span class="title function_">grid</span>  <span class="params">((nElem + block.x - <span class="number">1</span>) / block.x, <span class="number">1</span>)</span>;</span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">testInnerStruct</span><span class="params">(innerStruct *data, innerStruct * result,</span></span><br><span class="line"><span class="params">                                <span class="type">const</span> <span class="type">int</span> n)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (i &lt; n)</span><br><span class="line">    &#123;</span><br><span class="line">        innerStruct tmp = data[i];</span><br><span class="line">        tmp.x += <span class="number">10.f</span>;</span><br><span class="line">        tmp.y += <span class="number">20.f</span>;</span><br><span class="line">        result[i] = tmp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行程序如下</p>
<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/image-20230423155322864.png" class="" title="image-20230423155322864">
<p>书中的解释是：下面展示的50%的效率结果表明，对于AOS数据布局，加载请求和内存存储请求是重复的。因为字段x和y在内存中是被相邻存储的，并且有相同的大小，每当执行内存事务时都要加载特定字段的值，被加载的字节数的一半也必须属于其他字段。因此，请求加载和存储的50%带宽是未使用的。<strong>但是我没看懂为什么</strong>，一个结构体是<code>2*4</code>字节，block为(128,1)，所以一个线程束（32个线程）需要加载<code>32*2*4=256</code>字节的内存，按照4.3.2节的描述，需要两次内存事务。但是下面的SoA例子应该是一样的啊。。。不理解。。</p>
<p>这里放几篇查到的内容，看看后期能不能理解</p>
<p><a target="_blank" rel="noopener" href="https://www.fluentcpp.com/2018/12/18/the-soa-vector-part-1-optimizing-the-traversal-of-a-collection/">The SoA Vector – Part 1: Optimizing the Traversal of a Collection</a> </p>
<p><a target="_blank" rel="noopener" href="https://www.codebooklet.com/2022/10/02/ComputerScience/%5BHPP%5D-AOSandSOA/">AoS and SoA</a> </p>
<p><a target="_blank" rel="noopener" href="https://en.algorithmica.org/hpc/cpu-cache/aos-soa/#:~:text=AoS%20performs%20slightly%20better%20because%20it%20can%20compute,this%20causes%20a%20pretty%20complicated%20cache%20associativity%20effect.">AOS &amp; SOA</a> </p>
<p><a target="_blank" rel="noopener" href="https://developer.unity.cn/projects/61ff5161edbc2a001cf9856e">SoA vs AoS</a></p>
<h3 id="4-3-4-2-示例：使用SoA数据布局的简单数学运算"><a href="#4-3-4-2-示例：使用SoA数据布局的简单数学运算" class="headerlink" title="4.3.4.2 示例：使用SoA数据布局的简单数学运算"></a>4.3.4.2 示例：使用SoA数据布局的简单数学运算</h3><p>对应的kernel如下</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> LEN 1&lt;&lt;22</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">innerArray</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="type">float</span> x[LEN];</span><br><span class="line">    <span class="type">float</span> y[LEN];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="type">int</span> blocksize = <span class="number">128</span>;</span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">testInnerArray</span><span class="params">(InnerArray *data, InnerArray * result,</span></span><br><span class="line"><span class="params">                               <span class="type">const</span> <span class="type">int</span> n)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (i &lt; n)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">float</span> tmpx = data-&gt;x[i];</span><br><span class="line">        <span class="type">float</span> tmpy = data-&gt;y[i];</span><br><span class="line"></span><br><span class="line">        tmpx += <span class="number">10.f</span>;</span><br><span class="line">        tmpy += <span class="number">20.f</span>;</span><br><span class="line">        result-&gt;x[i] = tmpx;</span><br><span class="line">        result-&gt;y[i] = tmpy;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行结果如下，不明白为什么（书中的解释是100%的效率说明当处理SoA数据布局时，加载或存储内存请求不<br>会重复。每次访问都由一个独立的内存事务来处理。）</p>
<img src="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/image-20230423155907675.png" class="" title="image-20230423155907675">
<h2 id="4-3-5-性能调整"><a href="#4-3-5-性能调整" class="headerlink" title="4.3.5 性能调整"></a>4.3.5 性能调整</h2><p>优化设备内存带宽利用率有两个目标：</p>
<ul>
<li>对齐及合并内存访问， 以减少带宽的浪费</li>
<li>足够的并发内存操作， 以隐藏内存延迟</li>
</ul>
<h3 id="4-3-5-1-展开技术"><a href="#4-3-5-1-展开技术" class="headerlink" title="4.3.5.1 展开技术"></a>4.3.5.1 展开技术</h3><p>内存操作的循环展开增加了更独立的内存操作。 展开并不影响执行内存操作的数量（只影响并发执行的数量）。</p>
<h3 id="4-3-5-2-增大并行性"><a href="#4-3-5-2-增大并行性" class="headerlink" title="4.3.5.2 增大并行性"></a>4.3.5.2 增大并行性</h3><p>为了充分体现并行性， 你应该用一个核函数启动的网格和线程块大小进行试验， 以找到该核函数最佳的执行配置。</p>
<blockquote>
<p>最大化带宽利用率</p>
</blockquote>
<p>影响设备内存操作性能的因素主要有两个：</p>
<ul>
<li>有效利用设备DRAM和SM片上内存之间的字节移动： 为了避免设备内存带宽的浪费， 内存访问模式应是对齐和合并的</li>
<li>当前的并发内存操作数： 可通过以下两点实现最大化当前存储器操作数。<ul>
<li>展开，每个线程产生更多的独立内存访问。</li>
<li>修改核函数启动的执行配置来使每个SM有更多的并行性。</li>
</ul>
</li>
</ul>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html">官方nvprof参数说明</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>奔跑的IC
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://example.com/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-3%20%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/" title="4-3 内存访问模式">http://example.com/CUDA/CUDA C编程权威指南笔记/4-3 内存访问模式/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/C/" rel="tag"><i class="fa fa-tag"></i> C</a>
              <a href="/tags/GPU/" rel="tag"><i class="fa fa-tag"></i> GPU</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/3-5%20%E5%B1%95%E5%BC%80%E5%BE%AA%E7%8E%AF/" rel="prev" title="3-5 展开循环">
                  <i class="fa fa-chevron-left"></i> 3-5 展开循环
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/CUDA/CUDA%20C%E7%BC%96%E7%A8%8B%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/4-2%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/" rel="next" title="4-2 内存管理">
                  4-2 内存管理 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">奔跑的IC</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div><script color="0,0,255" opacity="0.5" zIndex="-1" count="99" src="https://lib.baomitu.com/canvas-nest.js/1.0.1/canvas-nest.js"></script>


    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"zmurder","repo":"zmurder.github.io","client_id":"cf2343f27b6c29efe0bc","client_secret":"3268a1fa92706c7358d5421f88f76a0f7ada3188","admin_user":"zmurder","distraction_free_mode":true,"proxy":"https://strong-caramel-969805.netlify.app/github_access_token","language":"zh-CN","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"a1e528c56324008c7958922e1a1eb13c"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
