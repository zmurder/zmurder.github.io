<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8693861384618000"
     crossorigin="anonymous"></script>
  <meta name="msvalidate.01" content="7EC20DBC74B004C2782077570E15C280">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.14.2","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8693861384618000"
     crossorigin="anonymous"></script>
    <meta name="description" content="简介卷积神经网络：卷积神经网络（Convolutional Neural Networks, CNN）是计算机视觉技术最经典的模型结构。本教程主要介绍卷积神经网络的常用模块，包括：卷积、池化、激活函数、批归一化、丢弃法等。">
<meta property="og:type" content="article">
<meta property="og:title" content="卷积神经网络基础">
<meta property="og:url" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/index.html">
<meta property="og:site_name" content="奔跑的IC">
<meta property="og:description" content="简介卷积神经网络：卷积神经网络（Convolutional Neural Networks, CNN）是计算机视觉技术最经典的模型结构。本教程主要介绍卷积神经网络的常用模块，包括：卷积、池化、激活函数、批归一化、丢弃法等。">
<meta property="og:locale">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/70d8475ed908487680057bf1f2760f10e367e7176acf43ebb380207b748b2377.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/d65f1ebcb0054dcb81a8eb50223adc529bb9b63265ab467d931a5df5b2864122.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/01179d17c9f74570b8a618d6123261ce6e10344f11c84dda8e47d44c1eb4fc81.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/1ccd30567304415d98b0b373ec641a3d00f76d803f194ea4b14aa85ce85bf7bb.jpeg">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/6d1440daa10944c899a7c98e1bed3931a09bae52730d4c20a65b322193d284e1.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/d5019afe174745efbf7a3d3c604b9c85eeddc947f7184446a9147d128863864d.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128150040527.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128150057389-170115485857513.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128150114469.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128150137416.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128151942162.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128152009398.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128152134173.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128152413487.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/01d311ec2c65435f85059953a84ec7ea8ef2fd236452450e912346a7da201c5f.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128152621271.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422110159369.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/afdae9af02fc45eabdd9663ee6474e4da86675fa1f444c78aea0e21539b32cf0.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128152709852.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/1021536721524f4d8f4c1aefa89693c4b0fd388f21a347b583d413b3ac41241b.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/ac14916db81e40a48a25ab894d7a95e33fa0eece71d44a55af7bffab462fb7a7.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/92186667b8424a7ca781b22de6766fa62e31512cf2e24e33a4b796541177c9dd.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128154049214.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/cf1fbddc141349e4b7aaeade9a201b78a16d249e069c4f8aaeb77e0ea1a95c31.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128154208307.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/60760d68001c40d6a6c500b17f57d8deae7b5921631b4b6b896b057b904d24b1.jpeg">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/1761233-20200227172057401-903386019.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/1761233-20200227172109497-117107623.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/1761233-20200227172140565-1727427851.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/1761233-20200227172126911-2099641929.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/v2-bedd0b4720b7fc13ff00f2023b231097_r.jpg">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/v2-941f580de5c7b425d3931ba357de403c_r.jpg">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/v2-75b876524407961c357643da1e417521_r.jpg">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/v2-b8e065c3998e0b02b487e13cc8307de2_r.jpg">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/v2-fbe68362b66bcff722475a1d1b337134_r.jpg">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/v2-15fc47c035e96b8e88ffd6b80a00bea8_r.jpg">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/v2-dbad4af92483ffa9723aa712d5bf8759_r.jpg">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422104617695.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422105237527.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/2020042210550658.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128154509543.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128154552997.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422151012841.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231220103625936.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231220103838108.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422162305516.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231220111307410.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/5479daa3734d424bb710615d3c4f7e017ba2558808a8421ca7c914f3fced0a48.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128154751593.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422174655532.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422175445969.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155010318.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155032340.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155046800.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155152504.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155343278-170115803374231.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155402167.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155439041.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155554779.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155615806.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422182001606.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422182214965.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/202006281600100.png">
<meta property="og:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200628160103118.png">
<meta property="article:published_time" content="2024-12-01T10:13:44.822Z">
<meta property="article:modified_time" content="2024-12-01T10:13:44.822Z">
<meta property="article:author" content="奔跑的IC">
<meta property="article:tag" content="C">
<meta property="article:tag" content="卷积神经网络">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/70d8475ed908487680057bf1f2760f10e367e7176acf43ebb380207b748b2377.png">


<link rel="canonical" href="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-Hans","comments":true,"permalink":"http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/","path":"DeepLearning/基础/卷积神经网络基础/","title":"卷积神经网络基础"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>卷积神经网络基础 | 奔跑的IC</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">奔跑的IC</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-reorder fa-fw"></i>文章列表</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AE%80%E4%BB%8B"><span class="nav-text">简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9A%84%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B"><span class="nav-text">1 计算机视觉的发展历程</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-text">2 卷积神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-%E5%8D%B7%E7%A7%AF%EF%BC%88Convolution%EF%BC%89"><span class="nav-text">2.1 卷积（Convolution）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-%E5%8D%B7%E7%A7%AF%E8%AE%A1%E7%AE%97"><span class="nav-text">2.2 卷积计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-%E5%A1%AB%E5%85%85%EF%BC%88padding%EF%BC%89"><span class="nav-text">2.3 填充（padding）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-%E6%AD%A5%E5%B9%85%EF%BC%88stride%EF%BC%89"><span class="nav-text">2.4 步幅（stride）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-5-%E6%84%9F%E5%8F%97%E9%87%8E%EF%BC%88Receptive-Field%EF%BC%89"><span class="nav-text">2.5 感受野（Receptive Field）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-6-%E5%A4%9A%E8%BE%93%E5%85%A5%E9%80%9A%E9%81%93%E3%80%81%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93%E5%92%8C%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C"><span class="nav-text">2.6 多输入通道、多输出通道和批量操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-7-%E5%8D%B7%E7%A7%AF%E7%AE%97%E5%AD%90%E5%BA%94%E7%94%A8%E4%B8%BE%E4%BE%8B"><span class="nav-text">2.7 卷积算子应用举例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-7-1-%E5%9E%82%E7%9B%B4%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E5%99%A8"><span class="nav-text">2.7.1 垂直边缘检测器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-7-2-%E6%B0%B4%E5%B9%B3%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E5%99%A8"><span class="nav-text">2.7.2 水平边缘检测器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-7-3-%E6%A1%88%E4%BE%8B1%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E9%BB%91%E7%99%BD%E8%BE%B9%E7%95%8C%E6%A3%80%E6%B5%8B"><span class="nav-text">2.7.3 案例1——简单的黑白边界检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-7-4-%E6%A1%88%E4%BE%8B2%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E4%B8%AD%E7%89%A9%E4%BD%93%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B"><span class="nav-text">2.7.4 案例2——图像中物体边缘检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-7-5-%E6%A1%88%E4%BE%8B3%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E5%9D%87%E5%80%BC%E6%A8%A1%E7%B3%8A"><span class="nav-text">2.7.5 案例3——图像均值模糊</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-8-%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C"><span class="nav-text">2.8 单层卷积网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-9-%E7%AE%80%E5%8D%95%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B"><span class="nav-text">2.9 简单卷积网络示例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-10-%E6%B1%A0%E5%8C%96%EF%BC%88Pooling%EF%BC%89"><span class="nav-text">2.10 池化（Pooling）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="nav-text">2.1 激活函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-12-%E6%89%B9%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%88Batch-Normalization%EF%BC%89"><span class="nav-text">2.12 批归一化（Batch Normalization）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-13-%E4%B8%A2%E5%BC%83%E6%B3%95%EF%BC%88Dropout%EF%BC%89"><span class="nav-text">2.13 丢弃法（Dropout）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-14-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B"><span class="nav-text">2.14 卷积神经网络示例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-15-%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%EF%BC%9F"><span class="nav-text">2.15 为什么使用卷积？</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%99%84%E5%BD%95%EF%BC%9A"><span class="nav-text">附录：</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="奔跑的IC"
      src="/images/zyd.gif">
  <p class="site-author-name" itemprop="name">奔跑的IC</p>
  <div class="site-description" itemprop="description">死磕牛角的IT农民工</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">157</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">27</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zyd.gif">
      <meta itemprop="name" content="奔跑的IC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="奔跑的IC">
      <meta itemprop="description" content="死磕牛角的IT农民工">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="卷积神经网络基础 | 奔跑的IC">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          卷积神经网络基础
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-01 18:13:44" itemprop="dateCreated datePublished" datetime="2024-12-01T18:13:44+08:00">2024-12-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DeepLearning/" itemprop="url" rel="index"><span itemprop="name">DeepLearning</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/DeepLearning/%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">基础</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><strong>卷积神经网络</strong>：卷积神经网络（Convolutional Neural Networks, CNN）是计算机视觉技术最经典的模型结构。本教程主要介绍卷积神经网络的常用模块，包括：卷积、池化、激活函数、批归一化、丢弃法等。</p>
<ul>
<li><strong>图像分类</strong>：介绍图像分类算法的经典模型结构，包括：LeNet、AlexNet、VGG、GoogLeNet、ResNet，并通过眼疾筛查的案例展示算法的应用。</li>
<li><strong>目标检测</strong>：介绍目标检测YOLOv3算法，并通过林业病虫害检测案例展示YOLOv3算法的应用。</li>
</ul>
<h1 id="1-计算机视觉的发展历程"><a href="#1-计算机视觉的发展历程" class="headerlink" title="1 计算机视觉的发展历程"></a>1 计算机视觉的发展历程</h1><p>计算机视觉的发展历程要从生物视觉讲起。对于生物视觉的起源，目前学术界尚没有形成定论。有研究者认为最早的生物视觉形成于距今约<a target="_blank" rel="noopener" href="https://www.pnas.org/content/109/46/18868">7亿年前的水母之中</a>，也有研究者认为生物视觉产生于距今约5亿年前寒武纪【<a target="_blank" rel="noopener" href="https://doi.org/10.1038%2Fnature10097">1</a>, <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Evolution_of_the_eye">2</a>】。寒武纪生物大爆发的原因一直是个未解之谜，不过可以肯定的是在寒武纪动物具有了视觉能力，捕食者可以更容易地发现猎物，被捕食者也可以更早的发现天敌的位置。视觉能力加剧了猎手和猎物之间的博弈，也催生出更加激烈的生存演化规则。视觉系统的形成有力地推动了食物链的演化，加速了生物进化过程，是生物发展史上重要的里程碑。经过几亿年的演化，目前人类的视觉系统已经具备非常高的复杂度和强大的功能，人脑中神经元数目达到了1000亿个，这些神经元通过网络互相连接，这样庞大的视觉神经网络使得我们可以很轻松的观察周围的世界，如 <strong>图2</strong> 所示。 </p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/70d8475ed908487680057bf1f2760f10e367e7176acf43ebb380207b748b2377.png" class="" title="img">
<p>图2：人类视觉感知</p>
<p>对人类来说，识别猫和狗是件非常容易的事。但对计算机来说，即使是一个精通编程的高手，也很难轻松写出具有通用性的程序（比如：假设程序认为体型大的是狗，体型小的是猫，但由于拍摄角度不同，可能一张图片上猫占据的像素比狗还多）。那么，如何让计算机也能像人一样看懂周围的世界呢？研究者尝试着从不同的角度去解决这个问题，由此也发展出一系列的子任务，如 <strong>图3</strong> 所示。 </p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/d65f1ebcb0054dcb81a8eb50223adc529bb9b63265ab467d931a5df5b2864122.png" class="" title="img">
<p>图3：计算机视觉子任务示意图</p>
<ul>
<li><strong>(a) Image Classification：</strong> 图像分类，用于识别图像中物体的类别（如：bottle、cup、cube）。</li>
<li><strong>(b) Object Localization：</strong> 目标检测，用于检测图像中每个物体的类别，并准确标出它们的位置。</li>
<li><strong>© Semantic Segmentation：</strong> 图像语义分割，用于标出图像中每个像素点所属的类别，属于同一类别的像素点用一个颜色标识。</li>
<li><strong>(d) Instance Segmentation：</strong> 实例分割，值得注意的是，（b）中的目标检测任务只需要标注出物体位置，而（d）中的实例分割任务不仅要标注出物体位置，还需要标注出物体的外形轮廓。</li>
</ul>
<p>在早期的图像分类任务中，通常是先人工提取图像特征，再用机器学习算法对这些特征进行分类，分类的结果强依赖于特征提取方法，往往只有经验丰富的研究者才能完成，如 <strong>图4</strong> 所示。 </p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/01179d17c9f74570b8a618d6123261ce6e10344f11c84dda8e47d44c1eb4fc81.png" class="" title="img">
<p>图4：早期的图像分类任务</p>
<p>在这种背景下，基于神经网络的特征提取方法应运而生。Yann  LeCun是最早将卷积神经网络应用到图像识别领域的，其主要逻辑是使用卷积神经网络提取图像特征，并对图像所属类别进行预测，通过训练数据不断调整网络参数，最终形成一套能自动提取图像特征并对这些特征进行分类的网络，如 <strong>图5</strong> 所示。 </p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/1ccd30567304415d98b0b373ec641a3d00f76d803f194ea4b14aa85ce85bf7bb.jpeg" class="" title="img">
<p>图5：早期的卷积神经网络处理图像任务示意</p>
<p>这一方法在手写数字识别任务上取得了极大的成功，但在接下来的时间里，却没有得到很好的发展。其主要原因一方面是数据集不完善，只能处理简单任务，在大尺寸的数据上容易发生过拟合；另一方面是硬件瓶颈，网络模型复杂时，计算速度会特别慢。</p>
<p>目前，随着互联网技术的不断进步，数据量呈现大规模的增长，越来越丰富的数据集不断涌现。另外，得益于硬件能力的提升，计算机的算力也越来越强大。不断有研究者将新的模型和算法应用到计算机视觉领域。由此催生了越来越丰富的模型结构和更加准确的精度，同时计算机视觉所处理的问题也越来越丰富，包括分类、检测、分割、场景描述、图像生成和风格变换等，甚至还不仅仅局限于2维图片，包括视频处理技术和3D视觉等。</p>
<h1 id="2-卷积神经网络"><a href="#2-卷积神经网络" class="headerlink" title="2 卷积神经网络"></a>2 卷积神经网络</h1><p>卷积神经网络是目前计算机视觉中使用最普遍的模型结构。本章节主要向读者介绍卷积神经网络的一些基础模块，包括：</p>
<ul>
<li>卷积（Convolution）</li>
<li>池化（Pooling）</li>
<li>ReLU激活函数</li>
<li>批归一化（Batch Normalization）</li>
<li>丢弃法（Dropout）</li>
</ul>
<p>回顾一下，在上一章“一个案例带你吃透深度学习”中，我们介绍了手写数字识别任务，应用的是全连接网络进行特征提取，即将一张图片上的所有像素点展开成一个1维向量输入网络，存在如下两个问题：</p>
<p><strong>1. 输入数据的空间信息被丢失。</strong> 空间上相邻的像素点往往具有相似的RGB值，RGB的各个通道之间的数据通常密切相关，但是转化成1维向量时，这些信息被丢失。同时，图像数据的形状信息中，可能隐藏着某种本质的模式，但是转变成1维向量输入全连接神经网络时，这些模式也会被忽略。</p>
<p><strong>2. 模型参数过多，容易发生过拟合。</strong> 在手写数字识别案例中，每个像素点都要跟所有输出的神经元相连接。当图片尺寸变大时，输入神经元的个数会按图片尺寸的平方增大，导致模型参数过多，容易发生过拟合。</p>
<p>为了解决上述问题，我们引入卷积神经网络进行特征提取，既能提取到相邻像素点之间的特征模式，又能保证参数的个数不随图片尺寸变化。<strong>图6</strong> 是一个典型的卷积神经网络结构，多层卷积和池化层组合作用在输入图片上，在网络的最后通常会加入一系列全连接层，ReLU激活函数一般加在卷积或者全连接层的输出上，网络中通常还会加入Dropout来防止过拟合。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/6d1440daa10944c899a7c98e1bed3931a09bae52730d4c20a65b322193d284e1.png" class="" title="img">
<p>图6：卷积神经网络经典结构</p>
<p><strong>说明：</strong></p>
<p>在卷积神经网络中，计算范围是在像素点的空间邻域内进行的，卷积核参数的数目也远小于全连接层。卷积核本身与输入图片大小无关，它代表了对空间邻域内某种特征模式的提取。比如，有些卷积核提取物体边缘特征，有些卷积核提取物体拐角处的特征，图像上不同区域共享同一个卷积核。当输入图片大小不一样时，仍然可以使用同一个卷积核进行操作。</p>
<h2 id="2-1-卷积（Convolution）"><a href="#2-1-卷积（Convolution）" class="headerlink" title="2.1 卷积（Convolution）"></a>2.1 卷积（Convolution）</h2><p>这一小节将为读者介绍卷积算法的原理和实现方案，并通过具体的案例展示如何使用卷积对图片进行操作，主要涵盖如下内容：</p>
<ul>
<li>卷积计算</li>
<li>填充（padding）</li>
<li>步幅（stride）</li>
<li>感受野（Receptive Field）</li>
<li>多输入通道、多输出通道和批量操作</li>
<li>卷积算子应用举例</li>
</ul>
<h2 id="2-2-卷积计算"><a href="#2-2-卷积计算" class="headerlink" title="2.2 卷积计算"></a>2.2 卷积计算</h2><p>卷积是数学分析中的一种积分变换的方法，在图像处理中采用的是卷积的离散形式。这里需要说明的是，在卷积神经网络中，卷积层的实现方式实际上是数学中定义的互相关   （cross-correlation）运算，与数学分析中的卷积定义有所不同，这里跟其他框架和卷积神经网络的教程保持一致，都使用互相关运算作为卷积的定义，具体的计算过程如 <strong>图7</strong> 所示。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/d5019afe174745efbf7a3d3c604b9c85eeddc947f7184446a9147d128863864d.png" class="" title="img">
<p>图7：卷积计算过程</p>
<p><strong>说明：</strong></p>
<p>卷积核（kernel）也被叫做滤波器（filter），假设卷积核的高和宽分别为$k_h$和$k_w$，则将称为$k_h*k_w$卷积，比如$3×5$卷积，就是指卷积核的高为3, 宽为5。</p>
<ul>
<li><p>如图7（a）所示：左边的图大小是$3<em>3$，表示输入数据是一个维度为$3</em>3$的二维数组；中间的图大小是$2<em>2$，表示一个维度为$2</em>2$的二维数组，我们将这个二维数组称为卷积核。先将卷积核的左上角与输入数据的左上角（即：输入数据的(0, 0)位置）对齐，把卷积核的每个元素跟其位置对应的输入数据中的元素相乘，再把所有乘积相加，得到卷积输出的第一个结果：</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128150040527.png" class="" title="image-20231128150040527">
</li>
<li><p>如图7（b）所示：将卷积核向右滑动，让卷积核左上角与输入数据中的(0,1)位置对齐，同样将卷积核的每个元素跟其位置对应的输入数据中的元素相乘，再把这4个乘积相加，得到卷积输出的第二个结果：</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128150057389-170115485857513.png" class="" title="image-20231128150057389">
</li>
<li><p>如图7（c）所示：将卷积核向下滑动，让卷积核左上角与输入数据中的(1, 0)位置对齐，可以计算得到卷积输出的第三个结果：</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128150114469.png" class="" title="image-20231128150114469">
</li>
<li><p>如图7（d）所示：将卷积核向右滑动，让卷积核左上角与输入数据中的(1, 1)位置对齐，可以计算得到卷积输出的第四个结果：</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128150137416.png" class="" title="image-20231128150137416">
</li>
</ul>
<p>卷积核的计算过程可以用下面的数学公式表示，其中 aaa 代表输入图片， bbb 代表输出特征图，www 是卷积核参数，它们都是二维数组，$\sum u,v$ 表示对卷积核参数进行遍历并求和。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128151942162.png" class="" title="image-20231128151942162">
<p>举例说明，假如上图中卷积核大小是2×22\times 22×2，则uuu可以取0和1，vvv也可以取0和1，也就是说：</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128152009398.png" class="" title="image-20231128152009398">
<p>读者可以自行验证，当$[i,j]$取不同值时，根据此公式计算的结果与上图中的例子是否一致。</p>
<p><strong>其它说明：</strong></p>
<p>在卷积神经网络中，一个卷积算子除了上面描述的卷积过程之外，还包括加上偏置项的操作。例如假设偏置为1，则上面卷积计算的结果为：</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128152134173.png" class="" title="image-20231128152134173">
<h2 id="2-3-填充（padding）"><a href="#2-3-填充（padding）" class="headerlink" title="2.3 填充（padding）"></a>2.3 填充（padding）</h2><p>在上面的例子中，输入图片尺寸为$3<em>3$，输出图片尺寸为$2</em>2$，经过一次卷积之后，图片尺寸变小。卷积输出特征图的尺寸计算方法如下（卷积核的高和宽分别为$k_h k_w$）：</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128152413487.png" class="" title="image-20231128152413487">
<p>如果输入尺寸为4，卷积核大小为3时，输出尺寸为4−3+1=24-3+1=24−3+1=2。读者可以自行检查当输入图片和卷积核为其他尺寸时，上述计算式是否成立。当卷积核尺寸大于1时，输出特征图的尺寸会小于输入图片尺寸。如果经过多次卷积，输出图片尺寸会不断减小。为了避免卷积之后图片尺寸变小，通常会在图片的外围进行填充(padding)，如 <strong>图8</strong> 所示。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/01d311ec2c65435f85059953a84ec7ea8ef2fd236452450e912346a7da201c5f.png" class="" title="img">
<p>图8：图形填充 </p>
<ul>
<li>如图8（a）所示：填充的大小为1，填充值为0。填充之后，输入图片尺寸从4×4变成了6×6，使用3×33\times33×3的卷积核，输出图片尺寸为4×4。</li>
<li>如图8（b）所示：填充的大小为2，填充值为0。填充之后，输入图片尺寸从4×4变成了8×8，使用3×3的卷积核，输出图片尺寸为6×6。</li>
</ul>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128152621271.png" class="" title="image-20231128152621271">
<p>按照我们上面讲的图片卷积，如果原始图片尺寸为 n×n，filter尺寸为 f × f ，则卷积后的图片尺寸为 ( n − f + 1 ) × ( n − f + 1 ) ，注意 f 一般为奇数。这样会带来两个问题：</p>
<ul>
<li>卷积运算后，输出图片尺寸缩小</li>
<li>原始图片边缘信息对输出贡献得少，输出图片丢失边缘信息</li>
</ul>
<p>为了解决图片缩小的问题，可以 使用padding方法，即把原始图片尺寸进行扩展，扩展区域补零，用 p  来表示每个方向扩展的宽度。<br><img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422110159369.png" class="" title="在这里插入图片描述"><br>经过padding之后:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>原始图像padding后尺寸</th>
<th>filter尺寸</th>
<th>卷积后的图像尺寸</th>
</tr>
</thead>
<tbody>
<tr>
<td>$(n+2p)*(n+2p)$</td>
<td>$(f*f)$</td>
<td>$(n+2p−f+1)×(n+2p−f+1)$</td>
</tr>
</tbody>
</table>
</div>
<p>若要保证卷积前后图像尺寸不变，则p应满足：</p>
<p>$n=(n+2p−f+1)$即$p={f−1\over 2}$</p>
<p>总结：</p>
<ul>
<li>无padding操作， $p = 0$ ，我们称之为 Valid convolutions （不填充）</li>
<li>有padding操作，$p={f−1\over 2}$，我们称之为 Same convolutions （填充，输入输出大小相等）</li>
</ul>
<h2 id="2-4-步幅（stride）"><a href="#2-4-步幅（stride）" class="headerlink" title="2.4 步幅（stride）"></a>2.4 步幅（stride）</h2><p><strong>图8</strong> 中卷积核每次滑动一个像素点，这是步幅为1的特殊情况。<strong>图9</strong> 是步幅为2的卷积过程，卷积核在图片上移动时，每次移动大小为2个像素点。 </p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/afdae9af02fc45eabdd9663ee6474e4da86675fa1f444c78aea0e21539b32cf0.png" class="" title="img">图9：步幅为2的卷积过程 

<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128152709852.png" class="" title="image-20231128152709852">
<h2 id="2-5-感受野（Receptive-Field）"><a href="#2-5-感受野（Receptive-Field）" class="headerlink" title="2.5 感受野（Receptive Field）"></a>2.5 感受野（Receptive Field）</h2><p>输出特征图上每个点的数值，是由输入图片上大小为$k_h <em> k_w$的区域的元素与卷积核每个元素相乘再相加得到的，所以输入图像上$k_h </em> k_w$区域内每个元素数值的改变，都会影响输出点的像素值。我们将这个区域叫做输出特征图上对应点的感受野。感受野内每个元素数值的变动，都会影响输出点的数值变化。比如$3×3$卷积对应的感受野大小就是$3×3$，如 <strong>图10</strong> 所示。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/1021536721524f4d8f4c1aefa89693c4b0fd388f21a347b583d413b3ac41241b.png" class="" title="img">
<p>图10：感受野为3×3的卷积 </p>
<p>而当通过两层$3×3$的卷积之后，感受野的大小将会增加到$5×5$，如 <strong>图11</strong> 所示。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/ac14916db81e40a48a25ab894d7a95e33fa0eece71d44a55af7bffab462fb7a7.png" class="" title="img">
<p>图11：感受野为5×5的卷积 </p>
<p>因此，当增加卷积网络深度的同时，感受野将会增大，输出特征图中的一个像素点将会包含更多的图像语义信息。</p>
<h2 id="2-6-多输入通道、多输出通道和批量操作"><a href="#2-6-多输入通道、多输出通道和批量操作" class="headerlink" title="2.6 多输入通道、多输出通道和批量操作"></a>2.6 多输入通道、多输出通道和批量操作</h2><p>前面介绍的卷积计算过程比较简单，实际应用时，处理的问题要复杂的多。例如：对于彩色图片有RGB三个通道，需要处理多输入通道的场景。输出特征图往往也会具有多个通道，而且在神经网络的计算中常常是把一个批次的样本放在一起计算，所以卷积算子需要具有批量处理多输入和多输出通道数据的功能，下面将分别介绍这几种场景的操作方式。</p>
<ul>
<li><strong>多输入通道场景</strong></li>
</ul>
<p>上面的例子中，卷积层的数据是一个2维数组，但实际上一张图片往往含有RGB三个通道，要计算卷积的输出结果，卷积核的形式也会发生变化。假设输入图片的通道数为$C<em>{in}$，输入数据的形状是，$C</em>{in} <em> H_{in} </em> W_{in}$计算过程如 <strong>图12</strong> 所示。</p>
<ol>
<li><p>对每个通道分别设计一个2维数组作为卷积核，卷积核数组的形状是$C_{in} <em> k_h </em> k_w$。</p>
</li>
<li><p>对任一通道Cin∈[0,Cin)，分别用大小为$k<em>h * k_w$的卷积核在大小为$H</em>{in} * W_{in}$的二维数组上做卷积。</p>
</li>
<li><p>将这$C<em>{in}$个通道的计算结果相加，得到的是一个形状为$H</em>{out} * W_{out}$的二维数组。 </p>
</li>
</ol>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/92186667b8424a7ca781b22de6766fa62e31512cf2e24e33a4b796541177c9dd.png" class="" title="img">
<p>图12：多输入通道计算过程 </p>
<ul>
<li><p><strong>多输出通道场景</strong></p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128154049214.png" class="" title="image-20231128154049214">
</li>
</ul>
<p>  <strong>说明：</strong></p>
<p>  通常将卷积核的输出通道数叫做卷积核的个数。</p>
  <img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/cf1fbddc141349e4b7aaeade9a201b78a16d249e069c4f8aaeb77e0ea1a95c31.png" class="" title="img">
<ul>
<li><p><strong>批量操作</strong></p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128154208307.png" class="" title="image-20231128154208307">
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/60760d68001c40d6a6c500b17f57d8deae7b5921631b4b6b896b057b904d24b1.jpeg" class="" title="img">
</li>
</ul>
<h2 id="2-7-卷积算子应用举例"><a href="#2-7-卷积算子应用举例" class="headerlink" title="2.7 卷积算子应用举例"></a>2.7 卷积算子应用举例</h2><img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/1761233-20200227172057401-903386019.png" class="" title="img">
<p>神经网络的前几层只能检测边缘边缘，比如：人脸的鼻子旁边的垂直线，后面的几层检测目标物体的部分区域，比如：人脸的鼻子、眼睛等，更靠后面的层就可以检测到完整的目标物体，比如：人脸。神经网络正是这样将一张图中的人脸分部来检测和提取特征从而识别出人脸，就像我们完成一项工作，将所有事情先分为一小步，完成这一步之后再进行下一步。</p>
<p>现在我们就以边缘检测来说明卷积运算是如何进行操作的</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/1761233-20200227172109497-117107623.png" class="" title="img">
<p>让我们举个例子，给了这样一张图片，让电脑去搞清楚这张照片里有什么物体，你可能做的第一件事是检测图片中的垂直边缘。</p>
<p>比如说，在这张图片中的栏杆就对应垂直线，与此同时，这些行人的轮廓线某种程度上也是垂线，这些线是垂直边缘检测器的输出。同样，你可能也想检测水平边缘，比如说这些栏杆就是很明显的水平线，它们也能被检测到，结果在这。</p>
<p>所以如何在图像中检测这些边缘？</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/1761233-20200227172140565-1727427851.png" class="" title="img">
<p>看一个例子，这是一个6×6的灰度图像。因为是灰度图像，所以它是6×6×1的矩阵，而不是6×6×3的，因为没有RGB三通道。为了检测图像中的垂直边缘，你可以构造一个3×3矩阵。<strong>在共用习惯中，在卷积神经网络的术语中，它被称为过滤器(或者叫做卷积核)。</strong>我要构造一个3×3的过滤器，像这样</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/1761233-20200227172126911-2099641929.png" class="" title="img">
<p>在论文它有时候会被称为核，而不是过滤器，但在这个笔记中，我将使用过滤器这个术语。对这个6×6的图像进行卷积运算，卷积运算用“*”来表示，用3×3的过滤器对其进行卷积。</p>
<h3 id="2-7-1-垂直边缘检测器"><a href="#2-7-1-垂直边缘检测器" class="headerlink" title="2.7.1 垂直边缘检测器"></a>2.7.1 垂直边缘检测器</h3><p>为什么中间的这个3*3的矩阵可以做垂直边缘检测器呢？这里举例一个更加简单形象的例子。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/v2-bedd0b4720b7fc13ff00f2023b231097_r.jpg" class="" title="img">
<p>左边是一个简单的6<em>6的图像，右边的一半是像素值为10，右边一半像素值为0，这在图片中的效果就是，图片的左边看起来是白色的，因为10更接近255，那么图片的右边看起来是灰色的，右边像素值比较暗，我使用灰色来表示 0，尽管它也可以被画成黑的，但是这里为了举例，就画灰色的。有一个特别明显的垂直边缘在图像中间，<em>*蓝色垂直分割线</em></em>，从白色到深色的分割线，这也就是我们的垂直边缘特征。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/v2-941f580de5c7b425d3931ba357de403c_r.jpg" class="" title="img">
<p>灰度级图像的灰度级分布</p>
<p>那么对于我们的垂直边缘检测器而言，如上图，左边是明亮的像素，中间的是一个过渡，0是灰色，然后右边是深色的，经过卷积运算之后，得到的结果则是一个4<em>4的矩阵，当做图像来说就是，左边是灰色，中间是白色，右边是灰色，中间的这个白色就是亮一点的区域，可以看成是由亮向暗过渡，就是我们6</em>6的原图中间的<strong>蓝色垂直边缘</strong>，这是一个十分明显的<strong>垂直边缘</strong>，也就是<strong>原图中由亮到暗的过渡</strong>，这样我们就把图片的垂直边缘特征提取出来了。</p>
<p><strong>如果将图片进行了翻转，还能检测出来吗?</strong></p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/v2-75b876524407961c357643da1e417521_r.jpg" class="" title="img">
<p>原图它的颜色被翻转了，变成了左边比较暗，右边比较亮。现 在亮度为 10 的点跑到了右边，为 0  的点则跑到了左边。我们用用相同的锤之边缘过滤器进行卷积，最后得到的卷积结果矩阵图中间元素会是-30，而不是  30。如果你将矩阵转换为图片，就会是该矩阵下面 图片的样子。现在中间的过渡部分被翻转了，<strong>之前的 30 翻转成了-30，表明是由暗向亮过渡， 而不是由亮向暗过渡。</strong>那么如何检测水平边缘特征呢？水平边缘过滤器又是什么样子呢？</p>
<h3 id="2-7-2-水平边缘检测器"><a href="#2-7-2-水平边缘检测器" class="headerlink" title="2.7.2 水平边缘检测器"></a>2.7.2 水平边缘检测器</h3><p>我们看一个更加复杂的例子,假设原图是像素点值不是那么绝对对称那么是怎么,难想到我们的水平边缘检测器长下面中间的这个样子，它的上边相对较亮，下边相对较暗比较暗，中间是过渡的灰色。可以看做将垂直边缘检测器，九十度向右翻转得到。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/v2-b8e065c3998e0b02b487e13cc8307de2_r.jpg" class="" title="img">
<p>对于左边的这个原图中的绿色区域，它的上部是相对比较亮，向上的箭头，它的像素值为10，它的下部是相对较暗，像素值为0。卷积后的结果是右图的绿色的30，可以看到它的上部是较暗的，较亮的，说明这是由暗到亮的过渡，中间是有一条水平分割线的，这条分割线就是我们的水平边缘特征。</p>
<p><strong>哪有的是呈现角度的边缘特征呢？不一定都是水平和垂直特征，这又应该怎么进行检测呢？</strong></p>
<p>比如下面的这张美女图片，帽子的边缘特征呈现角度，对于这样的复杂边缘特征该如何进行检测呢？</p>
<p><strong><img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/v2-fbe68362b66bcff722475a1d1b337134_r.jpg" class="" title="img"></strong></p>
<p>事实上，上面提到的3<em>3的过滤器，也就是3</em>3的矩阵中的9个元素，在神经网络中事实上是9个参数，也就带参数的过滤器，我们可以任意组合，直至能够很好的检测到边缘特征。</p>
<p><strong>下面是Sobel算子的过滤器参数</strong>，分别实现水平、垂直、45度、135度图像边缘检测，可以看到参数都不一样，这种就叫做<strong>sobel过滤器,还有许许多多的检测器，也就是过滤器，其实还有180度边缘检测、270边缘检测等，只是卷积核，也就是过滤器参数的不同而已。</strong></p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/v2-15fc47c035e96b8e88ffd6b80a00bea8_r.jpg" class="" title="img">
<p>下图和上图是分别使用<strong>Sobel算子实现45度、135度角边缘检测效果</strong></p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/v2-dbad4af92483ffa9723aa712d5bf8759_r.jpg" class="" title="img">
<p>我们可以看到，45度和135度的边缘检测器效果更好。</p>
<p>垂直边缘检测和水平边缘检测的滤波器算子如下所示：</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422104617695.png" class="" title="在这里插入图片描述">
<p>除了上面提到的这种简单的Vertical、Horizontal滤波器之外，还有其它常用的filters，例如Sobel filter和Scharr filter。这两种滤波器的特点是增加图片中心区域的权重。（下图展示的是垂直边缘检测算子，水平边缘检测算子只需将上图顺时针翻转90度即可。）</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422105237527.png" class="" title="在这里插入图片描述">
<p>在深度学习中，如果我们想检测图像的各种边缘特征，而不仅限于垂直边缘和水平边缘，那么 filter 的数值一般需要通过模型训练得到，类似于标准神经网络中的权重 w w w 一样由反向传播算法迭代求得。CNN的主要目的就是计算出这些 filter 的数值。确定得到了这些 filter 后，CNN浅层网络也就实现了对图片所有边缘特征的检测。<br><img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/2020042210550658.png" class="" title="在这里插入图片描述"></p>
<h3 id="2-7-3-案例1——简单的黑白边界检测"><a href="#2-7-3-案例1——简单的黑白边界检测" class="headerlink" title="2.7.3 案例1——简单的黑白边界检测"></a>2.7.3 <strong>案例1——简单的黑白边界检测</strong></h3><p>下面是使用Conv2D算子完成一个图像边界检测的任务。图像左边为光亮部分，右边为黑暗部分，需要检测出光亮跟黑暗的分界处。</p>
<p>设置宽度方向的卷积核为[1,0,−1][1, 0, -1][1,0,−1]，此卷积核会将宽度方向间隔为1的两个像素点的数值相减。当卷积核在图片上滑动时，如果它所覆盖的像素点位于亮度相同的区域，则左右间隔为1的两个像素点数值的差为0。只有当卷积核覆盖的像素点有的处于光亮区域，有的处在黑暗区域时，左右间隔为1的两个点像素值的差才不为0。将此卷积核作用到图片上，输出特征图上只有对应黑白分界线的地方像素值才不为0。具体代码如下所示，结果输出在下方的图案中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> Conv2D</span><br><span class="line"><span class="keyword">from</span> paddle.nn.initializer <span class="keyword">import</span> Assign</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建初始化权重参数w</span></span><br><span class="line">w = np.array([<span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>], dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"><span class="comment"># 将权重参数调整成维度为[cout, cin, kh, kw]的四维张量</span></span><br><span class="line">w = w.reshape([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># 创建卷积算子，设置输出通道数，卷积核大小，和初始化权重参数</span></span><br><span class="line"><span class="comment"># kernel_size = [1, 3]表示kh = 1, kw=3</span></span><br><span class="line"><span class="comment"># 创建卷积算子的时候，通过参数属性weight_attr指定参数初始化方式</span></span><br><span class="line"><span class="comment"># 这里的初始化方式时，从numpy.ndarray初始化卷积参数</span></span><br><span class="line">conv = Conv2D(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, kernel_size=[<span class="number">1</span>, <span class="number">3</span>],</span><br><span class="line">       weight_attr=paddle.ParamAttr(</span><br><span class="line">          initializer=Assign(value=w)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建输入图片，图片左边的像素点取值为1，右边的像素点取值为0</span></span><br><span class="line">img = np.ones([<span class="number">50</span>,<span class="number">50</span>], dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">img[:, <span class="number">30</span>:] = <span class="number">0.</span></span><br><span class="line"><span class="comment"># 将图片形状调整为[N, C, H, W]的形式</span></span><br><span class="line">x = img.reshape([<span class="number">1</span>,<span class="number">1</span>,<span class="number">50</span>,<span class="number">50</span>])</span><br><span class="line"><span class="comment"># 将numpy.ndarray转化成paddle中的tensor</span></span><br><span class="line">x = paddle.to_tensor(x)</span><br><span class="line"><span class="comment"># 使用卷积算子作用在输入图片上</span></span><br><span class="line">y = conv(x)</span><br><span class="line"><span class="comment"># 将输出tensor转化为numpy.ndarray</span></span><br><span class="line">out = y.numpy()</span><br><span class="line">f = plt.subplot(<span class="number">121</span>)</span><br><span class="line">f.set_title(<span class="string">&#x27;input image&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">f = plt.subplot(<span class="number">122</span>)</span><br><span class="line">f.set_title(<span class="string">&#x27;output featuremap&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line"><span class="comment"># 卷积算子Conv2D输出数据形状为[N, C, H, W]形式</span></span><br><span class="line"><span class="comment"># 此处N, C=1，输出数据形状为[1, 1, H, W]，是4维数组</span></span><br><span class="line"><span class="comment"># 但是画图函数plt.imshow画灰度图时，只接受2维数组</span></span><br><span class="line"><span class="comment"># 通过numpy.squeeze函数将大小为1的维度消除</span></span><br><span class="line">plt.imshow(out.squeeze(), cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="2-7-4-案例2——图像中物体边缘检测"><a href="#2-7-4-案例2——图像中物体边缘检测" class="headerlink" title="2.7.4 案例2——图像中物体边缘检测"></a>2.7.4 <strong>案例2——图像中物体边缘检测</strong></h3><p>上面展示的是一个人为构造出来的简单图片，使用卷积网络检测图片明暗分界处的示例。对于真实的图片，也可以使用合适的卷积核(3*3卷积核的中间值是8，周围一圈的值是8个-1)对其进行操作，用来检测物体的外形轮廓，观察输出特征图跟原图之间的对应关系，如下代码所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> Conv2D</span><br><span class="line"><span class="keyword">from</span> paddle.nn.initializer <span class="keyword">import</span> Assign</span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&#x27;./work/images/section1/000000098520.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置卷积核参数</span></span><br><span class="line">w = np.array([[-<span class="number">1</span>,-<span class="number">1</span>,-<span class="number">1</span>], [-<span class="number">1</span>,<span class="number">8</span>,-<span class="number">1</span>], [-<span class="number">1</span>,-<span class="number">1</span>,-<span class="number">1</span>]], dtype=<span class="string">&#x27;float32&#x27;</span>)/<span class="number">8</span></span><br><span class="line">w = w.reshape([<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># 由于输入通道数是3，将卷积核的形状从[1,1,3,3]调整为[1,3,3,3]</span></span><br><span class="line">w = np.repeat(w, <span class="number">3</span>, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 创建卷积算子，输出通道数为1，卷积核大小为3x3，</span></span><br><span class="line"><span class="comment"># 并使用上面的设置好的数值作为卷积核权重的初始化参数</span></span><br><span class="line">conv = Conv2D(in_channels=<span class="number">3</span>, out_channels=<span class="number">1</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], </span><br><span class="line">            weight_attr=paddle.ParamAttr(</span><br><span class="line">              initializer=Assign(value=w)))</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 将读入的图片转化为float32类型的numpy.ndarray</span></span><br><span class="line">x = np.array(img).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"><span class="comment"># 图片读入成ndarry时，形状是[H, W, 3]，</span></span><br><span class="line"><span class="comment"># 将通道这一维度调整到最前面</span></span><br><span class="line">x = np.transpose(x, (<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 将数据形状调整为[N, C, H, W]格式</span></span><br><span class="line">x = x.reshape(<span class="number">1</span>, <span class="number">3</span>, img.height, img.width)</span><br><span class="line">x = paddle.to_tensor(x)</span><br><span class="line">y = conv(x)</span><br><span class="line">out = y.numpy()</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">f = plt.subplot(<span class="number">121</span>)</span><br><span class="line">f.set_title(<span class="string">&#x27;input image&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.imshow(img)</span><br><span class="line">f = plt.subplot(<span class="number">122</span>)</span><br><span class="line">f.set_title(<span class="string">&#x27;output feature map&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.imshow(out.squeeze(), cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128154509543.png" class="" title="image-20231128154509543">
<h3 id="2-7-5-案例3——图像均值模糊"><a href="#2-7-5-案例3——图像均值模糊" class="headerlink" title="2.7.5 案例3——图像均值模糊"></a>2.7.5 <strong>案例3——图像均值模糊</strong></h3><p>另外一种比较常见的卷积核（5*5的卷积核中每个值均为1）是用当前像素跟它邻域内的像素取平均，这样可以使图像上噪声比较大的点变得更平滑，如下代码所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> Conv2D</span><br><span class="line"><span class="keyword">from</span> paddle.nn.initializer <span class="keyword">import</span> Assign</span><br><span class="line"><span class="comment"># 读入图片并转成numpy.ndarray</span></span><br><span class="line"><span class="comment"># 换成灰度图</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&#x27;./work/images/section1/000000355610.jpg&#x27;</span>).convert(<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line">img = np.array(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建初始化参数</span></span><br><span class="line">w = np.ones([<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>], dtype = <span class="string">&#x27;float32&#x27;</span>)/<span class="number">25</span></span><br><span class="line">conv = Conv2D(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, kernel_size=[<span class="number">5</span>, <span class="number">5</span>], </span><br><span class="line">        weight_attr=paddle.ParamAttr(</span><br><span class="line">         initializer=Assign(value=w)))</span><br><span class="line">x = img.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x = x.reshape(<span class="number">1</span>,<span class="number">1</span>,img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>])</span><br><span class="line">x = paddle.to_tensor(x)</span><br><span class="line">y = conv(x)</span><br><span class="line">out = y.numpy()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">12</span>))</span><br><span class="line">f = plt.subplot(<span class="number">121</span>)</span><br><span class="line">f.set_title(<span class="string">&#x27;input image&#x27;</span>)</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">f = plt.subplot(<span class="number">122</span>)</span><br><span class="line">f.set_title(<span class="string">&#x27;output feature map&#x27;</span>)</span><br><span class="line">out = out.squeeze()</span><br><span class="line">plt.imshow(out, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128154552997.png" class="" title="image-20231128154552997">
<h2 id="2-8-单层卷积网络"><a href="#2-8-单层卷积网络" class="headerlink" title="2.8 单层卷积网络"></a>2.8 单层卷积网络</h2><p>（One layer of a convolutional network）</p>
<p>卷积神经网络的单层结构如下所示：</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422151012841.png" class="" title="卷积神经网络的单层结构如下所示：">
<p> 相比之前单独的卷积过程，<strong>CNN的单层结构多了激活函数ReLU和偏移量b</strong>。整个过程与标准的神经网络单层结构非常类似：</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231220103625936.png" class="" title="image-20231220103625936">                                                         
<p>卷积运算对应着上式中的乘积运算，滤波器组数值对应着权重 $W^{[1]}$ ，所选的激活函数为ReLU。</p>
<p>我们来计算一下上图中参数的数目：每个滤波器组有3x3x3=27个参数，还有1个偏移量b，则每个滤波器组有27+1=28个参数，两个滤波器组总共包含28×2=56个参数。我们发现，选定滤波器组后，参数数目与输入图片尺寸无关。所以，就不存在由于图片尺寸过大，造成参数过多的情况。例如一张1000x1000x3的图片，标准神经网络输入层的维度将达到3百万，而在CNN中，参数数目只由滤波器组决定，数目相对来说要少得多，这是CNN的优势之一。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231220103838108.png" class="" title="image-20231220103838108">
<h2 id="2-9-简单卷积网络示例"><a href="#2-9-简单卷积网络示例" class="headerlink" title="2.9 简单卷积网络示例"></a>2.9 简单卷积网络示例</h2><p>（A simple convolution network example）</p>
<p>下面介绍一个简单的CNN网络模型（计算过程见上节公式）：</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422162305516.png" class="" title="在这里插入图片描述">
<p>$a^{[3]}$的维度是$7 x 7 x 40$，将$a^{[3]}$排列成1列，维度为$1960 x 1$，然后连接最后一级输出层。输出层可以是一个神经元，即二元分类（logistic）；也可以是多个神经元，即多元分类（softmax）。最后得到预测输出$\hat y$</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231220111307410.png" class="" title="image-20231220111307410">
<p>一个典型的卷积神经网络通常有三层：</p>
<ul>
<li>卷积层：Convolution layers（<strong>CONV</strong>）</li>
<li>池化层：Pooling layers（<strong>POOL</strong>）</li>
<li>全连接层：Fully connected layers（<strong>FC</strong>）</li>
</ul>
<h2 id="2-10-池化（Pooling）"><a href="#2-10-池化（Pooling）" class="headerlink" title="2.10 池化（Pooling）"></a>2.10 池化（Pooling）</h2><p>池化是使用某一位置的相邻输出的总体统计特征代替网络在该位置的输出，其好处是当输入数据做出少量平移时，经过池化函数后的大多数输出还能保持不变。比如：当识别一张图像是否是人脸时，我们需要知道人脸左边有一只眼睛，右边也有一只眼睛，而不需要知道眼睛的精确位置，这时候通过池化某一片区域的像素点来得到总体统计特征会显得很有用。由于池化之后特征图会变得更小，如果后面连接的是全连接层，能有效的减小神经元的个数，节省存储空间并提高计算效率。 如 <strong>图15</strong> 所示，将一个$2*2$的区域池化成一个像素点。通常有两种方法，平均池化和最大池化。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/5479daa3734d424bb710615d3c4f7e017ba2558808a8421ca7c914f3fced0a48.png" class="" title="img">
<ul>
<li>如图15（a）：平均池化。这里使用大小为$2*2$的池化窗口，每次移动的步幅为2，对池化窗口覆盖区域内的像素取平均值，得到相应的输出特征图的像素值。</li>
<li>如图15（b）：最大池化。对池化窗口覆盖区域内的像素取最大值，得到输出特征图的像素值。当池化窗口在图片上滑动时，会得到整张输出特征图。池化窗口的大小称为池化大小，用$k_h <em> k_w$表示。在卷积神经网络中用的比较多的是窗口大小为$2</em>2$，步幅为2的池化。</li>
</ul>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128154751593.png" class="" title="image-20231128154751593">
<p>（Pooling layers）</p>
<p>Pooling layers是CNN中用来减小尺寸，提高运算速度的，同样能减小noise影响，让各特征更具有健壮性。</p>
<p>Pooling layers 的做法比 Convolution layers 简单许多，没有卷积运算，仅仅是在滤波器算子滑动区域内取最大值，即max pooling，这是最常用的做法。(我的理解是类似于降采样)</p>
<p>注意，超参数p(padding)很少在pooling layers中使用。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422174655532.png" class="" title="在这里插入图片描述">
<p>Max pooling的好处是只保留区域内的最大值（特征)，忽略其它值，降低noise影响，提高模型健壮性。而且，max pooling需要的超参数仅为滤波器尺寸 f f f 和滤波器步长 s s s，没有其他参数需要模型训练得到，计算量很小。</p>
<p>如果是多个通道，那么就每个通道单独进行max pooling操作。</p>
<p>除了max pooling之外，还有一种做法：average pooling。顾名思义，average pooling就是在滤波器算子滑动区域计算平均值。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422175445969.png" class="" title="在这里插入图片描述">
<p>实际应用中，max pooling比average pooling更为常用。</p>
<h2 id="2-1-激活函数"><a href="#2-1-激活函数" class="headerlink" title="2.1 激活函数"></a>2.1 激活函数</h2><p>前面介绍的网络结构中，普遍使用Sigmoid函数做激活函数。在神经网络发展的早期，Sigmoid函数用的比较多，而目前用的较多的激活函数是ReLU。这是因为Sigmoid函数在反向传播过程中，容易造成梯度的衰减。让我们仔细观察Sigmoid函数的形式，就能发现这一问题。</p>
<p>Sigmoid激活函数定义如下：<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155010318.png" class="" title="image-20231128155010318"></p>
<p>ReLU激活函数的定义如下：<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155032340.png" class="" title="image-20231128155032340"></p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155046800.png" class="" title="image-20231128155046800">
<p><strong>梯度消失现象</strong></p>
<p>在神经网络里，将经过反向传播之后，梯度值衰减到接近于零的现象称作梯度消失现象。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155152504.png" class="" title="image-20231128155152504">
<h2 id="2-12-批归一化（Batch-Normalization）"><a href="#2-12-批归一化（Batch-Normalization）" class="headerlink" title="2.12 批归一化（Batch Normalization）"></a>2.12 批归一化（Batch Normalization）</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.03167">批归一化方法</a>（Batch Normalization，BatchNorm）是由Ioffe和Szegedy于2015年提出的，已被广泛应用在深度学习中，其目的是对神经网络中间层的输出进行标准化处理，使得中间层的输出更加稳定。</p>
<p>通常我们会对神经网络的数据进行标准化处理，处理后的样本数据集满足均值为0，方差为1的统计分布，这是因为当输入数据的分布比较固定时，有利于算法的稳定和收敛。对于深度神经网络来说，由于参数是不断更新的，即使输入数据已经做过标准化处理，但是对于比较靠后的那些层，其接收到的输入仍然是剧烈变化的，通常会导致数值不稳定，模型很难收敛。BatchNorm能够使神经网络中间层的输出变得更加稳定，并有如下三个优点：</p>
<ul>
<li>使学习快速进行（能够使用较大的学习率）</li>
<li>降低模型对初始值的敏感性</li>
<li>从一定程度上抑制过拟合</li>
</ul>
<p>BatchNorm主要思路是在训练时以mini-batch为单位，对神经元的数值进行归一化，使数据的分布满足均值为0，方差为1。具体计算过程如下：</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155343278-170115803374231.png" class="" title="image-20231128155343278">
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155402167.png" class="" title="image-20231128155402167">
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155439041.png" class="" title="image-20231128155439041">
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155554779.png" class="" title="image-20231128155554779">
<h2 id="2-13-丢弃法（Dropout）"><a href="#2-13-丢弃法（Dropout）" class="headerlink" title="2.13 丢弃法（Dropout）"></a>2.13 丢弃法（Dropout）</h2><p>丢弃法（Dropout）是深度学习中一种常用的抑制过拟合的方法，其做法是在神经网络学习过程中，随机删除一部分神经元。训练时，随机选出一部分神经元，将其输出设置为0，这些神经元将不对外传递信号。</p>
<p><strong>图16</strong> 是Dropout示意图，左边是完整的神经网络，右边是应用了Dropout之后的网络结构。应用Dropout之后，会将标了×\times×的神经元从网络中删除，让它们不向后面的层传递信号。在学习过程中，丢弃哪些神经元是随机决定，因此模型不会过度依赖某些神经元，能一定程度上抑制过拟合。</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/image-20231128155615806.png" class="" title="image-20231128155615806">
<h2 id="2-14-卷积神经网络示例"><a href="#2-14-卷积神经网络示例" class="headerlink" title="2.14 卷积神经网络示例"></a>2.14 卷积神经网络示例</h2><p>（Convolutional neural network example）</p>
<p>下面介绍一个简单的数字识别的CNN例子：</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422182001606.png" class="" title="在这里插入图片描述">
<p>图中，CONV层后面紧接一个POOL层，<strong>CONV1 和 POOL1 构成Layer1</strong>，<strong>CONV2 和 POOL2 构成 Layer2</strong>（一般在统计网络层数时，只计算具有权重的层，因为池化层没有权重和参数，只有一些超参数。因此我们把CONV1和POOL1共同作为一个卷积，并标记为Layer1）。</p>
<p>特别注意的是FC3和FC4为全连接层FC，它跟标准的神经网络结构一致。最后的输出层（softmax）由10个神经元构成。</p>
<p>整个网络各层的尺寸和参数如下表格所示</p>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200422182214965.png" class="" title="在这里插入图片描述">
<p>有几点要注意，第一，池化层和最大池化层没有参数；第二，卷积层的参数相对较少，前面课上我们提到过，其实许多参数都存在于神经网络的全连接层。</p>
<p>观察可发现，随着神经网络的加深，激活值尺寸会逐渐变小，如果激活值尺寸下降太快，也会影响神经网络性能。示例中，激活值尺寸在第一层为6000，然后减少到1600，慢慢减少到84，最后输出softmax结果。我们发现，许多卷积网络都具有这些属性，模式上也相似。</p>
<h2 id="2-15-为什么使用卷积？"><a href="#2-15-为什么使用卷积？" class="headerlink" title="2.15 为什么使用卷积？"></a>2.15 为什么使用卷积？</h2><p>（Why convolutions?）</p>
<p>相比标准神经网络，CNN的优势之一就是参数数目要少得多。参数数目少的原因有两个：</p>
<ul>
<li>参数共享：一个特征检测器（例如垂直边缘检测）对图片某块区域有用，同时也可能作用在图片其它区域。</li>
<li>局部感知：因为滤波器算子尺寸限制，每一层的每个输出只与输入部分区域内有关。</li>
</ul>
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/202006281600100.png" class="" title="在这里插入图片描述">
<img src="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/20200628160103118.png" class="" title="在这里插入图片描述">
<p> 除此之外，由于CNN参数数目较小，所需的训练样本就相对较少，从而一定程度上不容易发生过拟合现象。而且，CNN比较擅长捕捉区域位置偏移。也就是说CNN进行物体检测时，不太受物体所处图片位置的影响，增加检测的准确性和系统的健壮性。</p>
<h1 id="附录："><a href="#附录：" class="headerlink" title="附录："></a>附录：</h1><ul>
<li><a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/tutorials/projectdetail/4282406">零基础实践深度学习第三章：计算机视觉（上）卷积神经网络基础</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_37867091/article/details/105462334?spm=1001.2014.3001.5501">CNN基础</a></li>
<li></li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>奔跑的IC
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://example.com/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/" title="卷积神经网络基础">http://example.com/DeepLearning/基础/卷积神经网络基础/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/C/" rel="tag"><i class="fa fa-tag"></i> C</a>
              <a href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag"><i class="fa fa-tag"></i> 卷积神经网络</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%85%B3%E4%BA%8Eonnx%E7%9A%84resize%E5%B1%82/" rel="prev" title="关于onnx的resize层">
                  <i class="fa fa-chevron-left"></i> 关于onnx的resize层
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/DeepLearning/%E5%9F%BA%E7%A1%80/%E5%8F%8C%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC/" rel="next" title="双线性插值">
                  双线性插值 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">奔跑的IC</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div><script color="0,0,255" opacity="0.5" zIndex="-1" count="99" src="https://lib.baomitu.com/canvas-nest.js/1.0.1/canvas-nest.js"></script>


    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"zmurder","repo":"zmurder.github.io","client_id":"cf2343f27b6c29efe0bc","client_secret":"3268a1fa92706c7358d5421f88f76a0f7ada3188","admin_user":"zmurder","distraction_free_mode":true,"proxy":"https://strong-caramel-969805.netlify.app/github_access_token","language":"zh-CN","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"6af0a0ef67ebd764decccc2b65f6ca99"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
