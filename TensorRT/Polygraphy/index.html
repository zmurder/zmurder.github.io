<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8693861384618000"
     crossorigin="anonymous"></script>
  <meta name="msvalidate.01" content="7EC20DBC74B004C2782077570E15C280">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.14.2","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8693861384618000"
     crossorigin="anonymous"></script>
    <meta name="description" content="1 简介翻译自官网 https:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;TensorRT&#x2F;blob&#x2F;main&#x2F;tools&#x2F;Polygraphy&#x2F;README.md">
<meta property="og:type" content="article">
<meta property="og:title" content="Polygraphy">
<meta property="og:url" content="http://example.com/TensorRT/Polygraphy/index.html">
<meta property="og:site_name" content="奔跑的IC">
<meta property="og:description" content="1 简介翻译自官网 https:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;TensorRT&#x2F;blob&#x2F;main&#x2F;tools&#x2F;Polygraphy&#x2F;README.md">
<meta property="og:locale">
<meta property="article:published_time" content="2024-12-01T10:13:45.314Z">
<meta property="article:modified_time" content="2024-12-01T10:13:45.314Z">
<meta property="article:author" content="奔跑的IC">
<meta property="article:tag" content="git">
<meta property="article:tag" content="C">
<meta property="article:tag" content="Tensorrt">
<meta property="article:tag" content="DeepLearning">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/TensorRT/Polygraphy/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-Hans","comments":true,"permalink":"http://example.com/TensorRT/Polygraphy/","path":"TensorRT/Polygraphy/","title":"Polygraphy"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Polygraphy | 奔跑的IC</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">奔跑的IC</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-reorder fa-fw"></i>文章列表</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-%E7%AE%80%E4%BB%8B"><span class="nav-text">1 简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-%E5%AE%89%E8%A3%85"><span class="nav-text">2 安装</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Installing-Prebuilt-Wheels"><span class="nav-text">Installing Prebuilt Wheels</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8E%E6%BA%90%E7%A0%81%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85"><span class="nav-text">从源码包编译安装</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8Make-Targets-Linux"><span class="nav-text">使用Make Targets (Linux)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Using-Powershell-Script-Windows"><span class="nav-text">Using Powershell Script (Windows)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E6%9E%84%E5%BB%BA"><span class="nav-text">手动构建</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-%E8%B0%83%E8%AF%95TensorRT%E7%B2%BE%E5%BA%A6%E9%97%AE%E9%A2%98"><span class="nav-text">3 调试TensorRT精度问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-%E7%9C%9F%E5%AE%9E%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E4%BC%9A%E4%BA%A7%E7%94%9F%E5%BD%B1%E5%93%8D%E5%90%97%EF%BC%9F"><span class="nav-text">3.1 真实输入数据会产生影响吗？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-%E9%97%B4%E6%AD%87%E6%80%A7%E8%BF%98%E6%98%AF%E9%9D%9E%E9%97%B4%E6%AD%87%E6%80%A7%EF%BC%9F"><span class="nav-text">3.2 间歇性还是非间歇性？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-%E8%B0%83%E8%AF%95%E9%97%B4%E6%AD%87%E6%80%A7%E7%B2%BE%E5%BA%A6%E9%97%AE%E9%A2%98"><span class="nav-text">3.3 调试间歇性精度问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-4-%E5%88%86%E5%B1%82%E6%98%AF%E4%B8%80%E4%B8%AA%E9%80%89%E6%8B%A9%E5%90%97"><span class="nav-text">3.4 分层是一个选择吗</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-5-%E6%8F%90%E5%8F%96%E5%A4%B1%E8%B4%A5%E5%AD%90%E5%9B%BE"><span class="nav-text">3.5 提取失败子图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-6-%E5%87%8F%E5%B0%91%E5%A4%B1%E8%B4%A5%E7%9A%84ONNX%E6%A8%A1%E5%9E%8B"><span class="nav-text">3.6 减少失败的ONNX模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-7-%E9%87%8D%E5%A4%8D%E6%A3%80%E6%9F%A5%E6%82%A8%E7%9A%84%E5%87%8F%E5%B0%91%E9%80%89%E9%A1%B9"><span class="nav-text">3.7 重复检查您的减少选项</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-8-%E4%BD%A0%E6%9C%89%E4%B8%80%E4%B8%AA%E6%9C%80%E5%B0%8F%E7%9A%84%E5%A4%B1%E8%B4%A5%E6%A1%88%E4%BE%8B%EF%BC%81"><span class="nav-text">3.8 你有一个最小的失败案例！</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-9-run-example"><span class="nav-text">3.9 run example</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#example-01-%E6%AF%94%E8%BE%83%E6%A1%86%E6%9E%B6"><span class="nav-text">example 01 比较框架</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Introduction"><span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E7%A4%BA%E4%BE%8B"><span class="nav-text">运行示例</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%AF%94%E8%BE%83TensorRT%E5%92%8CONNX%E8%BF%90%E8%A1%8C%E6%97%B6%E8%BE%93%E5%87%BA"><span class="nav-text">比较TensorRT和ONNX运行时输出</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#example-05-%E4%B8%8E%E8%87%AA%E5%AE%9A%E4%B9%89%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E6%AF%94%E8%BE%83"><span class="nav-text">example 05 与自定义输入数据比较</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Introduction-1"><span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E7%A4%BA%E4%BE%8B-1"><span class="nav-text">运行示例</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-10-debug-example"><span class="nav-text">3.10 debug example</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#example-01-%E8%B0%83%E8%AF%95Flaky-TensorRT%E7%AD%96%E7%95%A5"><span class="nav-text">example 01 调试Flaky TensorRT策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Introduction-2"><span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E7%A4%BA%E4%BE%8B-2"><span class="nav-text">运行示例</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%99%84%E5%BD%95"><span class="nav-text">附录</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="奔跑的IC"
      src="/images/zyd.gif">
  <p class="site-author-name" itemprop="name">奔跑的IC</p>
  <div class="site-description" itemprop="description">死磕牛角的IT农民工</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">153</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/TensorRT/Polygraphy/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zyd.gif">
      <meta itemprop="name" content="奔跑的IC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="奔跑的IC">
      <meta itemprop="description" content="死磕牛角的IT农民工">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Polygraphy | 奔跑的IC">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Polygraphy
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-01 18:13:45" itemprop="dateCreated datePublished" datetime="2024-12-01T18:13:45+08:00">2024-12-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/TensorRT/" itemprop="url" rel="index"><span itemprop="name">TensorRT</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h1><p>翻译自官网 <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/README.md">https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/README.md</a></p>
<p>Polygraphy是一个工具包，旨在帮助在TensorRT和其他框架中运行和调试深度学习模型。它包括一个 <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/polygraphy">Python API</a> 和一个 <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/polygraphy/tools">a command-line interface (CLI)</a>）。</p>
<p>除其他外，使用Polygraphy，您可以：</p>
<ul>
<li>在多个后端之间运行推理，如TensorRT和ONNX-Runtime，并比较结果(for example <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/api/01_comparing_frameworks">API</a>,<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/run/01_comparing_frameworks">CLI</a>).                              </li>
<li>将模型转换为各种格式，例如带有训练后量化的TensorRT引擎 (for example <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/api/04_int8_calibration_in_tensorrt">API</a>,<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/convert/01_int8_calibration_in_tensorrt">CLI</a>).                              </li>
<li>查看有关各种类型模型的信息 (for example <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/inspect">CLI</a>)                              </li>
<li>在命令行上修改ONNX模型：</li>
<li>提取子图(for example <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/surgeon/01_isolating_subgraphs">CLI</a>).                                    </li>
<li>简化和净化 (for example <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/surgeon/02_folding_constants">CLI</a>).                                    </li>
<li>隔离TensorRT中的错误策略 (for example <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/debug/01_debugging_flaky_trt_tactics">CLI</a>).                              </li>
</ul>
<p>有关更多详细信息，请参阅 <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/tree/main/tools/Polygraphy">Polygraphy repository</a>.                     </p>
<h1 id="2-安装"><a href="#2-安装" class="headerlink" title="2 安装"></a>2 安装</h1><p>重要提示：Polygraphy仅支持Python 3.6及更高版本。在遵循以下说明之前，请确保您使用的是受支持的Python版本。</p>
<h2 id="Installing-Prebuilt-Wheels"><a href="#Installing-Prebuilt-Wheels" class="headerlink" title="Installing Prebuilt Wheels"></a>Installing Prebuilt Wheels</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m pip install colored polygraphy --extra-index-url https://pypi.ngc.nvidia.com</span><br></pre></td></tr></table></figure>
<p>注意：在Linux上，默认情况下，命令行工具包通常安装到${HOME}/.local/bin。请确保将此目录添加到PATH环境变量中。</p>
<h2 id="从源码包编译安装"><a href="#从源码包编译安装" class="headerlink" title="从源码包编译安装"></a>从源码包编译安装</h2><h3 id="使用Make-Targets-Linux"><a href="#使用Make-Targets-Linux" class="headerlink" title="使用Make Targets (Linux)"></a>使用Make Targets (Linux)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make install</span><br></pre></td></tr></table></figure>
<h3 id="Using-Powershell-Script-Windows"><a href="#Using-Powershell-Script-Windows" class="headerlink" title="Using Powershell Script (Windows)"></a>Using Powershell Script (Windows)</h3><p>确保允许您在系统上执行脚本，然后运行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\install.ps1</span><br></pre></td></tr></table></figure>
<h3 id="手动构建"><a href="#手动构建" class="headerlink" title="手动构建"></a>手动构建</h3><ul>
<li><p>安装先决条件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m pip install wheel</span><br></pre></td></tr></table></figure>
</li>
<li><p>Build a wheel:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py bdist_wheel</span><br></pre></td></tr></table></figure>
</li>
<li><p>从存储库手动安装wheel </p>
<p>On Linux, run:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m pip install Polygraphy/dist/polygraphy-*-py2.py3-none-any.whl</span><br></pre></td></tr></table></figure>
<p>On Windows, using Powershell, run:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$wheel_path</span> = gci -Name Polygraphy\dist</span><br><span class="line">python -m pip install Polygraphy\dist\<span class="variable">$wheel_path</span></span><br></pre></td></tr></table></figure>
<p>注：强烈建议为Polygraphy的彩色输出安装彩色模块，因为这可以大大提高可读性：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m pip install colored</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="3-调试TensorRT精度问题"><a href="#3-调试TensorRT精度问题" class="headerlink" title="3 调试TensorRT精度问题"></a>3 调试TensorRT精度问题</h1><p>参考：<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/how-to/debug_accuracy.md">https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/how-to/debug_accuracy.md</a></p>
<p>TensorRT中的准确性问题，尤其是在大型网络中，调试起来可能很有挑战性。使它们易于管理的一种方法是缩小问题的规模或找出故障的根源。</p>
<p>本指南旨在提供这样做的一般方法；它的结构是一个扁平的流程图——在每个分支上，都提供了两个链接，因此您可以选择最适合您的情况的链接。</p>
<p>如果您使用的是ONNX型号，请在继续操作之前尝试<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/surgeon/02_folding_constants">sanitizing it</a> ，因为这在某些情况下可能会解决问题。</p>
<h2 id="3-1-真实输入数据会产生影响吗？"><a href="#3-1-真实输入数据会产生影响吗？" class="headerlink" title="3.1 真实输入数据会产生影响吗？"></a>3.1 真实输入数据会产生影响吗？</h2><p>某些模型可能对输入数据敏感。例如，实际输入可能比随机生成的输入具有更好的准确性。Polygraphy提供了多种提供真实输入数据的方法，如<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/run/05_comparing_with_custom_input_data"><code>run</code> example 05</a>.所述。</p>
<p>使用真实的输入数据是否可以提高准确性？</p>
<ul>
<li><p>是的，使用真实输入数据时，准确性是可以接受的。</p>
<p>这可能意味着没有bug；相反，您的模型对输入数据很敏感。</p>
</li>
<li><p>不，即使使用真实的输入数据，我仍然会看到准确性问题。</p>
<p>转至：间歇性或不间歇性？（下面3,2）</p>
</li>
</ul>
<h2 id="3-2-间歇性还是非间歇性？"><a href="#3-2-间歇性还是非间歇性？" class="headerlink" title="3.2 间歇性还是非间歇性？"></a>3.2 间歇性还是非间歇性？</h2><p>这个问题在不同的引擎之间是间歇性的吗?</p>
<ul>
<li><p>是的，有时当我重建引擎时，准确性问题就消失了。</p>
<p>转到：调试间歇性精度问题（下面3,3）</p>
</li>
<li><p>不，我每次构建引擎时都会看到准确性问题。</p>
<p>转到:分层是一个选项（下面3.4）</p>
</li>
</ul>
<h2 id="3-3-调试间歇性精度问题"><a href="#3-3-调试间歇性精度问题" class="headerlink" title="3.3 调试间歇性精度问题"></a>3.3 调试间歇性精度问题</h2><p>由于引擎构建过程是不确定的，因此每次构建引擎时都可以选择不同的策略（即层实现）。当其中一种策略出现故障时，这可能表现为间歇性故障。Polygraphy包括一个调试构建子工具，可以帮助您找到这样的策略。</p>
<p>有关更多信息，请参阅<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/debug/01_debugging_flaky_trt_tactics"><code>debug</code> example 01</a>.。</p>
<p>你找到失败的策略了吗</p>
<ul>
<li><p>是的，我知道哪种策略是错误的。</p>
<p>转到：你有一个最小的失败案例！（下 3.8）</p>
</li>
<li><p>否，故障可能不是间歇性的。</p>
<p>转到：分层是一种选择吗？（下3,4）</p>
</li>
</ul>
<h2 id="3-4-分层是一个选择吗"><a href="#3-4-分层是一个选择吗" class="headerlink" title="3.4 分层是一个选择吗"></a>3.4 分层是一个选择吗</h2><p>如果精度问题始终是可重复的，那么最好的下一步是找出导致故障的层。Polygraphy包括一种机制，将网络中的所有张量标记为输出，以便进行比较；然而，这可能会潜在地影响TensorRT的优化过程。因此，我们需要确定当所有输出张量都被标记时，我们是否仍然观察到准确性问题。</p>
<p>有关如何在继续之前比较每层输出的详细信息，请参阅 <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/run/01_comparing_frameworks/README.md#comparing-per-layer-outputs-between-onnx-runtime-and-tensorrt">this example</a>。</p>
<p>在比较逐层输出时，您是否能够重现精度故障？</p>
<ul>
<li><p>是的，即使我在网络中标记了其他输出，故障也会重新处理。</p>
<p>转到：提取失败的子图（下 3.5）</p>
</li>
<li><p>不，标记其他输出会导致精度提高，或者当我标记其他输出时，我根本无法运行模型。</p>
<p>转到：减少失败的Onnx模型（下 3.6）</p>
</li>
</ul>
<h2 id="3-5-提取失败子图"><a href="#3-5-提取失败子图" class="headerlink" title="3.5 提取失败子图"></a>3.5 提取失败子图</h2><p>由于我们能够比较各层的输出，因此我们应该能够通过查看输出比较日志来确定哪个层首先引入了错误。一旦我们知道哪一层有问题，我们就可以从模型中提取它。</p>
<p>为了计算出所讨论的层的输入和输出张量，我们可以使用<code>polygraphy inspect model</code>检查模型。有关详细信息，请参阅其中一个示例：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/inspect/01_inspecting_a_tensorrt_network">TensorRT Networks</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/inspect/03_inspecting_an_onnx_model">ONNX models</a>.</li>
</ul>
<p>接下来，我们可以提取一个子图，只包括有问题的层。有关更多信息，请参阅<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/surgeon/01_isolating_subgraphs"><code>surgeon</code> example 01</a>.1。</p>
<p>这个孤立的子图是否再现了问题？</p>
<ul>
<li><p>是的，子图也失败了。</p>
<p>转到：你有一个最小的失败案例！（下 3.8）</p>
</li>
<li><p>不，子图工作得很好。</p>
<p>转到：减少失败的Onnx模型（下 3,6）</p>
</li>
</ul>
<h2 id="3-6-减少失败的ONNX模型"><a href="#3-6-减少失败的ONNX模型" class="headerlink" title="3.6 减少失败的ONNX模型"></a>3.6 减少失败的ONNX模型</h2><p>当我们无法使用分层比较来确定故障源时，我们可以使用蛮力方法来减少ONNX模型——迭代生成越来越小的子图，以找到仍然失败的最小子图。<code>debug reduce</code>工具有助于实现这一过程的自动化。</p>
<p>有关更多信息，请参阅<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/debug/02_reducing_failing_onnx_models"><code>ebug</code> example 02</a>。</p>
<p>简化模型是否失败？</p>
<ul>
<li><p>是的，精简模型失败了。</p>
<p>转到：你有一个最小的失败案例！（下 3.8）</p>
</li>
<li><p>不，简化模型不会失败，或者以不同的方式失败。</p>
<p>转到：重复检查您的减少选项（下 3.7）</p>
</li>
</ul>
<h2 id="3-7-重复检查您的减少选项"><a href="#3-7-重复检查您的减少选项" class="headerlink" title="3.7 重复检查您的减少选项"></a>3.7 重复检查您的减少选项</h2><p>如果精简模型不再失败，或者以其他方式失败，请确保<code>--check</code>命令是正确的。您可能还想使用<code>--fail regex</code>来确保在减少模型时只考虑准确性故障（而不是其他无关的故障）。</p>
<ul>
<li><p>再次尝试减少。</p>
<p>转到：减少失败的Onnx模型（3.6）</p>
</li>
</ul>
<h2 id="3-8-你有一个最小的失败案例！"><a href="#3-8-你有一个最小的失败案例！" class="headerlink" title="3.8 你有一个最小的失败案例！"></a>3.8 你有一个最小的失败案例！</h2><p>如果你已经做到了这一点，那么你现在就有了一个最小的失败案例！进一步的调试应该更容易。</p>
<p>如果您是TensorRT开发人员，那么此时您需要深入研究代码。如果没有，请报告您的错误！</p>
<h2 id="3-9-run-example"><a href="#3-9-run-example" class="headerlink" title="3.9 run example"></a>3.9 run example</h2><h3 id="example-01-比较框架"><a href="#example-01-比较框架" class="headerlink" title="example 01 比较框架"></a>example 01 比较框架</h3><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>您可以使用<code>run</code>子工具来比较不同框架之间的模型。在最简单的情况下，您可以提供一个模型和一个或多个框架标志。默认情况下，它将生成合成输入数据，使用指定的框架运行推理，然后比较指定框架的输出。</p>
<h4 id="运行示例"><a href="#运行示例" class="headerlink" title="运行示例"></a>运行示例</h4><p>在本例中，我们将概述<code>run</code>子工具的各种常见用例：</p>
<ul>
<li>比较TensorRT和ONNX运行时输出</li>
<li>TensorRT精度比较</li>
<li>更改公差</li>
<li>更改比较度量</li>
<li>ONNX Runtime和TensorRT的逐层输出比较</li>
</ul>
<h5 id="比较TensorRT和ONNX运行时输出"><a href="#比较TensorRT和ONNX运行时输出" class="headerlink" title="比较TensorRT和ONNX运行时输出"></a>比较TensorRT和ONNX运行时输出</h5><p>要在Polygraphy中使用两个框架运行模型并执行输出比较：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">polygraphy run dynamic_identity.onnx --trt --onnxrt</span><br></pre></td></tr></table></figure>
<p><code>dynamic_identity.onnx</code>模型具有动态输入形状。默认情况下，<code>Polygraphy</code>会将模型中的任何动态输入尺寸覆盖为常量。DEFAULT_SHAPE_VALUE（定义为1）并警告您：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[W]     Input tensor: X (dtype=DataType.FLOAT, shape=(1, 2, -1, -1)) | No shapes provided; Will use shape: [1, 2, 1, 1] <span class="keyword">for</span> min/opt/max <span class="keyword">in</span> profile.</span><br><span class="line">[W]     This will cause the tensor to have a static shape. If this is incorrect, please <span class="built_in">set</span> the range of shapes <span class="keyword">for</span> this input tensor.</span><br></pre></td></tr></table></figure>
<p>为了抑制此消息并明确向Polygraphy提供输入形状，请使用<code>--input-shapes</code>选项：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">polygraphy run dynamic_identity.onnx --trt --onnxrt \</span><br><span class="line">    --input-shapes X:[1,2,4,4]</span><br></pre></td></tr></table></figure>
<p>//TODO 待更新</p>
<h3 id="example-05-与自定义输入数据比较"><a href="#example-05-与自定义输入数据比较" class="headerlink" title="example 05 与自定义输入数据比较"></a>example 05 与自定义输入数据比较</h3><h4 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h4><p>在某些情况下，我们可能希望使用自定义输入数据进行比较。Polygraphy提供了多种方法来做到这一点，下面将详细介绍<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/how-to/use_custom_input_data.md">here</a>.。</p>
<p>在本例中，我们将演示两种不同的方法：</p>
<ol>
<li>通过在Python脚本<code>data_loader.py</code>中定义<code>load_data（）</code>函数来使用数据加载器脚本。Polygraphy将使用<code>load_data（</code>）在运行时生成输入。</li>
<li>使用包含预先生成的输入的JSON文件。为了方便起见，我们将使用上面的脚本<code>data_loader.py</code>将<code>load_data（）</code>生成的输入保存到一个名为<code>custom_puts.json</code>的文件中。</li>
</ol>
<p>提示：通常，在处理大量输入数据时，数据加载程序脚本是首选的，因为它可以避免写入磁盘。另一方面，JSON文件可能更具可移植性，并有助于确保再现性。</p>
<p>最后，我们将为<code>polygraphy run</code>提供自定义输入数据，并比较<code>ONNX Runtime</code>和<code>TensorRT</code>之间的输出。</p>
<p>由于我们的模型具有动态形状，我们需要设置一个TensorRT优化配置文件。有关如何通过命令行执行此操作的详细信息，请参见<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/examples/cli/convert/03_dynamic_shapes_in_tensorrt"><code>onvert</code> example 03</a>.。为了简单起见，我们将创建一个配置文件，其中<code>min==opt==max</code>。</p>
<p>注意：重要的是，我们的优化配置文件与自定义数据加载程序提供的形状配合使用。在我们非常简单的情况下，数据加载器总是生成形状（1，2，28，28）的输入，所以我们只需要确保这在[min，max]内。</p>
<h4 id="运行示例-1"><a href="#运行示例-1" class="headerlink" title="运行示例"></a>运行示例</h4><ol>
<li><p>运行脚本将输入数据保存到磁盘。注意：这仅适用于选项2。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 data_loader.py</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用自定义输入数据，使用TensorRT和ONNX Runtime运行模型：</p>
<ol>
<li><p>选项1：使用数据加载程序脚本：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">polygraphy run dynamic_identity.onnx --trt --onnxrt \</span><br><span class="line">    --trt-min-shapes X:[1,2,28,28] --trt-opt-shapes X:[1,2,28,28] --trt-max-shapes X:[1,2,28,28] \</span><br><span class="line">    --data-loader-script data_loader.py</span><br></pre></td></tr></table></figure>
</li>
<li><p>选项2：使用包含已保存输入的JSON文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">polygraphy run dynamic_identity.onnx --trt --onnxrt \</span><br><span class="line">    --trt-min-shapes X:[1,2,28,28] --trt-opt-shapes X:[1,2,28,28] --trt-max-shapes X:[1,2,28,28] \</span><br><span class="line">    --load-inputs custom_inputs.json</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ol>
<h2 id="3-10-debug-example"><a href="#3-10-debug-example" class="headerlink" title="3.10 debug example"></a>3.10 debug example</h2><h3 id="example-01-调试Flaky-TensorRT策略"><a href="#example-01-调试Flaky-TensorRT策略" class="headerlink" title="example 01 调试Flaky TensorRT策略"></a>example 01 调试Flaky TensorRT策略</h3><p>重要提示：此示例不再适用于较新版本的<code>TensorRT</code>，因为它们所做的一些策略选择没有通过<code>IAlgorithSelector</code>接口公开。因此，下面概述的方法不能保证确定性的引擎构建。使用<code>TensorRT 8.</code>7及更新版本，您可以使用策略定时缓存（<code>Polygraphy中的--save timing cache和--load timing  cache</code>）来确保确定性，但这些文件是不透明的，因此无法通过检查差异策略进行解释</p>
<h4 id="Introduction-2"><a href="#Introduction-2" class="headerlink" title="Introduction"></a>Introduction</h4><p>有时，<code>TensorRT</code>中的策略可能会产生不正确的结果，或者有其他错误的行为。由于<code>TensorRT</code>构建器依赖于定时策略，因此引擎构建是不确定的，这可能会使策略错误表现为片状/间歇性故障。</p>
<p>解决这个问题的一种方法是多次运行生成器，保存每次运行的战术回放文件。一旦我们有了一套已知的好策略和已知的坏策略，我们就可以对它们进行比较，以确定哪种策略可能是错误的来源。</p>
<p><code>debug build</code>工具允许您自动执行此过程。</p>
<p>有关<code>debug</code>工具如何工作的更多详细信息，请参阅帮助输出：<code>polygraph debug-h</code>和<code>polygraph debug-build-h</code>。</p>
<h4 id="运行示例-2"><a href="#运行示例-2" class="headerlink" title="运行示例"></a>运行示例</h4><ol>
<li><p>从ONNX运行时生成golden 输出：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">polygraphy run identity.onnx --onnxrt \</span><br><span class="line">    --save-outputs golden.json</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用调试构建来重复构建TensorRT引擎，并将结果与golden 输出进行比较，每次保存一个策略重播文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">polygraphy debug build identity.onnx --fp16 --save-tactics replay.json \</span><br><span class="line">    --artifacts-dir replays --artifacts replay.json --until=10 \</span><br><span class="line">    --check polygraphy run polygraphy_debug.engine --trt --load-outputs golden.json</span><br></pre></td></tr></table></figure>
<p>让我们来分解一下：</p>
<p>与其他<code>debug</code>子工具一样，<code>debug build</code>在每次迭代中生成一个中间工件（默认情况下为<code>./polygraphy_debug.engine</code>）。本例中的这个工件是一个<code>TensorRT</code>引擎。</p>
<p>提示：<code>debug build</code>支持其他工具支持的所有<code>TensorRT</code>构建器配置选项，如<code>convert</code>或<code>run</code>。</p>
<p>为了<code>debug build</code>以确定每个引擎是否失败或通过，我们提供了<code>--check</code>命令。由于我们看到的是（虚假的）准确性问题，我们可以使用<code>polygraphy run</code>将引擎的输出与我们的黄金值进行比较。</p>
<p>提示：与其他<code>debug</code>子工具一样，也支持交互式模式，只需省略<code>--check</code>参数即可使用该模式。</p>
<p>与其他<code>debug</code>子工具不同，<code>debug build</code>没有自动终止条件，因此我们需要提供<code>--until</code>选项，以便工具知道何时停止。这可以是多次迭代，也可以是<code>good</code> or <code>bad</code>。在后一种情况下，工具将在分别找到第一次通过或失败的迭代后停止。</p>
<p>由于我们最终想要比较好的和坏的战术回放，我们指定<code>--save-tactics</code>来保存每次迭代的策略重播文件，然后使用<code>--artifacts</code>来告诉调试构建来管理它们，这涉及到将它们排序到主<code>artifacts</code>目录下的<code>good</code>的和<code>bad</code>的子目录中，用<code>--artifacts-dir</code>指定。</p>
</li>
<li><p>使用<code>inspect diff-tactic</code>来确定哪些策略可能不好：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">polygraphy inspect diff-tactics --<span class="built_in">dir</span> replays</span><br></pre></td></tr></table></figure>
<p>注意：最后一步应该报告它无法确定潜在的糟糕策略，因为我们的糟糕目录此时应该是空的（否则请提交TensorRT问题！）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[I] Loaded 2 good tactic replays.</span><br><span class="line">[I] Loaded 0 bad tactic replays.</span><br><span class="line">[I] Could not determine potentially bad tactics. Try generating more tactic replay files?</span><br></pre></td></tr></table></figure>
<p>有关调试工具的更多信息，以及适用于所有调试子工具的提示和技巧，请参阅调<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/how-to/use_debug_subtools_effectively.md">how-to guide for <code>debug</code> subtools</a>.。</p>
</li>
</ol>
<ol>
<li><ol>
<li></li>
</ol>
</li>
</ol>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><p>官方文档</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/README.md">https://github.com/NVIDIA/TensorRT/blob/main/tools/Polygraphy/README.md</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#polygraphy-ovr">2.12. Polygraphy</a></li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>奔跑的IC
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://example.com/TensorRT/Polygraphy/" title="Polygraphy">http://example.com/TensorRT/Polygraphy/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/git/" rel="tag"><i class="fa fa-tag"></i> git</a>
              <a href="/tags/C/" rel="tag"><i class="fa fa-tag"></i> C</a>
              <a href="/tags/Tensorrt/" rel="tag"><i class="fa fa-tag"></i> Tensorrt</a>
              <a href="/tags/DeepLearning/" rel="tag"><i class="fa fa-tag"></i> DeepLearning</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/TensorRT/QAT/" rel="prev" title="QAT">
                  <i class="fa fa-chevron-left"></i> QAT
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/TensorRT/Calibration%20file/" rel="next" title="Calibration file">
                  Calibration file <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">奔跑的IC</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div><script color="0,0,255" opacity="0.5" zIndex="-1" count="99" src="https://lib.baomitu.com/canvas-nest.js/1.0.1/canvas-nest.js"></script>


    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"zmurder","repo":"zmurder.github.io","client_id":"cf2343f27b6c29efe0bc","client_secret":"3268a1fa92706c7358d5421f88f76a0f7ada3188","admin_user":"zmurder","distraction_free_mode":true,"proxy":"https://strong-caramel-969805.netlify.app/github_access_token","language":"zh-CN","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"25b475d7fee45d5bc004645d309e7555"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
