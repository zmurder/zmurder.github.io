 

# ç›®å½•

*   *   [æ³¨æ„äº‹é¡¹](#_2)
    *   [ä¸€ã€2023/11/5æ›´æ–°](#2023115_3)
    *   [å‰è¨€](#_6)
    *   [1\. YOLOv7-PTQé‡åŒ–æµç¨‹](#1_YOLOv7PTQ_19)
    *   [2\. å‡†å¤‡å·¥ä½œ](#2__69)
    *   [3\. æ’å…¥QDQèŠ‚ç‚¹](#3_QDQ_306)
    *   *   [3.1 è‡ªåŠ¨æ’å…¥QDQèŠ‚ç‚¹](#31_QDQ_308)
        *   [3.2 æ‰‹åŠ¨æ’å…¥QDQèŠ‚ç‚¹](#32_QDQ_630)
        *   [3.3 æ‰‹åŠ¨initialize](#33_initialize_833)
    *   [æ€»ç»“](#_872)

# æ³¨æ„äº‹é¡¹

### ä¸€ã€2023/11/5æ›´æ–°

**æ–°å¢æ‰‹åŠ¨æ’å…¥ QDQ èŠ‚ç‚¹ä»¥åŠæ‰‹åŠ¨ initialize**

### å‰è¨€

> æ‰‹å†™ AI æ¨å‡ºçš„å…¨æ–° TensorRT [æ¨¡å‹](https://ml-summit.org/cloud-member?uid=c1041&spm=1001.2101.3001.7020)é‡åŒ–å®æˆ˜è¯¾ç¨‹ï¼Œ[é“¾æ¥](https://www.bilibili.com/video/BV1NN411b7HZ/?spm_id_from=333.999.0.0)ã€‚è®°å½•ä¸‹ä¸ªäººå­¦ä¹ ç¬”è®°ï¼Œä»…ä¾›è‡ªå·±å‚è€ƒã€‚
> 
> è¯¥å®æˆ˜è¯¾ç¨‹ä¸»è¦åŸºäºæ‰‹å†™ AI çš„ Latte è€å¸ˆæ‰€å‡ºçš„ [TensorRTä¸‹çš„æ¨¡å‹é‡åŒ–](https://www.bilibili.com/video/BV18L41197Uz/)ï¼Œåœ¨å…¶è¯¾ç¨‹çš„åŸºç¡€ä¸Šï¼Œæ‰€æ•´ç†å‡ºçš„ä¸€äº›å®æˆ˜åº”ç”¨ã€‚
> 
> æœ¬æ¬¡è¯¾ç¨‹ä¸º YOLOv7 é‡åŒ–å®æˆ˜ç¬¬äºŒè¯¾ï¼Œä¸»è¦ä»‹ç» YOLOv7-PTQ é‡åŒ–
> 
> è¯¾ç¨‹å¤§çº²å¯çœ‹ä¸‹é¢çš„æ€ç»´å¯¼å›¾

![3ac8e54d0077179cfb351dafc2574475](TensorRTé‡åŒ–å®æˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(ä¸€)/3ac8e54d0077179cfb351dafc2574475.png)

# 1\. YOLOv7-PTQé‡åŒ–æµç¨‹

> åœ¨ä¸ŠèŠ‚è¯¾ç¨‹ä¸­æˆ‘ä»¬ä»‹ç»äº† pytorch\_quantization é‡åŒ–å·¥å…·ç®±ï¼Œä»è¿™èŠ‚è¯¾å¼€å§‹æˆ‘ä»¬å°†æ­£å¼è¿›å…¥ YOLOv7-PTQ é‡åŒ–çš„å®æˆ˜ã€‚
> 
> ä»ä¸Šé¢çš„æ€ç»´å¯¼å›¾æˆ‘ä»¬å¯ä»¥çœ‹åˆ° YOLOv7-PTQ é‡åŒ–çš„æ­¥éª¤ï¼Œæˆ‘ä»¬ä»£ç çš„è®²è§£å’Œç¼–å†™éƒ½æ˜¯æŒ‰ç…§è¿™ä¸ªæµç¨‹æ¥çš„ã€‚

åœ¨ç¼–å†™ä»£ç å¼€å§‹ä¹‹å‰æˆ‘ä»¬è¿˜æ˜¯å†æ¥æ¢³ç†ä¸‹æ•´ä¸ª YOLOv7-PTQ é‡åŒ–çš„è¿‡ç¨‹ï¼Œå¦‚ä¸‹ï¼š

## **1.** **å‡†å¤‡å·¥ä½œ**

é¦–å…ˆæ˜¯æˆ‘ä»¬çš„å‡†å¤‡å·¥ä½œï¼Œæˆ‘ä»¬éœ€è¦ä¸‹è½½ YOLOv7 å®˜æ–¹ä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹ä»¥åŠ COCO æ•°æ®é›†ï¼Œå¹¶ç¼–å†™ä»£ç å®Œæˆæ¨¡å‹å’Œæ•°æ®çš„åŠ è½½å·¥ä½œã€‚

## **2.** **æ’å…¥ QDQ èŠ‚ç‚¹**

ç¬¬äºŒä¸ªå°±æ˜¯æˆ‘ä»¬éœ€è¦å¯¹æ¨¡å‹æ’å…¥ QDQ èŠ‚ç‚¹ï¼Œå®ƒæœ‰ä»¥ä¸‹ä¸¤ç§æ–¹å¼ï¼š

*   **è‡ªåŠ¨æ’å…¥**
    *   ä½¿ç”¨ quant\_modules.initialize() è‡ªåŠ¨æ’å…¥é‡åŒ–èŠ‚ç‚¹
*   **æ‰‹åŠ¨æ’å…¥**
    *   ä½¿ç”¨ quant\_modules.initialize() åˆå§‹åŒ–é‡åŒ–æ“ä½œæˆ–ä½¿ç”¨ QuantDescriptor() è‡ªå®šä¹‰åˆå§‹åŒ–é‡åŒ–æ“ä½œ
    *   ç¼–å†™ä»£ç ä¸ºæ¨¡å‹æ’å…¥é‡åŒ–èŠ‚ç‚¹

## **3.** **æ ‡å®š**

ç¬¬ä¸‰éƒ¨åˆ†å°±æ˜¯æˆ‘ä»¬çš„æ ‡å®šï¼Œå…¶æµç¨‹å¦‚ä¸‹ï¼š

*   **1.** é€šè¿‡å°†æ ‡å®šæ•°æ®é€åˆ°ç½‘ç»œå¹¶æ”¶é›†ç½‘ç»œæ¯ä¸ªå±‚çš„è¾“å…¥è¾“å‡ºä¿¡æ¯
*   **2.** æ ¹æ®ç»Ÿè®¡å‡ºçš„ä¿¡æ¯ï¼Œè®¡ç®—åŠ¨æ€èŒƒå›´ range å’Œ scaleï¼Œå¹¶ä¿å­˜åœ¨ QDQ èŠ‚ç‚¹ä¸­

## **4.** **æ•æ„Ÿå±‚åˆ†æ**

ç¬¬å››éƒ¨åˆ†æ˜¯æ•æ„Ÿå±‚åˆ†æï¼Œå¤§è‡´æµç¨‹å¦‚ä¸‹ï¼š

*   **1.** è¿›è¡Œå•ä¸€é€å±‚é‡åŒ–ï¼Œåªå¼€å¯æŸä¸€å±‚çš„é‡åŒ–å…¶ä»–å±‚éƒ½ä¸å¼€å¯
*   **2.** åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œæ¨¡å‹ç²¾åº¦æµ‹è¯•
*   **3.** é€‰å‡ºå‰ 10 ä¸ªå¯¹æ¨¡å‹ç²¾åº¦å½±å“æ¯”è¾ƒå¤§çš„å±‚ï¼Œå…³é—­è¿™ 10 ä¸ªå±‚çš„é‡åŒ–ï¼Œåœ¨å‰å‘è®¡ç®—æ—¶ä½¿ç”¨ float16 è€Œä¸å»ä½¿ç”¨ int8

## **5.** **å¯¼å‡º PTQ æ¨¡å‹**

ç¬¬äº”ä¸ªå°±æ˜¯æˆ‘ä»¬åœ¨æ ‡å®šä¹‹åéœ€è¦å¯¼å‡º PTQ æ¨¡å‹ï¼Œå¯¼å‡ºæµç¨‹å¦‚ä¸‹ï¼š

*   **1.** éœ€è¦å°†æˆ‘ä»¬ä¸ŠèŠ‚è¯¾æ‰€è¯´çš„ quant\_nn.TensorQuantizer.use\_fb\_fake\_quant å±æ€§è®¾ç½®ä¸º true
*   **2.** torch.onnx.export() å¯¼å‡º ONNX æ¨¡å‹

**6.** **æ€§èƒ½å¯¹æ¯”**

ç¬¬å…­ä¸ªå°±æ˜¯[æ€§èƒ½](https://marketing.csdn.net/p/3127db09a98e0723b83b2914d9256174?pId=2782?utm_source=glcblog&spm=1001.2101.3001.7020)çš„å¯¹æ¯”ï¼ŒåŒ…æ‹¬ç²¾åº¦å’Œé€Ÿåº¦çš„å¯¹æ¯”ã€‚

OKï¼ä»¥ä¸Šå°±æ˜¯ YOLOv7-PTQ é‡åŒ–çš„æµç¨‹ï¼Œä¸‹é¢æˆ‘ä»¬æ ¹æ®ä¸Šé¢çš„æµç¨‹æ¥å…·ä½“çš„å®ç°ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼ï¼ï¼ğŸš€ğŸš€ğŸš€

# 2\. å‡†å¤‡å·¥ä½œ

é¦–å…ˆæ˜¯æˆ‘ä»¬çš„å‡†å¤‡å·¥ä½œï¼Œåœ¨æ­£å¼å¼€å§‹å‰æˆ‘ä»¬éœ€è¦å‡†å¤‡ä¸‰ä¸ªä¸œè¥¿ï¼š

*   **ä»£ç **ï¼šyolov7 å®˜æ–¹ä»£ç 
*   **æ•°æ®é›†**ï¼šcoco2017
*   **å®˜æ–¹é¢„è®­ç»ƒæ¨¡å‹**ï¼šyolov7.pt

å¤§å®¶å¯ä»¥ç‚¹å‡» [hereã€pwd:yoloã€‘](https://pan.baidu.com/s/1hXBxi9Sm_iW6nw5BFYxy-g) ä¸‹è½½åšä¸»å‡†å¤‡å¥½çš„ç›¸å…³ä»£ç ã€æ¨¡å‹å’Œæ•°æ®é›†

æˆ‘ä»¬æ¥çœ‹ä¸‹æˆ‘ä»¬æ•´ä¸ªé¡¹ç›®çš„ç›®å½•ç»“æ„ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![58b081510492e028789108b8fcb87d42](TensorRTé‡åŒ–å®æˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(ä¸€)/58b081510492e028789108b8fcb87d42.png)

å…¶ä¸­çš„ coco2017 çš„æ•°æ®é›†ç›®å½•å¦‚ä¸‹ï¼š

```shell
.
â”œâ”€train2017
â”‚  â”œâ”€images
â”‚  â”œâ”€labels
â”‚  â””â”€xml
â””â”€val2017
    â”œâ”€images
    â”œâ”€labels
    â””â”€xml
```

é™¤æ­¤ä¹‹å¤–æˆ‘ä»¬è¿˜éœ€è¦ train2017.txt å’Œ val2017.txt ä¸¤ä¸ª TXT æ–‡ä»¶ï¼Œåˆ†åˆ«å­˜å‚¨ç€å¯¹åº”[è®­ç»ƒé›†](https://ml-summit.org/cloud-member?uid=c1041&spm=1001.2101.3001.7020)å’ŒéªŒè¯é›†**å›¾åƒçš„å®Œæ•´è·¯å¾„**ï¼Œä»¥ä¸‹æ˜¯ç”Ÿæˆå¯¹åº” TXT çš„ä»£ç ï¼š

```python
import os

save_dir  = "/home/jarvis/Learn/Datasets/VOC_QAT"
train_dir = "/home/jarvis/Learn/Datasets/VOC_QAT/images/train"
train_txt_path = os.path.join(save_dir, "train2017.txt")

with open(train_txt_path, "w") as f:
    for filename in os.listdir(train_dir):
        if filename.endswith(".jpg") or filename.endswith(".png"): # æ·»åŠ ä½ çš„å›¾åƒæ–‡ä»¶æ‰©å±•å
            file_path = os.path.join(train_dir, filename)
            f.write(file_path + "\n")

print(f"train2017.txt has been created at {train_txt_path}")

val_dir = "/home/jarvis/Learn/Datasets/VOC_QAT/images/val"
val_txt_path = os.path.join(save_dir, "val2017.txt")

with open(val_txt_path, "w") as f:
    for filename in os.listdir(val_dir):
        if filename.endswith(".jpg") or filename.endswith(".png"): # æ·»åŠ ä½ çš„å›¾åƒæ–‡ä»¶æ‰©å±•å
            file_path = os.path.join(val_dir, filename)
            f.write(file_path + "\n")

print(f"val2017.txt has been created at {val_txt_path}")
```

ä½ éœ€è¦ä¿®æ”¹ä»¥ä¸‹å‡ é¡¹ï¼š

*   **save\_dir**ï¼štxt æ–‡æ¡£ä¿å­˜çš„è·¯å¾„ï¼Œåº”è¯¥ä¸ train2017 å’Œ val2017 æ–‡ä»¶å¤¹åœ¨åŒä¸€çº§ç›®å½•
*   **train\_dir**ï¼šè®­ç»ƒé›†å›¾ç‰‡è·¯å¾„
*   **val\_dir**ï¼šéªŒè¯é›†å›¾ç‰‡è·¯å¾„

å°†ä¸Šè¿°å·¥ä½œå®Œæˆåï¼Œä¸‹é¢æˆ‘ä»¬æ­£å¼å¼€å§‹ç¼–å†™ä»£ç ã€‚

æˆ‘ä»¬å°†æ•°æ®é›†å’Œæƒé‡æ–‡ä»¶éƒ½æ”¾åœ¨ YOLOv7-main æ–‡ä»¶å¤¹ä¸‹ï¼Œå¹¶å…ˆæ–°å»ºä¸€ä¸ª **ptq.py** æ–‡ä»¶ï¼Œå…ˆå®Œæˆæ¨¡å‹å’Œæ•°æ®é›†åŠ è½½ä»¥åŠæ¨¡å‹ mAP æµ‹è¯•å·¥ä½œï¼Œä¸»è¦æ˜¯ä»¥ä¸‹ä¸‰ä¸ªå‡½æ•°çš„ç¼–å†™ï¼š

*   **load\_yolov7\_model**ï¼šåŠ è½½ YOLOv7 æ¨¡å‹æƒé‡
*   **prepare\_dataset**ï¼šåŠ è½½æ•°æ®
*   **evaluate\_coco()**ï¼šmAP æµ‹è¯•

æˆ‘ä»¬å…ˆçœ‹æ¨¡å‹åŠ è½½å‡½æ•°çš„ç¼–å†™ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
def load_yolov7_model(weight, device='cpu'):
    ckpt  = torch.load(weight, map_location=device)
    model = Model("cfg/training/yolov7.yaml", ch=3, nc=80).to(device)
    state_dict = ckpt['model'].float().state_dict()
    model.load_state_dict(state_dict, strict=False)
    return model
```

é¦–å…ˆæˆ‘ä»¬é€šè¿‡ torch åŠ è½½äº†é¢„è®­ç»ƒæƒé‡ï¼Œç„¶åé€šè¿‡ YOLOv7 å®˜æ–¹çš„ Model ç±»åˆ›å»ºäº†ä¸€ä¸ªå®ä¾‹ï¼Œå¹¶é€šè¿‡ load\_state\_dict æ–¹æ³•å°†çŠ¶æ€å­—å…¸åŠ è½½åˆ°æ¨¡å‹ä¸­ï¼Œæœ€åè¿”å›æ¨¡å‹ã€‚å€¼å¾—å¤§å®¶æ³¨æ„çš„æ˜¯æˆ‘ä»¬ä¼šå°†åŠ è½½çš„æ¨¡å‹æƒé‡è½¬æ¢ä¸ºå•ç²¾åº¦æµ®ç‚¹æ•°ï¼Œè¿™æ˜¯å› ä¸ºæˆ‘ä»¬åŠ è½½çš„æƒé‡å¯èƒ½æ˜¯ float64ï¼Œä½†æ˜¯æˆ‘ä»¬æ¨¡å‹é€šå¸¸åœ¨å‰å‘çš„æ—¶å€™ä½¿ç”¨çš„æ˜¯å•ç²¾åº¦ float32 è¿›è¡Œçš„æ¨ç†ï¼Œæ‰€ä»¥è¿™è¾¹åšä¸€ä¸ªè½¬åŒ–ã€‚

æ¥ç€æˆ‘ä»¬æ¥çœ‹æ•°æ®é›†åŠ è½½å‡½æ•°çš„ç¼–å†™ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
def prepare_dataset(cocodir, batch_size=4):
    dataloader = create_dataloader(
        f"{cocodir}/val2017.txt",
        imgsz=640,
        batch_size=batch_size,
        opt=collections.namedtuple("Opt", "single_cls")(False),
        augment=False, hyp=None, rect=True, cache=False, stride=32, pad=0.5, image_weights=False
    )[0]
    return dataloader
```

æˆ‘ä»¬ä½¿ç”¨ YOLOv7 å®˜æ–¹æä¾›çš„æ•°æ®åŠ è½½å™¨å‡½æ•° create\_dataloader å®Œæˆæ•°æ®åŠ è½½ï¼Œæˆ‘ä»¬å°†å¯¹åº”çš„å‚æ•°å¡«å…¥å³å¯ï¼Œå…¶ä¸­çš„ opt å‚æ•°æ˜¯ç”¨æ¥æŒ‡å®šå½“å‰æ•°æ®é›†æ˜¯å¦ä¸ºå•ç±»åˆ«æ•°æ®é›†ï¼Œç”±äºæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ COCO æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å« 80 ä¸ªç±»åˆ«ï¼Œæˆ‘ä»¬åº”è¯¥è®¾ç½®ä¸º Falseã€‚

åœ¨ä»£ç ä¸­æˆ‘ä»¬æ˜¯ä½¿ç”¨ python çš„ **collections.namedtuple** å‡½æ•°å®ä¾‹åŒ–äº†ä¸€ä¸ªåä¸º **Opt** çš„å‘½åå…ƒç»„ç±»ï¼Œå®ƒæœ‰ä¸€ä¸ªå­—æ®µ **single\_cls**ï¼Œå…¶è¢«è®¾ç½®ä¸º **False**ï¼Œé‚£å…¶å®å°±ç›¸å½“äº **opt.single\_cls = Flase** å‚æ•°ä¼ é€’è¿›å»äº†ã€‚

æœ€åæˆ‘ä»¬æ¥çœ‹éªŒè¯å‡½æ•°çš„ç¼–å†™ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
def evaluate_coco(model, loader, save_dir='', conf_thres=0.001, iou_thres=0.65):
    
    if save_dir and os.path.dirname(save_dir) != "":
        os.makedirs(os.path.dirname(save_dir), exist_ok=True)
    
    return test.test(
        "data/coco.yaml",
        save_dir=Path(save_dir),
        conf_thres=conf_thres,
        iou_thres=iou_thres,
        model=model,
        dataloader=loader,
        is_coco=True,
        plots=False,
        half_precision=True,
        save_json=False
    )[0][3]
```

æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ YOLOv7 å®˜æ–¹çš„ test å‡½æ•°ï¼Œå°†å¯¹åº”çš„å‚æ•°ä¼ é€’å³å¯ã€‚

å®Œæ•´çš„ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
import os
import test
import torch
import collections
from pathlib import Path
from models.yolo import Model
from utils.datasets import create_dataloader

def load_yolov7_model(weight, device='cpu'):
    ckpt  = torch.load(weight, map_location=device)
    model = Model("cfg/training/yolov7.yaml", ch=3, nc=80).to(device)
    state_dict = ckpt['model'].float().state_dict()
    model.load_state_dict(state_dict, strict=False)
    return model

def prepare_dataset(cocodir, batch_size=4):
    dataloader = create_dataloader(
        f"{cocodir}/val2017.txt",
        imgsz=640,
        batch_size=batch_size,
        opt=collections.namedtuple("Opt", "single_cls")(False),
        augment=False, hyp=None, rect=True, cache=False, stride=32, pad=0.5, image_weights=False
    )[0]
    return dataloader

def evaluate_coco(model, loader, save_dir='', conf_thres=0.001, iou_thres=0.65):
    
    if save_dir and os.path.dirname(save_dir) != "":
        os.makedirs(os.path.dirname(save_dir), exist_ok=True)
    
    return test.test(
        "data/coco.yaml",
        save_dir=Path(save_dir),
        conf_thres=conf_thres,
        iou_thres=iou_thres,
        model=model,
        dataloader=loader,
        is_coco=True,
        plots=False,
        half_precision=True,
        save_json=False
    )[0][3]

if __name__ == "__main__":

    weight = "yolov7.pt"

    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    model = load_yolov7_model(weight, device)

    cocodir = "dataset/coco2017"
    dataloader = prepare_dataset(cocodir)

    ap = evaluate_coco(model, dataloader)
```

åœ¨æ­£å¼å¼€å§‹æµ‹è¯•ä¹‹å‰ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¿®æ”¹ä¸‹ data/coco.yaml æ–‡ä»¶ï¼Œä¸»è¦ä¿®æ”¹ä»¥ä¸‹å‡ ç‚¹ï¼š

*   æ³¨é‡Šç¬¬ 4 è¡Œçš„æ•°æ®ä¸‹è½½
*   ä¿®æ”¹ç¬¬ 7 è¡Œå’Œ ç¬¬ 8 è¡Œçš„ txt è·¯å¾„
*   æ³¨é‡Šç¬¬ 9 è¡Œçš„ test è·¯å¾„

å®Œæ•´çš„ coco.yaml æ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼š

```yaml
# COCO 2017 dataset http://cocodataset.org

# download command/URL (optional)
# download: bash ./scripts/get_coco.sh

# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]
train: D:\\YOLO\\yolov7-qat\\yolov7-main\\dataset\\coco2017\\train2017.txt  # 118287 images
val: D:\\YOLO\\yolov7-qat\\yolov7-main\\dataset\\coco2017\\val2017.txt  # 5000 images
# test: ./coco/test-dev2017.txt  # 20288 of 40670 images, submit to https://competitions.codalab.org/competitions/20794

# number of classes
nc: 80

# class names
names: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
         'hair drier', 'toothbrush' ]
```

ä¿®æ”¹å®Œæˆä¹‹åæˆ‘ä»¬å°±å¯ä»¥åœ¨ç»ˆç«¯æ‰§è¡Œå¦‚ä¸‹æŒ‡ä»¤å®Œæˆ mAP çš„æµ‹è¯•äº†ï¼ŒæŒ‡ä»¤å¦‚ä¸‹ï¼š

```shell
python ptq.py
```

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![075ea1a990307b383f44c3dd7ea2304e](TensorRTé‡åŒ–å®æˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(ä¸€)/075ea1a990307b383f44c3dd7ea2304e.png)

å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æœ€ç»ˆæµ‹è¯•çš„ mAP@.5:.95 å€¼æ˜¯ 0.454ï¼Œé‚£ä»¥ä¸Šå°±æ˜¯æˆ‘ä»¬æµ‹è¯• mAP çš„ä¸€ä¸ªç®€å•æµç¨‹äº†ï¼Œå¤§å®¶å¯ä»¥è‡ªè¡Œæµ‹è¯•ã€‚

ä¸‹é¢æˆ‘ä»¬æ¥çœ‹å¦‚ä½•åœ¨æ¨¡å‹ä¸­æ’å…¥ QDQ èŠ‚ç‚¹ã€‚

# 3\. æ’å…¥QDQèŠ‚ç‚¹

## 3.1 è‡ªåŠ¨æ’å…¥QDQèŠ‚ç‚¹

æˆ‘ä»¬å…ˆæ¥çœ‹è‡ªåŠ¨æ’å…¥ QDQ èŠ‚ç‚¹ï¼Œç¼–å†™ **prepare\_model** å‡½æ•°ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
def prepare_model(weight, device):
    quant_modules.initialize()
    model = load_yolov7_model(weight, device)
    model.float()
    model.eval()
    with torch.no_grad():
        model.fuse()    # conv bn è¿›è¡Œå±‚çš„åˆå¹¶, åŠ é€Ÿ
    return model
```

æˆ‘ä»¬ä½¿ç”¨ initialize å‡½æ•°æ¥è‡ªåŠ¨æ’å…¥ QDQ èŠ‚ç‚¹ï¼Œæˆ‘ä»¬æ‰“å°å¯¹æ¯”ä¸‹åŸæ¥çš„ torch æ¨¡å‹å’Œæ’å…¥ QDQ èŠ‚ç‚¹æ¨¡å‹ç»“æ„çš„å˜åŒ–ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![e130471d29babd681626fb5413ac083f](TensorRTé‡åŒ–å®æˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(ä¸€)/e130471d29babd681626fb5413ac083f.png)

**å›¾3-1 åŸå§‹torchæ¨¡å‹**

![d06c38807b1aaa233e9d24c9cbd5e86a](TensorRTé‡åŒ–å®æˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(ä¸€)/d06c38807b1aaa233e9d24c9cbd5e86a.png)

**å›¾3-2 æ’å…¥QDQèŠ‚ç‚¹æ¨¡å‹**

ä»ä¸Šå›¾å¯ä»¥çœ‹å‡º torch æ¨¡å‹çš„ç»“æ„æ˜¯æˆ‘ä»¬å¸¸è§çš„ä¸€ä¸ªå·ç§¯å±‚çš„ç»“æ„ï¼Œè€Œæ’å…¥äº†é‡åŒ–èŠ‚ç‚¹çš„æ¨¡å‹ç»“æ„å¯ä»¥çœ‹åˆ°å¤šäº†ä¸¤ä¸ªè¾“å…¥ \_input\_quantizer å’Œ \_weight\_quantizerï¼Œå¦å¤– Conv2d ä¹Ÿå˜æˆäº†å¯¹åº”çš„é‡åŒ–ç‰ˆ QuantConv2dã€‚

è‡³æ­¤ï¼ŒQDQ èŠ‚ç‚¹çš„è‡ªåŠ¨æ’å…¥å°±å®Œæˆäº†ã€‚

ä¸‹é¢æˆ‘ä»¬æ¥äº†è§£ä¸‹ initializer å…·ä½“çš„å·¥ä½œæµç¨‹ï¼Œå‡½æ•°å®šä¹‰å¦‚ä¸‹ï¼š

```python
def initialize(float_module_list=None, custom_quant_modules=None):
    """Dynamic module replacement using monkey patching.

    Dynamically monkey patches the modules with their quantized versions. Internally, the
    state is maintained by a helper class object which helps in replacing the original
    modules back.

    Args:
        float_module_list: A list. User supplied list which indicates which modules to not monkey patch.
        custom_quant_modules: A dict. A mapping provided by user to indicate any other module apart
            from torch.nn and its corresponding quantized version.

    Returns:
        nothing.

    Typical usage example:

        # Define the deny list for torch.nn modules and custom map for modules other than torch.nn.
        float_module_list = ["Linear"]
        custom_quant_modules = [(torch.nn, "Linear", quant_nn.QuantLinear)]
        ## Monkey patch the modules
        pytorch_quantization.quant_modules.initialize(float_module_list, custom_modules)
        ## Use the quantized modules
        pytorch_quantization.quant_modules.deactivate()
    """
    _quant_module_helper_object.prepare_state(float_module_list, custom_quant_modules)
    _quant_module_helper_object.apply_quant_modules()
```

é¦–å…ˆ **initialize** å‡½æ•°å±äº **pytorch\_quantization.quant\_modules** æ¨¡å—ï¼Œå®ƒç”¨äºåˆå§‹åŒ–é‡åŒ–è¿‡ç¨‹ï¼Œé€šè¿‡æ‰€è°“çš„ **monkey patching** åŠ¨æ€åœ°æ›¿æ¢æ¨¡å‹ä¸­çš„æ¨¡å—ä¸ºå®ƒä»¬çš„é‡åŒ–ç‰ˆæœ¬ã€‚

å®ƒåŒ…å«ä»¥ä¸‹ä¸¤ä¸ªå‚æ•°ï¼š

*   **float\_module\_list**ï¼šç”¨æˆ·æä¾›çš„åˆ—è¡¨ï¼Œç”¨æ¥æŒ‡ç¤ºå“ªäº›æ¨¡å—ä¸åº”è¯¥è¢«æ›¿æ¢ä¸ºé‡åŒ–ç‰ˆæœ¬ã€‚è¿™å…è®¸ç”¨æˆ·å¯¹å“ªäº›æ¨¡å—è¿›è¡Œé‡åŒ–æœ‰æ›´ç»†ç²’åº¦çš„æ§åˆ¶
*   **custom\_quant\_modules**ï¼šç”¨æˆ·æä¾›çš„å­—å…¸ï¼Œå¯ä»¥ç”¨äºæŒ‡ç¤ºé™¤äº† **torch.nn** ä¹‹å¤–çš„å…¶ä»–æ¨¡å—åŠå…¶å¯¹åº”çš„é‡åŒ–ç‰ˆæœ¬ã€‚è¿™å…è®¸ç”¨æˆ·ä¸ºè‡ªå®šä¹‰çš„æ¨¡å—æŒ‡å®šé‡åŒ–ç‰ˆæœ¬

å®ƒçš„å·¥ä½œæµç¨‹åŒ…å«ä»¥ä¸‹ä¸¤ä¸ªæ­¥éª¤ï¼š

**1.** **å‡†å¤‡çŠ¶æ€**

*   ä½¿ç”¨ **prepare\_state** å‡½æ•°æ¥å‡†å¤‡é‡åŒ–çš„çŠ¶æ€
*   è¿™ä¸ªå‡½æ•°æ¥æ”¶ **float\_module\_list** å’Œ **custom\_quant\_modules** å‚æ•°ï¼Œå¹¶å°†è¿™äº›ä¿¡æ¯ä¼ é€’ç»™ä¸€ä¸ªè¾…åŠ©ç±»å¯¹è±¡
*   è¾…åŠ©ç±»å¯¹è±¡ä½¿ç”¨è¿™äº›ä¿¡æ¯æ¥ç¡®å®šå“ªäº›æ¨¡å—åº”è¯¥è¢«æ›¿æ¢ä¸ºé‡åŒ–ç‰ˆæœ¬ï¼Œå“ªäº›åº”è¯¥ä¿æŒåŸæ ·

**2.** **åº”ç”¨é‡åŒ–æ¨¡å—**

*   æ¥ä¸‹æ¥ï¼Œ**apply\_quant\_modules** å‡½æ•°æ¥å®é™…åº”ç”¨é‡åŒ–
*   åœ¨è¿™ä¸€æ­¥ä¸­ï¼ŒåŸå§‹çš„æ¨¡å—è¢«å®ƒä»¬çš„é‡åŒ–ç‰ˆæœ¬æ‰€æ›¿æ¢ã€‚å¯¹äº **torch.nn** ä¸­çš„æ ‡å‡†æ¨¡å—ï¼Œæ¯”å¦‚è¯´ **torch.nn.Conv2d** ä¼šè¢«æ›¿æ¢ä¸º **quant\_nn.QuantConv2d**
*   å¯¹äºç”¨æˆ·æŒ‡å®šçš„è‡ªå®šä¹‰æ¨¡å—ï¼Œå°†ä½¿ç”¨ **custom\_quant\_modules** ä¸­æä¾›çš„æ˜ å°„æ¥è¿›è¡Œæ›¿æ¢

æˆ‘ä»¬å†æ¥çœ‹ä¸‹å…·ä½“çš„å®ç°æ¨¡å—æ›¿æ¢çš„ QuantModuleReplacementHelper ç±»ï¼Œå®ƒçš„ç»“æ„å’ŒåŠŸèƒ½å¦‚ä¸‹ï¼š

**ç±»å±æ€§**

*   **orginal\_func\_map**ï¼šç”¨äºå­˜å‚¨åŸå§‹æ¨¡å—ï¼Œè¿™äº›åŸå§‹æ¨¡å—åœ¨è¿›è¡Œ **monkey patching** æ—¶ä¼šè¢«æ›¿æ¢
*   **default\_quant\_map**ï¼šå­˜å‚¨ pytorch\_quantization å·¥å…·æ‰€æ”¯æŒçš„é»˜è®¤é‡åŒ–æ¨¡å—çš„åˆ—è¡¨ï¼Œè¿™äº›æ˜¯å†…ç½®çš„é‡åŒ–ç‰ˆæœ¬ï¼Œé€šå¸¸å¯¹åº”äº torch.nn ä¸­çš„æ ‡å‡†æ¨¡å—ï¼Œæ¯”å¦‚ Convã€Poolã€LSTM ç­‰ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å—çš„é‡åŒ–ç‰ˆæ›¿æ¢çš„æ—¶å€™éœ€è¦ä½¿ç”¨ **namedtuple** è¿™ç§å½¢å¼ã€‚
*   **quant\_map**ï¼šå­˜å‚¨æœ€ç»ˆçš„é‡åŒ–æ¨¡å—ï¼Œç€åŒ…æ‹¬ pytorch\_quantization é»˜è®¤çš„é‡åŒ–æ¨¡å—å’Œç”¨æˆ·æä¾›çš„è‡ªå®šä¹‰é‡åŒ–æ¨¡å—

**prepare\_state æ–¹æ³•**

*   è¿™ä¸ªæ–¹æ³•æ˜¯ç”¨äºå‡†å¤‡ **monkey patching** æœºåˆ¶ä¸­ä½¿ç”¨çš„é‡åŒ–æ¨¡å—åˆ—è¡¨
*   å®ƒæ¥å—ä¸¤ä¸ªå‚æ•°ï¼š**float\_module\_list** å’Œ **custom\_map**
*   **float\_module\_list** æ˜¯ç”¨æˆ·æŒ‡å®šçš„ä¸åº”è¯¥è¢«æ›¿æ¢çš„æ¨¡å—åˆ—è¡¨
*   **custom\_map** æ˜¯ç”¨æˆ·æä¾›çš„é™¤äº† **torch.nn** ä¹‹å¤–çš„è‡ªå®šä¹‰æ¨¡å—é‡åŒ–ç‰ˆæœ¬çš„æ˜ å°„
*   è¯¥æ–¹æ³•é¦–å…ˆåŸºäº **default\_quant\_map** ç”Ÿæˆ **quant\_map**ï¼Œä½†ä¼šè·³è¿‡ **float\_module\_list** ä¸­æŒ‡å®šçš„æ¨¡å—
*   ç„¶åï¼Œå®ƒä¼šå°† **custom\_map** ä¸­çš„è‡ªå®šä¹‰æ¨¡å—æ·»åŠ åˆ° **quant\_map** ä¸­
*   åŒæ—¶ï¼Œå®ƒä¹Ÿä¼šåœ¨ **orginal\_func\_map** ä¸­å­˜å‚¨åŸå§‹æ¨¡å—ï¼Œä»¥ä¾¿ä»¥åå¯ä»¥æ¢å¤ã€‚

**apply\_quant\_modules æ–¹æ³•**

*   è¿™ä¸ªç”¨äºå®é™…åº”ç”¨ **monkey patching**
*   å®ƒä¼šéå† **quant\_map** ä¸­æ³¨å†Œçš„æ¨¡å—ï¼Œå°†å®ƒä»¬æ›¿æ¢ä¸ºé‡åŒ–ç‰ˆæœ¬ï¼Œå¹¶åœ¨ **orginal\_func\_map** ä¸­å­˜å‚¨åŸå§‹æ¨¡å—ï¼Œä»¥ä¾¿ä»¥åæ¢å¤
*   æˆ‘ä»¬å¯ä»¥åœ¨è¿è¡Œæ—¶åŠ¨æ€åœ°æ›¿æ¢ torch.nn ä¸­çš„æ¨¡å—ï¼Œå°†å…¶å˜ä¸ºé‡åŒ–ç‰ˆæœ¬ï¼Œä»è€Œå®ç°æ¨¡å‹çš„é‡åŒ–ã€‚

**restore\_float\_modules æ–¹æ³•**

*   è¿™ä¸ªæ–¹æ³•ç”¨äºæ¢å¤åŸå§‹æ¨¡å—ï¼Œå³æ’¤é”€ä¹‹å‰åº”ç”¨çš„ **monkey patching**
*   å®ƒä¼šéå† **orginal\_func\_map**ï¼Œå°†åŸå§‹æ¨¡å—æ›¿æ¢å›å»

ç»¼ä¸Šï¼Œ**QuantModuleReplacementHelper** ç±»æ˜¯ä¸€ä¸ªé‡è¦çš„è¾…åŠ©ç±»ï¼Œç”¨äºå®ç°æ¨¡å—çš„åŠ¨æ€æ›¿æ¢ï¼Œä»¥ä¾¿è¿›è¡Œ[æ¨¡å‹é‡åŒ–](https://so.csdn.net/so/search?q=%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96&spm=1001.2101.3001.7020)ã€‚é€šè¿‡è¿™ä¸ªç±»ï¼Œç”¨æˆ·å¯ä»¥çµæ´»åœ°æŒ‡å®šå“ªäº›æ¨¡å—åº”è¯¥è¢«é‡åŒ–ï¼Œå“ªäº›ä¸åº”è¯¥è¢«é‡åŒ–ï¼Œç”šè‡³å¯ä»¥æä¾›è‡ªå®šä¹‰çš„é‡åŒ–æ¨¡å—ï¼Œä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”çµæ´»çš„æ–¹å¼æ¥æ›¿æ¢æ¨¡å‹çš„é‡åŒ–ç‰ˆæœ¬ã€‚

é‚£ä¸‹é¢æˆ‘ä»¬å°±æ¥å…·ä½“çœ‹çœ‹é‡åŒ–ç‰ˆæœ¬çš„æ¨¡å—åˆ°åº•æ˜¯å¦‚ä½•å®ç°çš„ï¼Œæˆ‘ä»¬ä»¥ **QuantConv2d** ä¸ºä¾‹è¯´æ˜

é¦–å…ˆ **QuantConv2d** ç»§æ‰¿è‡ª **\_QuantConvNd**ï¼Œè€Œ **\_QuantConvNd** åˆç»§æ‰¿è‡ª **torch.nn.modules.conv.\_ConvNd** å’Œ **\_utils.QuantMixin**ï¼Œé‚£æˆ‘ä»¬é‡ç‚¹æ¥å…³æ³¨ä¸‹ **QuantMixin** ç±»çš„å·¥ä½œæµç¨‹

**QuantMixin** ç±»çš„å®šä¹‰å¦‚ä¸‹ï¼š

```python
class QuantMixin():
    """Mixin class for adding basic quantization logic to quantized modules"""

    default_quant_desc_input = QUANT_DESC_8BIT_PER_TENSOR
    default_quant_desc_weight = QUANT_DESC_8BIT_PER_TENSOR

    @classmethod
    def set_default_quant_desc_input(cls, value):
        """
        Args:
            value: An instance of :class:`QuantDescriptor <pytorch_quantization.tensor_quant.QuantDescriptor>`
        """
        if not isinstance(value, QuantDescriptor):
            raise ValueError("{} is not an instance of QuantDescriptor!")
        cls.default_quant_desc_input = copy.deepcopy(value)

    @classmethod
    def set_default_quant_desc_weight(cls, value):
        """
        Args:
            value: An instance of :class:`QuantDescriptor <pytorch_quantization.tensor_quant.QuantDescriptor>`
        """
        if not isinstance(value, QuantDescriptor):
            raise ValueError("{} is not an instance of QuantDescriptor!")
        cls.default_quant_desc_weight = copy.deepcopy(value)

    def init_quantizer(self, quant_desc_input, quant_desc_weight, num_layers=None):
        """Helper function for __init__ of quantized module

        Create input and weight quantizer based on quant_desc passed by kwargs, or default of the class.

        Args:
            quant_desc_input: An instance of :class:`QuantDescriptor <pytorch_quantization.tensor_quant.QuantDescriptor>`
            quant_desc_weight: An instance of :class:`QuantDescriptor <pytorch_quantization.tensor_quant.QuantDescriptor>`
            num_layers: An integer. Default None. If not None, create a list of quantizers.
        """
        if not inspect.stack()[1].function == "__init__":
            raise TypeError("{} should be only called by __init__ of quantized module.".format(__name__))
        self._fake_quant = True
        if (not quant_desc_input.fake_quant) or (not quant_desc_weight.fake_quant):
            raise ValueError("Only fake quantization is supported!")

        logging.info("Input is %squantized to %d bits in %s with axis %s!", ""
                     if not quant_desc_input.fake_quant else "fake ",
                     quant_desc_input.num_bits, self.__class__.__name__, quant_desc_input.axis)
        logging.info("Weight is %squantized to %d bits in %s with axis %s!", ""
                     if not quant_desc_weight.fake_quant else "fake ",
                     quant_desc_weight.num_bits, self.__class__.__name__, quant_desc_weight.axis)

        if num_layers is None:
            self._input_quantizer = TensorQuantizer(quant_desc_input)
            self._weight_quantizer = TensorQuantizer(quant_desc_weight)
        else:
            self._input_quantizers = nn.ModuleList([TensorQuantizer(quant_desc_input) for _ in range(num_layers)])
            self._weight_quantizers = nn.ModuleList([TensorQuantizer(quant_desc_weight) for _ in range(num_layers)])

    # pylint:disable=missing-docstring
    @property
    def input_quantizer(self):
        return self._input_quantizer

    @property
    def weight_quantizer(self):
        return self._weight_quantizer
    # pylint:enable=missing-docstring
```

å®ƒæ˜¯ä¸€ä¸ªæ··åˆç±»ï¼Œç”¨äºå‘é‡åŒ–æ¨¡å—å’ŒåŸºæœ¬çš„é‡åŒ–é€»è¾‘ï¼Œå®ƒçš„ç»“æ„å’ŒåŠŸèƒ½å¦‚ä¸‹ï¼š

**ç±»å±æ€§**

*   **default\_quant\_desc\_input**: è¾“å…¥å¼ é‡çš„é»˜è®¤é‡åŒ–æè¿°ç¬¦ã€‚
*   **default\_quant\_desc\_weight**: æƒé‡å¼ é‡çš„é»˜è®¤é‡åŒ–æè¿°ç¬¦ã€‚

**set\_default\_quant\_desc\_input(weight) ç±»æ–¹æ³•**

*   è¿™ä¸¤ä¸ªæ–¹æ³•ç”¨äºè®¾ç½®è¾“å…¥å’Œæƒé‡å¼ é‡çš„è‡ªå®šä¹‰æè¿°ç¬¦
*   å®ƒä»¬æ¥å—ä¸€ä¸ª **QuantDescriptor** å®ä¾‹ä½œä¸ºå‚æ•°ï¼Œå¹¶å°†å…¶å¤åˆ¶ä¸ºå¯¹åº”çš„é»˜è®¤æè¿°ç¬¦

**init\_quantizer æ–¹æ³•**

*   è¿™æ˜¯ä¸€ä¸ªè¾…åŠ©æ–¹æ³•ï¼Œé€šå¸¸åœ¨é‡åŒ–æ¨¡å—çš„ **\_\_init\_\_** æ–¹æ³•ä¸­è°ƒç”¨
*   å®ƒä¼šæ ¹æ®æä¾›çš„é‡åŒ–æè¿°ç¬¦åˆ›å»ºè¾“å…¥å’Œæƒé‡é‡åŒ–å™¨ï¼Œé€šè¿‡ **TensorQuantizer** æ¥åˆ›å»º

å€¼å¾—æ³¨æ„çš„æ˜¯æè¿°ç¬¦æ˜¯ **ScaleQuantDescriptor** ç±»çš„å®ä¾‹ï¼Œ**ScaleQuantDescriptor** ç±»çš„æè¿°å¦‚ä¸‹ï¼š

```python
class ScaledQuantDescriptor():
    """Supportive descriptor of quantization

    Describe how a tensor should be quantized. A QuantDescriptor and a tensor defines a quantized tensor.

    Args:
        num_bits: An integer. Number of bits of quantization. It is used to calculate scaling factor. Default 8.
        name: Seems a nice thing to have

    Keyword Arguments:
        fake_quant: A boolean. If True, use fake quantization mode. Default True.
        axis: None, int or tuple of int. axes which will have its own max for computing scaling factor.
            If None (the default), use per tensor scale.
            Must be in the range [-rank(input_tensor), rank(input_tensor)).
            e.g. For a KCRS weight tensor, quant_axis=(0) will yield per channel scaling.
            Default None.
        amax: A float or list/ndarray of floats of user specified absolute max range. If supplied,
            ignore quant_axis and use this to quantize. If learn_amax is True, will be used to initialize
            learnable amax. Default None.
        learn_amax: A boolean. If True, learn amax. Default False.
        scale_amax: A float. If supplied, multiply amax by scale_amax. Default None. It is useful for some
            quick experiment.
        calib_method: A string. One of ["max", "histogram"] indicates which calibration to use. Except the simple
            max calibration, other methods are all hisogram based. Default "max".
        unsigned: A Boolean. If True, use unsigned. Default False.

    Raises:
        TypeError: If unsupported type is passed in.

    Read-only properties:
        - fake_quant:
        - name:
        - learn_amax:
        - scale_amax:
        - axis:
        - calib_method:
        - num_bits:
        - amax:
        - unsigned:
    """

    def __init__(self, num_bits=8, name=None, **kwargs):
        ...
```

å®ƒæè¿°äº†å¼ é‡åº”è¯¥å¦‚ä½•è¿›è¡Œé‡åŒ–ï¼Œè¿™ä¸ªç±»å®šä¹‰äº†é‡åŒ–æ‰€éœ€çš„å‚æ•°å’Œå±æ€§ï¼Œæä¾›äº†ä¸€ç§çµæ´»çš„æ–¹å¼æ¥é…ç½®é‡åŒ–è¿‡ç¨‹ï¼Œå®ƒçš„ç»“æ„å’ŒåŠŸèƒ½å¦‚ä¸‹ï¼š

**ç±»å±æ€§**

*   **num\_bits**ï¼šé‡åŒ–ä½æ•°ï¼Œç”¨äºè®¡ç®—ç¼©æ”¾å› å­
*   **fake\_quant**ï¼šä¼ªé‡åŒ–æ¨¡å¼ï¼Œå¦‚æœè®¾ç½®ä¸º Trueï¼Œåˆ™ä½¿ç”¨ä¼ªé‡åŒ–ï¼Œé»˜è®¤ä¸º True
*   **axis**ï¼šç”¨äºè®¡ç®—ç¼©æ”¾å› å­ scale çš„è½´ï¼Œå¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨æ¯ä¸ªå¼ é‡è®¡ç®— scaleï¼Œä¾‹å¦‚ input\_quantï¼›å¦‚æœç­‰äº 0 å°†æŒ‰ç…§æ¯ä¸ªé€šé“è®¡ç®— scaleï¼Œé»˜è®¤ä¸º None
*   **amax**ï¼šåŠ¨æ€èŒƒå›´çš„æœ€å¤§å€¼ï¼Œå¦‚æœç”¨æˆ·æä¾›ï¼Œåˆ™ä½¿ç”¨è¯¥å€¼è¿›è¡Œé‡åŒ–
*   **learn\_amax**ï¼šå¸ƒå°”å€¼ï¼Œå¦‚æœä¸º True åˆ™å°†å­¦ä¹  amaxï¼Œé»˜è®¤ False
*   **scale\_amax**ï¼šå¦‚æœç”¨æˆ·æä¾›ï¼Œåˆ™ä¼šå°† amax ä¹˜ä»¥ scale\_amaxï¼Œé»˜è®¤ None
*   **calib\_method**ï¼šæ ¡å‡†æ–¹æ³•ï¼Œå¯ä»¥æ˜¯ Max æœ€å¤§å€¼æ ¡å‡†æˆ–è€… Histogram ç›´æ–¹å›¾æ ¡å‡†ï¼Œé»˜è®¤ç›´æ–¹å›¾æ ¡å‡†

è€Œé‡åŒ–å™¨æ¨¡å— **TensorQuantizer** ç±»çš„æè¿°å¦‚ä¸‹ï¼š

```python
class TensorQuantizer(nn.Module):
    """Tensor quantizer module

    This module uses tensor_quant or fake_tensor_quant function to quantize a tensor. And wrappers variable, moving
    statistics we'd want when training a quantized network.

    Experimental features:
        ``clip`` stage learns range before enabling quantization.
        ``calib`` stage runs calibration

    Args:
        quant_desc: An instance of :func:`QuantDescriptor <pytorch_quantization.tensor_quant.QuantDescriptor>`.
        disabled: A boolean. If True, by pass the whole module returns input. Default False.
        if_quant: A boolean. If True, run main quantization body. Default True.
        if_clip: A boolean. If True, clip before quantization and learn amax. Default False.
        if_calib: A boolean. If True, run calibration. Not implemented yet. Settings of calibration will probably
            go to :func:`QuantDescriptor <pytorch_quantization.tensor_quant.QuantDescriptor>`.

    Raises:

    Readonly Properties:
        - axis:
        - fake_quant:
        - scale:
        - step_size:

    Mutable Properties:
        - num_bits:
        - unsigned:
        - amax:
    """

    # An experimental static switch for using pytorch's native fake quantization
    # Primary usage is to export to ONNX
    use_fb_fake_quant = False

    def __init__(self, quant_desc=QuantDescriptor(), disabled=False, if_quant=True, if_clip=False, if_calib=False):
        """Initialize quantizer and set up required variables"""
        ...
```

è¯¥ç±»æ˜¯æˆ‘ä»¬å®é™…çš„å¼ é‡é‡åŒ–æ¨¡å—ï¼Œå³é‡åŒ–å™¨æ¨¡å—ã€‚å®ƒä½¿ç”¨ tensor\_quant æˆ–è€… fake\_tensor\_quant å‡½æ•°å¯¹å¼ é‡è¿›è¡Œé‡åŒ–ï¼Œç‰¹ç‚¹æ˜¯åœ¨å¯åŠ¨é‡åŒ–ä¹‹å‰å®ƒä¼šè®¡ç®—é‡åŒ–çš„ä¸€ä¸ªåŠ¨æ€èŒƒå›´ï¼Œä¹‹åæ ¹æ®æˆ‘ä»¬é€‰ç”¨çš„æ ¡å‡†æ–¹æ³•æ¥è¿›è¡Œæ ¡å‡†ã€‚å®ƒçš„ç»“æ„å’ŒåŠŸèƒ½å¦‚ä¸‹ï¼š

**\_\_init\_\_ æ–¹æ³•**

*   æ¥æ”¶ä¸€ä¸ª **QuantDescriptor** é‡åŒ–æè¿°ç¬¦å®ä¾‹ä½œä¸ºå‚æ•°ï¼Œç”¨äºè®¾ç½®é‡åŒ–çš„å„ç§å±æ€§å’Œå‚æ•°
*   **disabled** å‚æ•°ç”¨äºæ§åˆ¶æ˜¯å¦ç¦ç”¨è¯¥å±‚è¿›è¡Œé‡åŒ–ï¼Œé»˜è®¤ False
*   **if\_quant** å‚æ•°ç”¨äºæ§åˆ¶æ˜¯å¦è¿è¡Œä¸»ä½“é‡åŒ–é€»è¾‘ï¼Œé»˜è®¤ True
*   **if\_clip** å‚æ•°ç”¨äºæ§åˆ¶æ˜¯å¦åœ¨é‡åŒ–å‰è£å‰ªå¹¶å­¦ä¹  amaxï¼Œé»˜è®¤ False
*   **if\_calib** å‚æ•°æ§åˆ¶æ˜¯å¦è¿è¡Œæ ¡å‡†ï¼Œé»˜è®¤ False

OKï¼ä»¥ä¸Šå°±æ˜¯ QDQ èŠ‚ç‚¹çš„è‡ªåŠ¨æ’å…¥å’Œ initializer å‡½æ•°çš„ç®€å•åˆ†æï¼Œä¸‹é¢æˆ‘ä»¬æ¥ä»‹ç»ä¸‹æ‰‹åŠ¨æ’å…¥ QDQ é‡åŒ–èŠ‚ç‚¹ã€‚

## 3.2 æ‰‹åŠ¨æ’å…¥QDQèŠ‚ç‚¹

ä¸Šé¢æˆ‘ä»¬å¯¹ initializer å‡½æ•°è¿›è¡Œäº†ç®€å•çš„åˆ†æï¼Œå…¶ä¸­æ¶‰åŠäº†å¤šä¸ªç±»ä¹‹é—´çš„ç»§æ‰¿å…³ç³»ï¼Œä¸‹é¢æ˜¯ initializer å‡½æ•°ä¸­æ¶‰åŠåˆ°çš„ç±»çš„ç»§æ‰¿å…³ç³»å›¾ï¼š

![d266ac5e9fe31c1b7912b94edc202afb](TensorRTé‡åŒ–å®æˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(ä¸€)/d266ac5e9fe31c1b7912b94edc202afb.png)

å¤§å®¶å¯ä»¥æ ¹æ®ä¸Šé¢çš„ç»§æ‰¿å…³ç³»å›¾å¯¹åº”åˆ°å®é™…çš„ä»£ç ä¸­å»çœ‹çœ‹ç›¸åº”çš„ç»§æ‰¿å…³ç³»ï¼Œæ¯”å¦‚åœ¨é‡åŒ–æ¨¡å—è½¬æ¢ä¸­ **QuantConv2d** ç»§æ‰¿è‡ª **\_QuantConvNd**ï¼Œè€Œ **QuantConv2d** ä¸ **Conv2d** åˆå¯ä»¥ç›¸äº’è½¬æ¢ã€‚

ä¸‹é¢æˆ‘ä»¬å°±æ ¹æ®ä¸Šé¢çš„ç»§æ‰¿å…³ç³»æµç¨‹å›¾æ¥æ‰‹åŠ¨å®ç° QDQ èŠ‚ç‚¹çš„æ’å…¥ï¼Œæˆ‘ä»¬ä¸»è¦æ˜¯å®ç°ä¸‰ä¸ªå‡½æ•°ï¼š

**1.** **replace\_to\_quantization\_model**

```python
def replace_to_quantization_model(model):
    
    module_list = {}
    
    for entry in quant_modules._DEFAULT_QUANT_MAP:
        module = getattr(entry.orig_mod, entry.mod_name)  # module -> torch.nn.modules.conv.Conv1d
        module_list[id(module)] = entry.replace_mod
    
    torch_module_find_quant_module(model, module_list)
```

è¯¥å‡½æ•°æ˜¯æ‰‹åŠ¨æ’å…¥é‡åŒ–èŠ‚ç‚¹çš„èµ·å§‹å‡½æ•°ï¼Œç›®çš„æ˜¯ä¸ºæ¨¡å‹ç”Ÿæˆä¸€ä¸ªæ›¿æ¢æ˜ å°„ï¼Œå¹¶è°ƒç”¨[é€’å½’](https://edu.csdn.net/course/detail/40020?utm_source=glcblog&spm=1001.2101.3001.7020)å‡½æ•°æ¥æŸ¥æ‰¾å’Œæ›¿æ¢æ¨¡å‹ä¸­çš„æ¨¡å—ã€‚

*   **ç”Ÿæˆæ›¿æ¢æ˜ å°„**ï¼šmodule\_list å­—å…¸åŸºäº quant\_modules.\_DEFAULT\_QUANT\_MAP æ„å»ºï¼Œå®ƒåŒ…å«äº†åŸå§‹ pytorch æ¨¡å—ç±»ï¼ˆå¦‚ nn.Conv2dï¼‰åˆ°å®ƒä»¬å¯¹åº”çš„é‡åŒ–æ¨¡å—ç±»ï¼ˆå¦‚ quant\_modules.QuantConv2dï¼‰çš„æ˜ å°„ã€‚
*   **è°ƒç”¨é€’å½’å‡½æ•°**ï¼šè°ƒç”¨ torch\_module\_find\_quant\_module å‡½æ•°å¼€å§‹é€’å½’è¿‡ç¨‹ï¼Œä¼ å…¥æ¨¡å‹å’Œ module\_list ä½œä¸ºå‚æ•°

**2.** **torch\_module\_find\_quant\_module**

```python
def torch_module_find_quant_module(model, module_list, prefix=''):
    for name in model._modules:
        submodule = model._modules[name]
        path = name if prefix == '' else prefix + '.' + name
        torch_module_find_quant_module(submodule, module_list, prefix=path) # é€’å½’

        submodule_id = id(type(submodule))
        if submodule_id in module_list:
            # è½¬æ¢
            model._modules[name] = transfer_torch_to_quantization(submodule, module_list[submodule_id])
```

è¯¥å‡½æ•°é€’å½’çš„éå†æ¨¡å‹ä¸­çš„æ‰€æœ‰å­æ¨¡å—ï¼Œå¯»æ‰¾å¯ä»¥è¢«é‡åŒ–ç‰ˆæœ¬æ›¿æ¢çš„æ¨¡å—ã€‚

*   **é€’å½’éå†**ï¼šå¯¹äºæ¨¡å‹ä¸­çš„æ¯ä¸€ä¸ªå­æ¨¡å—ï¼Œå‡½æ•°é€’å½’è°ƒç”¨è‡ªèº«ä»¥éå†æ›´æ·±å±‚æ¬¡çš„å­æ¨¡å—
*   **æ£€æŸ¥å¹¶æ›¿æ¢æ¨¡å—**ï¼šå¦‚æœå­æ¨¡å—çš„ç±»å‹å­˜åœ¨äº module\_list æ˜ å°„ä¸­ï¼Œåˆ™ä½¿ç”¨ transfer\_torch\_to\_quantization å‡½æ•°å°†å­æ¨¡å—æ›¿æ¢ä¸ºå…¶é‡åŒ–ç‰ˆæœ¬
*   **è·¯å¾„è®°å½•**ï¼šprefix å‚æ•°ç”¨äºè·Ÿè¸ªå½“å‰å­æ¨¡å—åœ¨æ¨¡å‹ä¸­çš„è·¯å¾„

**3.** **transfer\_torch\_to\_quantization**

```python
def transfer_torch_to_quantization(nn_instance, quant_module):
    
    quant_instances = quant_module.__new__(quant_module)

    # å±æ€§èµ‹å€¼
    for k, val in vars(nn_instance).items():
        setattr(quant_instances, k, val)

    # åˆå§‹åŒ–
    def __init__(self):
        # è¿”å›ä¸¤ä¸ª QuantDescriptor çš„å®ä¾‹ self.__class__ æ˜¯ quant_instance çš„ç±», QuantConv2d
        quant_desc_input, quant_desc_weight = quant_nn_utils.pop_quant_desc_in_kwargs(self.__class__)
        if isinstance(self, quant_nn_utils.QuantInputMixin):
            self.init_quantizer(quant_desc_input)
            # åŠ å¿«é‡åŒ–é€Ÿåº¦
            if isinstance(self._input_quantizer._calibrator, calib.HistogramCalibrator):
                self._input_quantizer._calibrator._torch_hist = True
        else:
            self.init_quantizer(quant_desc_input, quant_desc_weight)
            if isinstance(self._input_quantizer._calibrator, calib.HistogramCalibrator):
                self._input_quantizer._calibrator._torch_hist = True
                self._weight_quantizer._calibrator._torch_hist = True

    __init__(quant_instances)
    return quant_instances
```

æ ¸å¿ƒå‡½æ•°ï¼Œç”¨äºå°†ä¸€ä¸ªæ ‡å‡†çš„ pytorch æ¨¡å—å®ä¾‹è½¬æ¢ä¸ºå…¶é‡åŒ–ç‰ˆæœ¬

*   **å®ä¾‹é‡åŒ–æ¨¡å—**ï¼šä½¿ç”¨ quant\_module å‚æ•°ï¼ˆä¸€ä¸ªé‡åŒ–æ¨¡å—ç±»ï¼‰åˆ›å»ºä¸€ä¸ªæ–°çš„é‡åŒ–æ¨¡å—å®ä¾‹
*   **å±æ€§å¤åˆ¶**ï¼šå°†åŸå§‹æ¨¡å— nn\_instance çš„æ‰€æœ‰å±æ€§å¤åˆ¶åˆ°æ–°çš„é‡åŒ–æ¨¡å—å®ä¾‹ä¸­
*   **åˆå§‹åŒ–é‡åŒ–å™¨**ï¼šé€šè¿‡ é€šè¿‡ \_\_init\_\_ å†…éƒ¨å‡½æ•°è°ƒç”¨ï¼Œä½¿ç”¨ init\_quantizer æ–¹æ³•åˆå§‹åŒ–é‡åŒ–å™¨ã€‚è¿™ä¸ªæ­¥éª¤ç¡®ä¿é‡åŒ–æ¨¡å—å…·æœ‰é€‚å½“çš„é‡åŒ–æè¿°ç¬¦ï¼Œå¹¶è®¾ç½®äº†ä»»ä½•å¿…è¦çš„é‡åŒ–å‚æ•°ã€‚
*   **å¯ç”¨ç›´æ–¹å›¾æ ¡å‡†ä¼˜åŒ–**: å¦‚æœé‡åŒ–å™¨ä½¿ç”¨ HistogramCalibratorï¼Œå°†è®¾ç½® \_torch\_hist æ ‡å¿—ä»¥åŠ é€Ÿç›´æ–¹å›¾è®¡ç®—è¿‡ç¨‹ã€‚

å®Œæ•´çš„ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python

import torch
from models.yolo import Model
from pytorch_quantization import calib
from pytorch_quantization import quant_modules
from pytorch_quantization.nn.modules import _utils as quant_nn_utils

def load_yolov7_model(weight, device='cpu'):
    ckpt  = torch.load(weight, map_location=device)
    model = Model("cfg/training/yolov7.yaml", ch=3, nc=80).to(device)
    state_dict = ckpt['model'].float().state_dict()
    model.load_state_dict(state_dict, strict=False)
    return model

def prepare_model(weight, device):
    model = load_yolov7_model(weight, device)
    model.float()
    model.eval()
    with torch.no_grad():
        model.fuse()    # conv bn è¿›è¡Œå±‚çš„åˆå¹¶, åŠ é€Ÿ
    return model

def transfer_torch_to_quantization(nn_instance, quant_module):
    
    quant_instances = quant_module.__new__(quant_module)

    # å±æ€§èµ‹å€¼
    for k, val in vars(nn_instance).items():
        setattr(quant_instances, k, val)

    # åˆå§‹åŒ–
    def __init__(self):
        # è¿”å›ä¸¤ä¸ª QuantDescriptor çš„å®ä¾‹ self.__class__ æ˜¯ quant_instance çš„ç±», QuantConv2d
        quant_desc_input, quant_desc_weight = quant_nn_utils.pop_quant_desc_in_kwargs(self.__class__)
        if isinstance(self, quant_nn_utils.QuantInputMixin):
            self.init_quantizer(quant_desc_input)
            # åŠ å¿«é‡åŒ–é€Ÿåº¦
            if isinstance(self._input_quantizer._calibrator, calib.HistogramCalibrator):
                self._input_quantizer._calibrator._torch_hist = True
        else:
            self.init_quantizer(quant_desc_input, quant_desc_weight)
            if isinstance(self._input_quantizer._calibrator, calib.HistogramCalibrator):
                self._input_quantizer._calibrator._torch_hist = True
                self._weight_quantizer._calibrator._torch_hist = True

    __init__(quant_instances)
    return quant_instances

def torch_module_find_quant_module(model, module_list, prefix=''):
    for name in model._modules:
        submodule = model._modules[name]
        path = name if prefix == '' else prefix + '.' + name
        torch_module_find_quant_module(submodule, module_list, prefix=path) # é€’å½’

        submodule_id = id(type(submodule))
        if submodule_id in module_list:
            # è½¬æ¢
            model._modules[name] = transfer_torch_to_quantization(submodule, module_list[submodule_id])
        
def replace_to_quantization_model(model):
    
    module_list = {}
    
    for entry in quant_modules._DEFAULT_QUANT_MAP:
        module = getattr(entry.orig_mod, entry.mod_name)  # module -> torch.nn.modules.conv.Conv1d
        module_list[id(module)] = entry.replace_mod
    
    torch_module_find_quant_module(model, module_list)


if __name__ == "__main__":

    weight = "yolov7.pt"

    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    pth_model = load_yolov7_model(weight, device)

    model = prepare_model(weight, device)
    replace_to_quantization_model(model)
    print(model)
```

è¿è¡Œæ•ˆæœå¦‚ä¸‹ï¼š

![a2e73bee11aec11e9558c33f98da3d88](TensorRTé‡åŒ–å®æˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(ä¸€)/a2e73bee11aec11e9558c33f98da3d88.png)

**å›¾3-3 æ‰‹åŠ¨æ’å…¥QDQèŠ‚ç‚¹æ¨¡å‹**

å¯ä»¥çœ‹åˆ°å¯¹åº”çš„ pytorch ç®—å­éƒ½å˜æˆäº†å…¶å¯¹åº”çš„é‡åŒ–ç‰ˆæœ¬ï¼ŒåŒæ—¶è¿˜æ‹¥æœ‰äº† \_input\_quantizer å’Œ \_weight\_quantizerã€‚

ä¸‹é¢æˆ‘ä»¬ç®€å•æ€»ç»“ä¸‹æ‰‹åŠ¨æ’å…¥é‡åŒ–èŠ‚ç‚¹çš„æµç¨‹ï¼š

*   **1\. å‡†å¤‡æ¨¡å‹**: åœ¨æ¨¡å‹å‡†å¤‡é˜¶æ®µï¼Œæ‰§è¡Œå¿…è¦çš„ä¼˜åŒ–ï¼ˆå¦‚å±‚èåˆï¼‰ã€‚
    
*   **2\. æ„å»ºæ›¿æ¢æ˜ å°„**: åŸºäºé¢„å®šä¹‰çš„é‡åŒ–æ˜ å°„ï¼ˆquant\_modules.\_DEFAULT\_QUANT\_MAPï¼‰ï¼Œåˆ›å»ºä¸€ä¸ªæ˜ å°„å­—å…¸ï¼Œç”¨äºå°†æ ‡å‡†æ¨¡å—æ›¿æ¢ä¸ºç›¸åº”çš„é‡åŒ–æ¨¡å—ã€‚
    
*   **3\. é€’å½’éå†æ¨¡å‹**: ä½¿ç”¨ torch\_module\_find\_quant\_module å‡½æ•°é€’å½’åœ°éå†æ•´ä¸ªæ¨¡å‹çš„å­æ¨¡å—ã€‚
    
*   **4\. æ£€æŸ¥å¹¶æ›¿æ¢æ¨¡å—**: å¯¹äºæ¯ä¸ªå­æ¨¡å—ï¼Œå¦‚æœå…¶ç±»å‹åœ¨æ›¿æ¢æ˜ å°„ä¸­ï¼Œåˆ™ä½¿ç”¨ transfer\_torch\_to\_quantization å‡½æ•°å°†å…¶æ›¿æ¢ä¸ºé‡åŒ–ç‰ˆæœ¬ã€‚
    
*   **5\. åˆå§‹åŒ–é‡åŒ–å™¨**: åœ¨é‡åŒ–æ¨¡å—å®ä¾‹ä¸­åˆå§‹åŒ–é‡åŒ–å™¨ï¼Œç¡®ä¿é‡åŒ–æè¿°ç¬¦å’Œæ ¡å‡†å™¨è®¾ç½®æ­£ç¡®ã€‚
    
*   **6\. ä¼˜åŒ–é‡åŒ–è¿‡ç¨‹**: å¦‚æœä½¿ç”¨ç›´æ–¹å›¾æ ¡å‡†å™¨ï¼Œå¼€å¯ \_torch\_hist ä»¥åŠ å¿«ç›´æ–¹å›¾æ ¡å‡†è¿‡ç¨‹ã€‚
    
*   **7\. æ’å…¥é‡åŒ–èŠ‚ç‚¹**: å°†é‡åŒ–æ¨¡å—å®ä¾‹æ’å…¥åˆ°æ¨¡å‹ä¸­ï¼Œæ›¿æ¢åŸå§‹çš„éé‡åŒ–æ¨¡å—ã€‚
    
*   **8\. å®Œæˆé‡åŒ–å‡†å¤‡**: å®Œæˆè¿™äº›æ­¥éª¤åï¼Œæ¨¡å‹å°±è¢«è½¬æ¢ä¸ºä¸€ä¸ªé‡åŒ–æ¨¡å‹ï¼Œå…¶ä¸­åŒ…å«äº†ä¸ºæ¨æ–­å’Œ/æˆ–è®­ç»ƒè¿‡ç¨‹é‡åŒ–å‡†å¤‡å¥½çš„èŠ‚ç‚¹ã€‚
    

é€šè¿‡è¿™ä¸ªè¿‡ç¨‹ï¼Œæ¨¡å‹ä¸­çš„æ¯ä¸ªç¬¦åˆæ¡ä»¶çš„æ¨¡å—éƒ½ä¼šè¢«å…¶é‡åŒ–ç‰ˆæœ¬æ‰€æ›¿æ¢ã€‚è¿™ç§æ‰‹åŠ¨æ’å…¥é‡åŒ–èŠ‚ç‚¹çš„æ–¹æ³•å¯ä»¥è®©ä½ æœ‰æ›´ç»†ç²’åº¦çš„æ§åˆ¶ï¼Œä¾‹å¦‚åœ¨æ¨¡å‹çš„ç‰¹å®šéƒ¨åˆ†ä½¿ç”¨ä¸åŒçš„é‡åŒ–ç­–ç•¥æˆ–æè¿°ç¬¦ã€‚

OKï¼ä»¥ä¸Šå°±æ˜¯ QDQ èŠ‚ç‚¹çš„æ‰‹åŠ¨æ’å…¥ï¼Œä¸‹é¢æˆ‘ä»¬æ¥ä»‹ç»ä¸‹æ‰‹åŠ¨ initializeã€‚

## 3.3 æ‰‹åŠ¨initialize

æˆ‘ä»¬å…ˆæ¥çœ‹ä¸‹æ‰‹åŠ¨æ’å…¥é‡åŒ–èŠ‚ç‚¹åæ¨¡å‹ mAP æµ‹è¯•çš„ç»“æœï¼Œè¿è¡Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![835dc14ca12e4382ef1d6173038e9d7a](TensorRTé‡åŒ–å®æˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(ä¸€)/835dc14ca12e4382ef1d6173038e9d7a.png)

å¯ä»¥çœ‹åˆ°æµ‹è¯•ç»“æœå’Œ torch å·®ä¸å¤šï¼Œæ­¤å¤–é‡åŒ–å™¨ä½¿ç”¨çš„æ˜¯é»˜è®¤ MaxCalibrator æ ¡å‡†å™¨ï¼Œå…¶ä¸­çš„ initialize æ˜¯æŒ‰ç…§**é»˜è®¤çš„æ–¹æ³•**å»è¿›è¡Œåˆå§‹åŒ–çš„ã€‚

ä¸‹é¢æˆ‘ä»¬æ‰‹åŠ¨æ¥å®ç° initializeï¼Œä¸ä½¿ç”¨é»˜è®¤çš„ Max é‡åŒ–å™¨è€Œæ˜¯å»ä½¿ç”¨ç›´æ–¹å›¾ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸‹åº”è¯¥æ€ä¹ˆå»æ“ä½œã€‚

**initialize** å‡½æ•°çš„å®ç°ä»£ç å¦‚ä¸‹ï¼š

```python
from absl import logging as quant_logging
from pytorch_quantization import nn as quant_nn
from pytorch_quantization.tensor_quant import QuantDescriptor

# input: Max ==> Histogram
def initialize():
    quant_desc_input = QuantDescriptor(calib_method='histogram')
    quant_nn.QuantConv2d.set_default_quant_desc_input(quant_desc_input)
    quant_nn.QuantMaxPool2d.set_default_quant_desc_input(quant_desc_input)
    quant_nn.QuantLinear.set_default_quant_desc_input(quant_desc_input)

    quant_logging.set_verbosity(quant_logging.ERROR)
```

åœ¨ä»£ç ä¸­æˆ‘ä»¬å°† QuantConv2dã€QuantMaxPool2d ä»¥åŠ QuantLinear çš„ input é‡åŒ–å™¨ä¿®æ”¹ä¸ºäº†ç›´æ–¹å›¾ï¼Œæˆ‘ä»¬å¯ä»¥è‡ªå·±æ‰‹åŠ¨ç¼–å†™ initialize ä»è€Œå®Œæˆä¸€äº›è‡ªå®šä¹‰çš„æ“ä½œã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬æ¥è¿›è¡ŒéªŒè¯ï¼Œçœ‹çœ‹é‡åŒ–æ–¹å¼ä¼šä¸ä¼šæœ‰æ‰€å˜åŒ–ï¼Œè¿è¡Œæ•ˆæœå¦‚ä¸‹ï¼š

![d38812303c139eff477729e0a7c2c95f](TensorRTé‡åŒ–å®æˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(ä¸€)/d38812303c139eff477729e0a7c2c95f.png)

æˆ‘ä»¬å¯ä»¥çœ‹åˆ° input çš„é‡åŒ–å™¨ä½¿ç”¨çš„æ˜¯ç›´æ–¹å›¾ï¼Œæƒé‡ä¾æ—§ä½¿ç”¨çš„æ˜¯é»˜è®¤çš„ Max é‡åŒ–å™¨ï¼Œè¿™è¯´æ˜æˆ‘ä»¬æ‰‹åŠ¨å®ç°çš„ initialize èµ·ä½œç”¨äº†ã€‚å¦å¤–å¯ä»¥çœ‹åˆ° mAP å’Œä¹‹å‰çš„æ²¡æœ‰ä»€ä¹ˆå˜åŒ–ï¼Œå› ä¸ºæˆ‘ä»¬å¹¶æ²¡æœ‰çœŸæ­£çš„å»æ‰§è¡Œç›¸å…³é‡åŒ–æ“ä½œï¼Œè€Œä»…ä»…æ’å…¥äº†é‡åŒ–èŠ‚ç‚¹ã€‚

ä¸‹èŠ‚è¯¾æˆ‘ä»¬å°†ä¼šè®²è§£æ¨¡å‹æ ‡å®šçš„ç›¸å…³å†…å®¹ã€‚

# æ€»ç»“

> æœ¬æ¬¡è¯¾ç¨‹ä»‹ç»äº† YOLOv7-PTQ é‡åŒ–æµç¨‹ä¸­çš„å‡†å¤‡å·¥ä½œå’Œ QDQ èŠ‚ç‚¹çš„æ’å…¥ï¼Œå…¶ä¸­å‡†å¤‡å·¥ä½œåŒ…æ‹¬æ¨¡å‹å’Œæ•°æ®é›†çš„å‡†å¤‡ï¼Œè€Œé‡åŒ–èŠ‚ç‚¹çš„æ’å…¥æˆ‘ä»¬ä»‹ç»äº†è‡ªåŠ¨å’Œæ‰‹åŠ¨æ’å…¥ä¸¤ç§æ–¹å¼ï¼Œå…¶ä¸­è‡ªåŠ¨æ’å…¥æ˜¯è°ƒç”¨ initialize å‡½æ•°æ¥å®Œæˆçš„ï¼Œè€Œæ‰‹åŠ¨æ’å…¥æ˜¯æ ¹æ® initialize å‡½æ•°ä¸­ç±»çš„ç»§æ‰¿å…³ç³»å›¾æ¥ä¸€æ­¥æ­¥å®ç°çš„ã€‚QDQ èŠ‚ç‚¹æ’å…¥åä»æ¨¡å‹ç»“æ„å¯ä»¥çœ‹åˆ°æ¯ä¸ªèŠ‚ç‚¹å¤šäº† \_input\_quantizer å’Œ \_weight\_quantizer ä¸¤ä¸ªè¾“å…¥ï¼ŒåŒæ—¶ torch æ¨¡å—ä¹Ÿå˜æˆäº†å¯¹åº”çš„é‡åŒ–ç‰ˆæœ¬ã€‚æœ€åæˆ‘ä»¬æ‰‹åŠ¨å®ç°äº† initialize å‡½æ•°å°† input çš„æ ¡å‡†å™¨ä»é»˜è®¤çš„ Max æ›¿æ¢æˆäº†ç›´æ–¹å›¾ã€‚
> 
> ä¸‹èŠ‚è¯¾ç¨‹æˆ‘ä»¬å°†ä¼šçœŸæ­£çš„å»ç¼–å†™ä»£ç å¯¹æ’å…¥é‡åŒ–èŠ‚ç‚¹çš„æ¨¡å‹è¿›è¡Œæ ‡å®šè®¡ç®—ä»¥å®Œæˆ PTQ æ¨¡å‹çš„é‡åŒ–å’Œå¯¼å‡ºå·¥ä½œã€‚

æœ¬æ–‡è½¬è‡ª <https://blog.csdn.net/qq_40672115/article/details/134108526>ï¼Œå¦‚æœ‰ä¾µæƒï¼Œè¯·è”ç³»åˆ é™¤ã€‚