 

# ç›®å½•

*   *   [æ³¨æ„äº‹é¡¹](#_2)
    *   [ä¸€ã€2023/11/19æ›´æ–°](#20231119_4)
    *   [äºŒã€2023/12/27æ›´æ–°](#20231227_8)
    *   [å‰è¨€](#_11)
    *   [1\. YOLOv7-PTQé‡åŒ–æµç¨‹](#1_YOLOv7PTQ_24)
    *   [2\. æ¨¡åž‹æ ‡å®š](#2__74)
    *   [3\. æ•æ„Ÿå±‚åˆ†æž](#3__505)
    *   [4\. PTQé‡åŒ–](#4_PTQ_1078)
    *   [æ€»ç»“](#_1596)

# æ³¨æ„äº‹é¡¹

### ä¸€ã€2023/11/19æ›´æ–°

**æ–°å¢žæ•æ„Ÿå±‚åˆ†æžå’Œ PTQ é‡åŒ–ä»£ç å·¥ç¨‹åŒ–**

### äºŒã€2023/12/27æ›´æ–°

**å’Œ `è´è’‚å°ç†Š` çœ‹å®˜äº¤æµçš„è¿‡ç¨‹ä¸­å‘çŽ°æ¨¡åž‹æ ‡å®šå°èŠ‚ä¸­çš„ä¸€äº›æè¿°å­˜åœ¨é—®é¢˜ï¼Œä¿®æ”¹æ¨¡åž‹æ ‡å®šå°èŠ‚ä¸€äº›æè¿°è¯è¯­ï¼Œé‡æ–°æ¢³ç†ä¸‹ PTQ é‡åŒ–å’Œ QAT é‡åŒ–çš„åŒºåˆ«ï¼Œå…·ä½“å¯å‚è€ƒç¬¬ 2 å°èŠ‚ä¿®æ”¹çš„å†…å®¹**

# å‰è¨€

> æ‰‹å†™ AI æŽ¨å‡ºçš„å…¨æ–° TensorRT æ¨¡åž‹é‡åŒ–å®žæˆ˜è¯¾ç¨‹ï¼Œ[é“¾æŽ¥](https://www.bilibili.com/video/BV1NN411b7HZ/?spm_id_from=333.999.0.0)ã€‚è®°å½•ä¸‹ä¸ªäººå­¦ä¹ ç¬”è®°ï¼Œä»…ä¾›è‡ªå·±å‚è€ƒã€‚
> 
> è¯¥å®žæˆ˜è¯¾ç¨‹ä¸»è¦åŸºäºŽæ‰‹å†™ AI çš„ Latte è€å¸ˆæ‰€å‡ºçš„ [TensorRTä¸‹çš„æ¨¡åž‹é‡åŒ–](https://www.bilibili.com/video/BV18L41197Uz/)ï¼Œåœ¨å…¶è¯¾ç¨‹çš„åŸºç¡€ä¸Šï¼Œæ‰€æ•´ç†å‡ºçš„ä¸€äº›å®žæˆ˜åº”ç”¨ã€‚
> 
> æœ¬æ¬¡è¯¾ç¨‹ä¸º YOLOv7 é‡åŒ–å®žæˆ˜ç¬¬ä¸‰è¯¾ï¼Œä¸»è¦ä»‹ç» YOLOv7-PTQ é‡åŒ–
> 
> è¯¾ç¨‹å¤§çº²å¯çœ‹ä¸‹é¢çš„æ€ç»´å¯¼å›¾

![b03a269e88c866011bdced6d9b002fee](TensorRTé‡åŒ–å®žæˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(äºŒ)/b03a269e88c866011bdced6d9b002fee.png)

# 1\. YOLOv7-PTQé‡åŒ–æµç¨‹

> åœ¨ä¸ŠèŠ‚è¯¾ç¨‹ä¸­æˆ‘ä»¬ä»‹ç»äº† YOLOv7-PTQ é‡åŒ–ä¸­ QDQ èŠ‚ç‚¹çš„æ’å…¥ï¼Œè¿™èŠ‚è¯¾æˆ‘ä»¬å°†ä¼šå®Œæˆ PTQ æ¨¡åž‹çš„é‡åŒ–å’Œå¯¼å‡ºã€‚
> 
> ä»Žä¸Šé¢çš„æ€ç»´å¯¼å›¾æˆ‘ä»¬å¯ä»¥çœ‹åˆ° YOLOv7-PTQ é‡åŒ–çš„æ­¥éª¤ï¼Œæˆ‘ä»¬ä»£ç çš„è®²è§£å’Œç¼–å†™éƒ½æ˜¯æŒ‰ç…§è¿™ä¸ªæµç¨‹æ¥çš„ã€‚

åœ¨ç¼–å†™ä»£ç å¼€å§‹ä¹‹å‰æˆ‘ä»¬è¿˜æ˜¯å†æ¥æ¢³ç†ä¸‹æ•´ä¸ª YOLOv7-PTQ é‡åŒ–çš„è¿‡ç¨‹ï¼Œå¦‚ä¸‹ï¼š

## **1.** **å‡†å¤‡å·¥ä½œ**

é¦–å…ˆæ˜¯æˆ‘ä»¬çš„å‡†å¤‡å·¥ä½œï¼Œæˆ‘ä»¬éœ€è¦ä¸‹è½½ YOLOv7 å®˜æ–¹ä»£ç å’Œé¢„è®­ç»ƒæ¨¡åž‹ä»¥åŠ COCO æ•°æ®é›†ï¼Œå¹¶ç¼–å†™ä»£ç å®Œæˆæ¨¡åž‹å’Œæ•°æ®çš„åŠ è½½å·¥ä½œã€‚

## **2.** **æ’å…¥ QDQ èŠ‚ç‚¹**

ç¬¬äºŒä¸ªå°±æ˜¯æˆ‘ä»¬éœ€è¦å¯¹æ¨¡åž‹æ’å…¥ QDQ èŠ‚ç‚¹ï¼Œå®ƒæœ‰ä»¥ä¸‹ä¸¤ç§æ–¹å¼ï¼š

*   **è‡ªåŠ¨æ’å…¥**
    *   ä½¿ç”¨ quant\_modules.initialize() è‡ªåŠ¨æ’å…¥é‡åŒ–èŠ‚ç‚¹
*   **æ‰‹åŠ¨æ’å…¥**
    *   ä½¿ç”¨ quant\_modules.initialize() åˆå§‹åŒ–é‡åŒ–æ“ä½œæˆ–ä½¿ç”¨ QuantDescriptor() è‡ªå®šä¹‰åˆå§‹åŒ–é‡åŒ–æ“ä½œ
    *   ç¼–å†™ä»£ç ä¸ºæ¨¡åž‹æ’å…¥é‡åŒ–èŠ‚ç‚¹

## **3.** **æ ‡å®š**

ç¬¬ä¸‰éƒ¨åˆ†å°±æ˜¯æˆ‘ä»¬çš„æ ‡å®šï¼Œå…¶æµç¨‹å¦‚ä¸‹ï¼š

*   **1.** é€šè¿‡å°†æ ‡å®šæ•°æ®é€åˆ°ç½‘ç»œå¹¶æ”¶é›†ç½‘ç»œæ¯ä¸ªå±‚çš„è¾“å…¥è¾“å‡ºä¿¡æ¯
*   **2.** æ ¹æ®ç»Ÿè®¡å‡ºçš„ä¿¡æ¯ï¼Œè®¡ç®—åŠ¨æ€èŒƒå›´ range å’Œ scaleï¼Œå¹¶ä¿å­˜åœ¨ QDQ èŠ‚ç‚¹ä¸­

## **4.** **æ•æ„Ÿå±‚åˆ†æž**

ç¬¬å››éƒ¨åˆ†æ˜¯æ•æ„Ÿå±‚åˆ†æžï¼Œå¤§è‡´æµç¨‹å¦‚ä¸‹ï¼š

*   **1.** è¿›è¡Œå•ä¸€é€å±‚é‡åŒ–ï¼Œåªå¼€å¯æŸä¸€å±‚çš„é‡åŒ–å…¶ä»–å±‚éƒ½ä¸å¼€å¯
*   **2.** åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œæ¨¡åž‹ç²¾åº¦æµ‹è¯•
*   **3.** é€‰å‡ºå‰ 10 ä¸ªå¯¹æ¨¡åž‹ç²¾åº¦å½±å“æ¯”è¾ƒå¤§çš„å±‚ï¼Œå…³é—­è¿™ 10 ä¸ªå±‚çš„é‡åŒ–ï¼Œåœ¨å‰å‘è®¡ç®—æ—¶ä½¿ç”¨ float16 è€Œä¸åŽ»ä½¿ç”¨ int8

## **5.** **å¯¼å‡º PTQ æ¨¡åž‹**

ç¬¬äº”ä¸ªå°±æ˜¯æˆ‘ä»¬åœ¨æ ‡å®šä¹‹åŽéœ€è¦å¯¼å‡º PTQ æ¨¡åž‹ï¼Œå¯¼å‡ºæµç¨‹å¦‚ä¸‹ï¼š

*   **1.** éœ€è¦å°†æˆ‘ä»¬ä¸ŠèŠ‚è¯¾æ‰€è¯´çš„ quant\_nn.TensorQuantizer.use\_fb\_fake\_quant å±žæ€§è®¾ç½®ä¸º true
*   **2.** torch.onnx.export() å¯¼å‡º ONNX æ¨¡åž‹

## **6.** **æ€§èƒ½å¯¹æ¯”**

ç¬¬å…­ä¸ªå°±æ˜¯æ€§èƒ½çš„å¯¹æ¯”ï¼ŒåŒ…æ‹¬ç²¾åº¦å’Œé€Ÿåº¦çš„å¯¹æ¯”ã€‚

ä¸ŠèŠ‚è¯¾æˆ‘ä»¬å®Œæˆäº† YOLOv7-PTQ é‡åŒ–æµç¨‹ä¸­çš„å‡†å¤‡å·¥ä½œå’Œæ’å…¥ QDQ èŠ‚ç‚¹ï¼Œè¿™èŠ‚æˆ‘ä»¬ç»§ç»­æŒ‰ç…§æµç¨‹èµ°ï¼Œå…ˆæ¥å®žçŽ°æ¨¡åž‹çš„æ ‡å®šå·¥ä½œï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼ï¼ï¼ðŸš€ðŸš€ðŸš€

# 2\. æ¨¡åž‹æ ‡å®š

æ¨¡åž‹é‡åŒ–æ ¡å‡†ä¸»è¦æ˜¯ç”±ä»¥ä¸‹ä¸‰ä¸ª[å‡½æ•°](https://marketing.csdn.net/p/3127db09a98e0723b83b2914d9256174?pId=2782?utm_source=glcblog&spm=1001.2101.3001.7020)å®Œæˆçš„ï¼š

## **1.** **calibrate\_model**

```python
def calibrate_model(model, dataloader, device):

    # æ”¶é›†å‰å‘ä¿¡æ¯
    collect_stats(model, dataloader, device)

    # èŽ·å–åŠ¨æ€èŒƒå›´ï¼Œè®¡ç®— amax å€¼ï¼Œscale å€¼
    compute_amax(model, method = 'mse')
```

è¯¥å‡½æ•°ä¸»è¦æ˜¯è®²ä¸¤ä¸ªæ ¡å‡†æ­¥éª¤ç»„åˆèµ·æ¥ï¼Œç”¨äºŽæ¨¡åž‹çš„æ•´ä½“æ ¡å‡†ï¼Œæ•´ä½“æ­¥éª¤å¦‚ä¸‹ï¼š

*   ä½¿ç”¨ collect\_stats å‡½æ•°æ”¶é›†å‰å‘ä¼ æ’­çš„ç»Ÿè®¡ä¿¡æ¯
*   è°ƒç”¨ compute\_amax å‡½æ•°è®¡ç®—é‡åŒ–çš„å°ºåº¦å› å­ amax

## **2.** **collect\_stats**

```python
def collect_stats(model, data_loader, device, num_batch = 200):
    model.eval()

    # å¼€å¯æ ¡å‡†å™¨
    for name, module in model.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            if module._calibrator is not None:
                module.disable_quant()
                module.enable_calib()
            else:
                module.disable()

    # test
    with torch.no_grad():
        for i, datas in enumerate(data_loader):
            imgs = datas[0].to(device, non_blocking=True).float() / 255.0
            model(imgs)

            if i >= num_batch:
                break
    
    # å…³é—­æ ¡å‡†å™¨
    for name, module in model.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            if module._calibrator is not None:
                module.enable_quant()
                module.disable_calib()
            else:
                module.enable()
```

è¯¥å‡½æ•°çš„ç›®çš„æ˜¯æ”¶é›†æ¨¡åž‹åœ¨ç»™å®šæ•°æ®é›†ä¸Šçš„æ¿€æ´»ç»Ÿè®¡ä¿¡æ¯ï¼Œè¿™é€šå¸¸æ˜¯æ¨¡åž‹é‡åŒ–æ ¡å‡†è¿‡ç¨‹ä¸­çš„ç¬¬ä¸€æ­¥ï¼Œå…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š

*   è®¾ç½®æ¨¡åž‹ä¸º eval æ¨¡åž‹ï¼Œç¡®ä¿ä¸å¯ç”¨å¦‚ dropout è¿™æ ·çš„è®­ç»ƒç‰¹æœ‰çš„è¡Œä¸º
*   éåŽ†æ¨¡åž‹çš„æ‰€æœ‰æ¨¡å—ï¼Œå¯¹äºŽæ¯ä¸€ä¸ª TensorQuantizer å®žä¾‹
    *   å¦‚æžœæœ‰æ ¡å‡†å™¨å­˜åœ¨ï¼Œåˆ™ç¦ç”¨é‡åŒ–ï¼ˆä¸å¯¹è¾“å…¥è¿›è¡Œé‡åŒ–ï¼‰å¹¶å¯åŠ¨æ ¡å‡†æ¨¡å¼ï¼ˆæ”¶é›†ç»Ÿè®¡ä¿¡æ¯ï¼‰
    *   å¦‚æžœæ²¡æœ‰æ ¡å‡†å™¨ï¼Œåˆ™å®Œå…¨ç¦ç”¨è¯¥é‡åŒ–å™¨ï¼ˆä¸æ‰§è¡Œä»»ä½•æ“ä½œï¼‰
*   ä½¿ç”¨ data\_loader æ¥æä¾›æ•°æ®ï¼Œå¹¶é€šè¿‡æ¨¡åž‹æ‰§è¡Œå‰å‘ä¼ æ’­
    *   è®²æ•°æ®è½¬ç§»åˆ° device ä¸Šï¼Œå¹¶è¿›è¡Œé€‚å½“çš„å½’ä¸€åŒ–
    *   å¯¹æ¯ä¸ªæ‰¹æ¬¡æ•°æ®ï¼Œæ¨¡åž‹è¿›è¡ŒæŽ¨ç†ï¼Œä½†ä¸è¿›è¡Œæ¢¯åº¦è®¡ç®—
    *   æ”¶é›†æ¿€æ´»ç»Ÿè®¡ä¿¡æ¯ç›´åˆ°å¤„ç†æŒ‡å®šæ•°é‡çš„æ‰¹æ¬¡
*   æœ€åŽï¼ŒéåŽ†æ¨¡åž‹çš„æ‰€æœ‰æ¨¡å—ï¼Œå¯¹äºŽæ¯ä¸€ä¸ª TensorQuantizer å®žä¾‹
    *   å¦‚æžœæœ‰æ ¡å‡†å™¨å­˜åœ¨ï¼Œåˆ™å¯ç”¨é‡åŒ–å¹¶ç¦ç”¨æ ¡å‡†æ¨¡å¼
    *   å¦‚æžœæ²¡æœ‰æ ¡å‡†å™¨ï¼Œåˆ™é‡æ–°å¯ç”¨è¯¥é‡åŒ–å™¨

## **3.** **compute\_amax**

```python
def compute_amax(model, **kwargs):
    
    for name, module in model.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            if module._calibrator is not None:
                if isinstance(module._calibrator, calib.MaxCalibrator):
                    module.load_calib_amax()
                else:
                    module.load_calib_amax(**kwargs)
                module._amax = module._amax.to(device)
```

ä¸€æ—¦æ”¶é›†äº†æ¿€æ´»çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œè¯¥å‡½æ•°å°±ä¼šè®¡ç®—é‡åŒ–çš„å°ºåº¦å› å­ amaxï¼ˆåŠ¨æ€èŒƒå›´çš„æœ€å¤§å€¼ï¼‰ï¼Œè¿™é€šå¸¸æ˜¯æ¨¡åž‹é‡åŒ–æ ¡å‡†è¿‡ç¨‹ä¸­çš„ç¬¬äºŒæ­¥ï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š

*   éåŽ†æ¨¡åž‹çš„æ‰€æœ‰æ¨¡å—ï¼Œå¯¹äºŽæ¯ä¸€ä¸ª TensorQuantizer å®žä¾‹
    *   å¦‚æžœæœ‰æ ¡å‡†å™¨å­˜åœ¨ï¼Œåˆ™æ ¹æ®æ”¶é›†çš„ç»Ÿè®¡ä¿¡æ¯è®¡ç®— amax å€¼ï¼Œè¿™ä¸ªå€¼ä»£è¡¨äº†æ¿€æ´»çš„æœ€å¤§å¹…å€¼ï¼Œç”¨äºŽç¡®å®šé‡åŒ–çš„å°ºåº¦
    *   å°† amax å€¼è½¬ç§»åˆ° device ä¸Šï¼Œä»¥ä¾¿åœ¨åŽç»­ä¸­ä½¿ç”¨

ä¸‹é¢æˆ‘ä»¬ç®€å•æ€»ç»“ä¸‹æ¨¡åž‹é‡åŒ–æ ¡å‡†çš„æµç¨‹ï¼š

*   **1.æ•°æ®å‡†å¤‡**: å‡†å¤‡ç”¨äºŽæ ‡å®šçš„æ•°æ®é›†ï¼Œé€šå¸¸æ˜¯[æ¨¡åž‹è®­ç»ƒ](https://ml-summit.org/cloud-member?uid=c1041&spm=1001.2101.3001.7020)æˆ–éªŒè¯æ•°æ®é›†çš„ä¸€ä¸ªå­é›†ã€‚
    
*   **2.æ”¶é›†ç»Ÿè®¡ä¿¡æ¯**: é€šè¿‡ collect\_stats å‡½æ•°è¿›è¡Œå‰å‘ä¼ æ’­ï¼Œä»¥æ”¶é›†æ¨¡åž‹å„å±‚çš„æ¿€æ´»åˆ†å¸ƒç»Ÿè®¡ä¿¡æ¯ã€‚
    
*   **3.è®¡ç®— amax**: ä½¿ç”¨ compute\_amax å‡½æ•°åŸºäºŽæ”¶é›†çš„ç»Ÿè®¡ä¿¡æ¯è®¡ç®—é‡åŒ–å‚æ•°ï¼ˆå¦‚æœ€å¤§æ¿€æ´»å€¼ amaxï¼‰ã€‚
    

é€šè¿‡ä¸Šè¿°æ­¥éª¤ï¼Œæ¨¡åž‹å°±å¯ä»¥å¾—åˆ°åˆé€‚çš„é‡åŒ–å‚æ•°ï¼Œä»Žè€Œåœ¨é‡åŒ–åŽä¿æŒæ€§èƒ½å¹¶å‡å°ç²¾åº¦æŸå¤±ã€‚

å®Œæ•´çš„ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
import os
import yaml
import test
import torch
import collections
from pathlib import Path
from models.yolo import Model
from pytorch_quantization import calib
from absl import logging as quant_logging
from utils.datasets import create_dataloader
from pytorch_quantization import quant_modules
from pytorch_quantization import nn as quant_nn
from pytorch_quantization.tensor_quant import QuantDescriptor
from pytorch_quantization.nn.modules import _utils as quant_nn_utils

def load_yolov7_model(weight, device='cpu'):
    ckpt  = torch.load(weight, map_location=device)
    model = Model("cfg/training/yolov7.yaml", ch=3, nc=80).to(device)
    state_dict = ckpt['model'].float().state_dict()
    model.load_state_dict(state_dict, strict=False)
    return model

def prepare_val_dataset(cocodir, batch_size=32):
    dataloader = create_dataloader(
        f"{cocodir}/val2017.txt",
        imgsz=640,
        batch_size=batch_size,
        opt=collections.namedtuple("Opt", "single_cls")(False),
        augment=False, hyp=None, rect=True, cache=False, stride=32, pad=0.5, image_weights=False
    )[0]
    return dataloader

def prepare_train_dataset(cocodir, batch_size=32):
    
    with open("data/hyp.scratch.p5.yaml") as f:
        hyp = yaml.load(f, Loader=yaml.SafeLoader)

    dataloader = create_dataloader(
        f"{cocodir}/train2017.txt",
        imgsz=640,
        batch_size=batch_size,
        opt=collections.namedtuple("Opt", "single_cls")(False),
        augment=True, hyp=hyp, rect=True, cache=False, stride=32, pad=0, image_weights=False
    )[0]
    return dataloader

# input: Max ==> Histogram
def initialize():
    quant_desc_input = QuantDescriptor(calib_method='histogram')
    quant_nn.QuantConv2d.set_default_quant_desc_input(quant_desc_input)
    quant_nn.QuantMaxPool2d.set_default_quant_desc_input(quant_desc_input)
    quant_nn.QuantLinear.set_default_quant_desc_input(quant_desc_input)

    quant_logging.set_verbosity(quant_logging.ERROR)

def prepare_model(weight, device):
    # quant_modules.initialize()
    initialize()
    model = load_yolov7_model(weight, device)
    model.float()
    model.eval()
    with torch.no_grad():
        model.fuse()    # conv bn è¿›è¡Œå±‚çš„åˆå¹¶, åŠ é€Ÿ
    return model

def tranfer_torch_to_quantization(nn_instance, quant_module):
    
    quant_instances = quant_module.__new__(quant_module)

    # å±žæ€§èµ‹å€¼
    for k, val in vars(nn_instance).items():
        setattr(quant_instances, k, val)

    # åˆå§‹åŒ–
    def __init__(self):
        # è¿”å›žä¸¤ä¸ª QuantDescriptor çš„å®žä¾‹ self.__class__ æ˜¯ quant_instance çš„ç±», QuantConv2d
        quant_desc_input, quant_desc_weight = quant_nn_utils.pop_quant_desc_in_kwargs(self.__class__)
        if isinstance(self, quant_nn_utils.QuantInputMixin):
            self.init_quantizer(quant_desc_input)
            # åŠ å¿«é‡åŒ–é€Ÿåº¦
            if isinstance(self._input_quantizer._calibrator, calib.HistogramCalibrator):
                self._input_quantizer._calibrator._torch_hist = True
        else:
            self.init_quantizer(quant_desc_input, quant_desc_weight)
            if isinstance(self._input_quantizer._calibrator, calib.HistogramCalibrator):
                self._input_quantizer._calibrator._torch_hist = True
                self._weight_quantizer._calibrator._torch_hist = True

    __init__(quant_instances)
    return quant_instances

def torch_module_find_quant_module(model, module_list, prefix=''):
    for name in model._modules:
        submodule = model._modules[name]
        path = name if prefix == '' else prefix + '.' + name
        torch_module_find_quant_module(submodule, module_list, prefix=path) # é€’å½’

        submodule_id = id(type(submodule))
        if submodule_id in module_list:
            # è½¬æ¢
            model._modules[name] = tranfer_torch_to_quantization(submodule, module_list[submodule_id])
        
def replace_to_quantization_model(model):
    
    module_list = {}
    
    for entry in quant_modules._DEFAULT_QUANT_MAP:
        module = getattr(entry.orig_mod, entry.mod_name)  # module -> torch.nn.modules.conv.Conv1d
        module_list[id(module)] = entry.replace_mod
    
    torch_module_find_quant_module(model, module_list)


def evaluate_coco(model, loader, save_dir='', conf_thres=0.001, iou_thres=0.65):
    
    if save_dir and os.path.dirname(save_dir) != "":
        os.makedirs(os.path.dirname(save_dir), exist_ok=True)
    
    return test.test(
        "data/coco.yaml",
        save_dir=Path(save_dir),
        conf_thres=conf_thres,
        iou_thres=iou_thres,
        model=model,
        dataloader=loader,
        is_coco=True,
        plots=False,
        half_precision=True,
        save_json=False
    )[0][3]

def collect_stats(model, data_loader, device, num_batch = 200):
    model.eval()

    # å¼€å¯æ ¡å‡†å™¨
    for name, module in model.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            if module._calibrator is not None:
                module.disable_quant()
                module.enable_calib()
            else:
                module.disable()

    # test
    with torch.no_grad():
        for i, datas in enumerate(data_loader):
            imgs = datas[0].to(device, non_blocking=True).float() / 255.0
            model(imgs)

            if i >= num_batch:
                break
    
    # å…³é—­æ ¡å‡†å™¨
    for name, module in model.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            if module._calibrator is not None:
                module.enable_quant()
                module.disable_calib()
            else:
                module.enable()
            
def compute_amax(model, **kwargs):
    
    for name, module in model.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            if module._calibrator is not None:
                if isinstance(module._calibrator, calib.MaxCalibrator):
                    module.load_calib_amax()
                else:
                    module.load_calib_amax(**kwargs)
                module._amax = module._amax.to(device)


def calibrate_model(model, dataloader, device):

    # æ”¶é›†å‰å‘ä¿¡æ¯
    collect_stats(model, dataloader, device)

    # èŽ·å–åŠ¨æ€èŒƒå›´ï¼Œè®¡ç®— amax å€¼ï¼Œscale å€¼
    compute_amax(model, method = 'mse')

if __name__ == "__main__":

    weight = "yolov7.pt"
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    # åŠ è½½æ•°æ®
    print("Evalute Dataset...")
    cocodir = "dataset/coco2017"
    val_dataloader   = prepare_val_dataset(cocodir)
    train_dataloader = prepare_train_dataset(cocodir)

    # åŠ è½½ pth æ¨¡åž‹
    pth_model = load_yolov7_model(weight, device)
    # pth æ¨¡åž‹éªŒè¯
    print("Evalute Origin...")
    ap = evaluate_coco(pth_model, val_dataloader)

    # èŽ·å–ä¼ªé‡åŒ–æ¨¡åž‹(æ‰‹åŠ¨ initial(), æ‰‹åŠ¨æ’å…¥ QDQ)
    model = prepare_model(weight, device)
    replace_to_quantization_model(model)

    # æ¨¡åž‹æ ‡å®š
    calibrate_model(model, train_dataloader, device)

    # # PTQ æ¨¡åž‹éªŒè¯
    print("Evaluate PTQ...")
    ptq_ap = evaluate_coco(model, val_dataloader)
```

å€¼å¾—æ³¨æ„çš„æ˜¯æˆ‘ä»¬æ ¡å‡†æ—¶æ˜¯åœ¨è®­ç»ƒé›†ä¸Šå®Œæˆçš„ï¼Œæµ‹è¯•æ—¶æ˜¯åœ¨éªŒè¯é›†ä¸Šå®Œæˆçš„ï¼Œè¿è¡Œæ•ˆæžœå¦‚ä¸‹ï¼š

![0175313e5448829028e4b202628242e5](TensorRTé‡åŒ–å®žæˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(äºŒ)/0175313e5448829028e4b202628242e5.png)

å¯ä»¥çœ‹åˆ°é‡åŒ–æ ¡å‡†åŽçš„æ¨¡åž‹çš„ mAP ä»…ä»…ä¸‹é™äº† 0.003 ä¸ªç‚¹ã€‚

åšä¸»å­¦å¾—æœ‰ç‚¹æ··æ·†äº†ï¼Œå…ˆæ¢³ç†ä¸‹ä¸€äº›æ¦‚å¿µï¼Œæˆ‘ä»¬æ”¶é›†ç»Ÿè®¡ä¿¡æ¯çš„ç›®çš„æ˜¯ä¸ºäº†ç¡®å®šå½“å‰ tensor çš„ amax å³å¹…åº¦çš„æœ€å¤§å€¼ï¼Œç„¶åŽæ ¹æ®ä¸åŒçš„æ ¡å‡†æ–¹æ³•å’ŒèŽ·å–çš„ç»Ÿè®¡ä¿¡æ¯åŽ»æ ¡å‡†è®¡ç®— amaxï¼Œå…¶ä¸­åŒ…æ‹¬ Max å’Œç›´æ–¹å›¾ä¸¤ç§æ ¡å‡†æ–¹æ³•ï¼ŒMax æ ¡å‡†æ–¹æ³•ç›´æŽ¥é€‰æ‹© tensor ç»Ÿè®¡ä¿¡æ¯çš„æœ€å¤§å€¼æ¥ä½œä¸º amaxï¼Œè€Œç›´æ–¹å›¾æ ¡å‡†ä¸­åˆåŒ…å« entropyã€mseã€percentile ä¸‰ç§æ–¹æ³•æ¥è®¡ç®— amaxï¼Œ~ä¸Šè¿°è¿‡ç¨‹ä»…ä»…æ˜¯è¿›è¡Œäº†æ ¡å‡†ç¡®å®šäº† amax å€¼ï¼Œå¾—åˆ°äº†é‡åŒ–æ—¶æ‰€éœ€è¦çš„ scaleï¼Œä½†æ˜¯è¿˜æ²¡æœ‰åˆ©ç”¨ scale è¿›è¡Œå…·ä½“çš„é‡åŒ–æ“ä½œï¼Œæ¨¡åž‹çš„æƒé‡æˆ–æ¿€æ´»å€¼è¿˜æ²¡æœ‰æ”¹å˜ï¼Œåº”è¯¥æ˜¯è¿™ä¹ˆç†è§£çš„å§ðŸ˜‚~

**ä¸Šè¿°è¿‡ç¨‹ä¸­è¿›è¡Œäº†æ ¡å‡†ç¡®å®šäº† amax å€¼ï¼Œå¾—åˆ°äº†é‡åŒ–æ—¶æ‰€éœ€è¦çš„ scaleï¼Œå¹¶åœ¨æ¨¡åž‹ forward çš„è¿‡ç¨‹ä¸­å†…éƒ¨æ‰§è¡Œäº†é‡åŒ–æ“ä½œï¼Œå› æ­¤ä¸Šè¿°æµç¨‹æ˜¯è¿›è¡Œäº† PTQ é‡åŒ–çš„**

* * *

* * *

**2023/12/27 æ–°å¢žå†…å®¹**

åšä¸»ä¹‹å‰ä¸€ç›´ä»¥ä¸º Q/DQ èŠ‚ç‚¹æ˜¯ QAT é‡åŒ–ä¸“å±žçš„ï¼Œè¿™è¿˜æ˜¯å±žäºŽé‡åŒ–çš„ä¸€äº›åŸºç¡€æ¦‚å¿µéƒ½æ²¡æœ‰ç†æ¸…æ¥šðŸ˜‚

å®žé™…ä¸Š Q/DQ èŠ‚ç‚¹æ—¢ç”¨äºŽ QAT é‡åŒ–ä¹Ÿç”¨äºŽ PTQ é‡åŒ–ï¼Œè¿™ä¸¤ç§é‡åŒ–ç­–ç•¥çš„ä¸»è¦åŒºåˆ«åœ¨äºŽå®ƒä»¬ä½¿ç”¨ Q/DQ èŠ‚ç‚¹çš„æ–¹å¼å’Œé‡åŒ–çš„æ—¶é—´ç‚¹ï¼Œå…·ä½“å¦‚ä¸‹ï¼š(**from ChatGPT**)

**PTQ ä¸­çš„ Q/DQ èŠ‚ç‚¹**

*   åœ¨ PTQ é‡åŒ–è¿‡ç¨‹ä¸­ï¼ŒQ/DQ èŠ‚ç‚¹è¢«æ’å…¥åˆ°å·²ç»è®­ç»ƒå¥½çš„æ¨¡åž‹ä¸­ã€‚è¿™æ˜¯ä¸ºäº†æ¨¡æ‹Ÿé‡åŒ–è¿‡ç¨‹ä¸­å¯¹æ¨¡åž‹æŽ¨ç†çš„å½±å“ï¼Œå¹¶é€šè¿‡æ ¡å‡†æ•°æ®æ¥ç¡®å®šæœ€ä½³çš„é‡åŒ–å‚æ•°ï¼ˆå¦‚ scale å’Œ zero-pointï¼‰
*   åœ¨ PTQ é‡åŒ–è¿‡ç¨‹ä¸­ï¼ŒQ/DQ èŠ‚ç‚¹**ä¸»è¦ç”¨äºŽé‡åŒ–è½¬æ¢è¿‡ç¨‹ä¸­çš„æ•°æ®æ”¶é›†å’Œé‡åŒ–å‚æ•°çš„ç¡®å®šï¼Œå®ƒä»¬ä¸å‚ä¸Žæ¨¡åž‹è®­ç»ƒçš„åå‘ä¼ æ’­è¿‡ç¨‹**

**QAT ä¸­çš„ Q/DQ èŠ‚ç‚¹**

*   åœ¨ QAT é‡åŒ–è¿‡ç¨‹ä¸­ï¼ŒQ/DQ èŠ‚ç‚¹æ˜¯æ¨¡åž‹è®­ç»ƒè¿‡ç¨‹çš„ä¸€éƒ¨åˆ†ã€‚å®ƒä»¬è¢«ç”¨æ¥æ¨¡æ‹Ÿé‡åŒ–çš„å½±å“ï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è°ƒæ•´æ¨¡åž‹çš„æƒé‡ï¼Œä»¥æœ€å°åŒ–é‡åŒ–å¸¦æ¥çš„æ€§èƒ½æŸå¤±
*   åœ¨ QAT é‡åŒ–è¿‡ç¨‹ä¸­ï¼ŒQ/DQ èŠ‚ç‚¹**å¯¹æ¨¡åž‹æƒé‡çš„æ›´æ–°æœ‰ç›´æŽ¥å½±å“**ã€‚è¿™æ˜¯å› ä¸ºå®ƒä»¬å‚ä¸Žäº†æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ã€‚

æ‰€ä»¥è¯´ Q/DQ åœ¨ PTQ å’Œ QAT ä¸­æ‰®æ¼”ç€ä¸åŒçš„è§’è‰²ï¼Œåœ¨ PTQ ä¸­æ˜¯æ¨¡æ‹Ÿé‡åŒ–è¿‡ç¨‹ç¡®å®š scaleï¼Œè€Œåœ¨ QAT ä¸­ä¸ä»…ä»…ä¼šæ¨¡æ‹Ÿé‡åŒ–ç¡®å®š scale è¿˜ä¼šåœ¨å¾®è°ƒè®­ç»ƒè¿‡ç¨‹ä¸­è°ƒæ•´æ¨¡åž‹çš„æƒé‡ä»¥é€‚åº”é‡åŒ–å¸¦æ¥çš„å½±å“

ä»¥ä¸‹æ˜¯ QAT ä¸­ Q/DQ èŠ‚ç‚¹ä½œç”¨çš„è¯¦ç»†è§£é‡Šï¼š(**from ChatGPT**)

*   **æ¨¡æ‹Ÿè®­ç»ƒçŽ¯å¢ƒ**ï¼šQ/DQ èŠ‚ç‚¹è¢«å¼•å…¥åˆ°å·¡ç¤¼è¿‡ç¨‹ä¸­ï¼Œæ¨¡æ‹Ÿé‡åŒ–åŽæ¨¡åž‹çš„è¿è¡ŒçŽ¯å¢ƒã€‚è¿™æ„å‘³ç€åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæƒé‡å’Œæ¿€æ´»æ•°æ®ä¼šç»åŽ†å®žé™…çš„é‡åŒ–å’Œåé‡åŒ–è¿‡ç¨‹ã€‚
*   **æƒé‡è°ƒæ•´**ï¼šç”±äºŽé‡åŒ–è¿‡ç¨‹å¯èƒ½å¼•å…¥ä¸€å®šçš„è¯¯å·®ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡åž‹ä¼šé€šè¿‡æ ‡å‡†çš„æ¢¯åº¦ä¸‹é™å’Œåå‘ä¼ æ’­è¿‡ç¨‹ï¼Œ**ä¸æ–­è°ƒæ•´æƒé‡**ã€‚è¿™ä¸ªè¿‡ç¨‹æ—¨åœ¨**ä½¿æ¨¡åž‹é€‚åº”é‡åŒ–å¸¦æ¥çš„å½±å“ï¼Œä»Žè€Œå‡å°‘é‡åŒ–è¯¯å·®å¯¹æ¨¡åž‹æ€§èƒ½çš„å½±å“**
*   **å­¦ä¹ é‡åŒ–å‚æ•°**ï¼šåŒæ—¶ï¼ŒQAT è¿‡ç¨‹ä¸­è¿˜ä¼šå­¦ä¹ ç¡®å®šé‡åŒ–è¿‡ç¨‹ä¸­çš„å…³é”®å‚æ•°ï¼Œå¦‚ scale å’Œ zero-pointã€‚è¿™äº›å‚æ•°æ˜¯é‡åŒ–è¿‡ç¨‹ä¸­éžå¸¸å…³é”®çš„ï¼Œå®ƒä»¬å†³å®šäº†å¦‚ä½•è®²æµ®ç‚¹æ•°å€¼æ˜ å°„åˆ°æ•´æ•°è¡¨ç¤º
*   **æœ€ç»ˆç»“æžœ**ï¼šé€šè¿‡è¿™ç§æ–¹å¼ï¼ŒQAT é‡åŒ–åŽçš„æ¨¡åž‹ä¸ä»…ä»…æ˜¯èŽ·å¾—äº†é€‚åˆé‡åŒ–çš„ scale å€¼ï¼Œè€Œä¸”å…¶æƒé‡ä¹Ÿè¢«è°ƒæ•´ä¸ºæ›´é€‚åˆé‡åŒ–åŽçš„è¿è¡ŒçŽ¯å¢ƒï¼Œè¿™æœ‰åŠ©äºŽä¿æŒæˆ–æŽ¥è¿‘åŽŸå§‹æµ®ç‚¹æ¨¡åž‹çš„æ€§èƒ½

QAT å’Œ PTQ é‡åŒ–æœ€æ˜¾è‘—çš„åŒºåˆ«åœ¨äºŽ QAT é‡åŒ–ä¸­æ¨¡åž‹çš„æƒé‡ä¼šå‘ç”Ÿå˜åŒ–ä»¥é€‚åº”é‡åŒ–å¸¦æ¥çš„å½±å“ã€‚

ç®€å•æ€»ç»“ä¸‹ï¼ŒPTQ å’Œ QAT æ¨¡åž‹éƒ½ä¼šæºå¸¦ Q/DQ èŠ‚ç‚¹ï¼ŒQAT é‡åŒ–ä¼šé€šè¿‡è®­ç»ƒçš„æ–¹å¼èŽ·å– scale ç­‰é‡åŒ–ä¿¡æ¯å¹¶è°ƒæ•´æ¨¡åž‹æƒé‡ä»¥é€‚åº”é‡åŒ–å¸¦æ¥çš„å½±å“ï¼ŒPTQ é‡åŒ–åˆ™æ˜¯é€šè¿‡æ ¡å‡†å›¾ç‰‡æ¥èŽ·å– scale ç­‰é‡åŒ–ä¿¡æ¯æ— éœ€è®­ç»ƒ

æœ€åŽå†æ¥æ¢³ç†ä¸‹äºŒè€…çš„åŒºåˆ«ï¼š(**from ChatGPT**)

**PTQ**

*   **æ“ä½œæ—¶é—´**ï¼šPTQ æ˜¯åœ¨æ¨¡åž‹è®­ç»ƒå®ŒæˆåŽè¿›è¡Œçš„ã€‚è¿™ç§æ–¹æ³•ä¸æ¶‰åŠé‡æ–°è®­ç»ƒæ¨¡åž‹
*   **ä¸»è¦æ­¥éª¤**ï¼š
    *   **æ’å…¥ Q/DQ èŠ‚ç‚¹**ï¼šé¦–å…ˆåœ¨æ¨¡åž‹çš„é€‚å½“ä½ç½®æ’å…¥é‡åŒ–ï¼ˆQuantizeï¼‰å’Œåé‡åŒ–ï¼ˆDequantizeï¼‰èŠ‚ç‚¹
    *   **æ ¡å‡†**ï¼šé€šè¿‡ä½¿ç”¨ä¸€ç»„ä»£è¡¨æ€§æ•°æ®ï¼ˆé€šå¸¸å«æ ¡å‡†æ•°æ®é›†ï¼‰æ¥è¿è¡Œæ¨¡åž‹ï¼Œä»¥æ­¤æ¥æ”¶é›†æ¿€æ´»ï¼ˆActivationï¼‰çš„ç»Ÿè®¡æ•°æ®ã€‚è¿™äº›æ•°æ®ç”¨äºŽç¡®å®šé‡åŒ–å‚æ•°ï¼ˆå¦‚ scale å’Œ zero-pointï¼‰
    *   **é‡åŒ–è½¬æ¢**ï¼šåˆ©ç”¨æ”¶é›†åˆ°çš„ç»Ÿè®¡æ•°æ®ï¼Œå°†æµ®ç‚¹æƒé‡å’Œæ¿€æ´»è½¬æ¢ä¸ºæ•´æ•°æ ¼å¼
*   **ä¼˜åŠ¿**ï¼šæ“ä½œç®€å•ï¼Œä¸éœ€è¦é¢å¤–è®­ç»ƒï¼Œé€‚ç”¨äºŽèµ„æºæœ‰é™çš„æƒ…å†µ
*   **åŠ£åŠ¿**ï¼šå¯èƒ½ä¼šæœ‰è¾ƒå¤§çš„ç²¾åº¦æŸå¤±ï¼Œå°¤å…¶æ˜¯å¯¹äºŽé‚£äº›å¯¹é‡åŒ–æ•æ„Ÿçš„æ¨¡åž‹ï¼ˆéœ€è¦è¿›è¡Œæ•æ„Ÿå±‚åˆ†æžï¼‰

**QAT**

*   **æ“ä½œæ—¶é—´**ï¼šQAT æ˜¯åœ¨æ¨¡åž‹è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œçš„ã€‚å®ƒå®žé™…ä¸Šæ˜¯æ¨¡åž‹è®­ç»ƒçš„ä¸€ä¸ªéƒ¨åˆ†ã€‚
*   **ä¸»è¦æ­¥éª¤**ï¼š
    *   **æ¨¡æ‹Ÿé‡åŒ–**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥ Q/DQ èŠ‚ç‚¹ï¼Œæ¨¡æ‹Ÿé‡åŒ–è¿‡ç¨‹ä¸­çš„å½±å“ã€‚è¿™æ„å‘³ç€åœ¨å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­æ—¶ï¼Œæƒé‡å’Œæ¿€æ´»éƒ½ä¼šç»åŽ†é‡åŒ–å’Œåé‡åŒ–çš„è¿‡ç¨‹
    *   **è®­ç»ƒå¾®è°ƒ**ï¼šé€šè¿‡å¯¹æ¨¡åž‹çš„æ­£å¸¸è®­ç»ƒæµç¨‹è¿›è¡Œå¾®è°ƒï¼Œè°ƒæ•´æƒé‡ï¼Œä»¥è¡¥å¿é‡åŒ–è¿‡ç¨‹å¯èƒ½å¼•å…¥çš„è¯¯å·®
    *   **å­¦ä¹ é‡åŒ–å‚æ•°**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¹ ç¡®å®šæœ€ä½³çš„é‡åŒ–å‚æ•°ï¼ˆå¦‚ scaleï¼‰
*   **ä¼˜åŠ¿**ï¼šç”±äºŽæ¨¡åž‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å·²ç»é€‚åº”äº†é‡åŒ–çš„å½±å“ï¼Œå› æ­¤é‡åŒ–åŽçš„æ¨¡åž‹é€šå¸¸æœ‰æ›´å¥½çš„æ€§èƒ½å’Œè¾ƒå°çš„ç²¾åº¦æŸå¤±
*   **åŠ£åŠ¿**ï¼šéœ€è¦é¢å¤–çš„è®­ç»ƒèµ„æºå’Œæ—¶é—´ï¼Œç›¸å¯¹äºŽ PTQ æ¥è¯´æ›´åŠ å¤æ‚

OKï¼Œä»¥ä¸Šå°±æ˜¯æœ¬æ¬¡æ›´æ–°æ–°å¢žçš„å†…å®¹ï¼Œå¦‚æœ‰ä¸å¯¹çš„åœ°æ–¹ï¼Œæ¬¢è¿Žå„ä½çœ‹å®˜æ‰¹è¯„æŒ‡æ­£ðŸ˜„

* * *

* * *

ä¸‹é¢æˆ‘ä»¬æ¥å¯¹æ¯”ä¸‹ Max å’Œç›´æ–¹å›¾æ ¡å‡†æ–¹æ³•çš„ PTQ æ¨¡åž‹çš„å¯¹æ¯”ï¼Œæ¥çœ‹çœ‹ä¸åŒçš„æ ¡å‡†æ–¹æ³•å¯¹æ¨¡åž‹çš„å½±å“

ä¸Šé¢æˆ‘ä»¬æµ‹è¯•äº†ç›´æ–¹å›¾æ ¡å‡†åŽçš„ PTQ [æ¨¡åž‹æ€§èƒ½](https://edu.csdn.net/cloud/pm_summit?utm_source=blogglc&spm=1001.2101.3001.7020)ï¼Œä¸‹é¢æˆ‘ä»¬æ¥çœ‹ Max æ ¡å‡†æ–¹æ³•ï¼Œæˆ‘ä»¬å°† prepare\_model å‡½æ•°ä¸­çš„æ‰‹åŠ¨ initialize å‡½æ•°æ³¨é‡Šï¼Œæ‰“å¼€è‡ªåŠ¨åˆå§‹åŒ– quant\_module.initialize

å†æ¬¡æ‰§è¡Œä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š

![0a1db5742c80d3fbfc571ceaa95b816b](TensorRTé‡åŒ–å®žæˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(äºŒ)/0a1db5742c80d3fbfc571ceaa95b816b.png)

å¯ä»¥çœ‹åˆ°æˆ‘ä»¬ä½¿ç”¨é»˜è®¤çš„ Max æ ¡å‡†æ–¹æ³•å¾—åˆ°çš„ mAP å€¼æ˜¯ 0.444ï¼Œç›¸æ¯”äºŽä¹‹å‰ç›´æ–¹å›¾æ ¡å‡†çš„æ•ˆæžœè¦å·®ä¸€äº›ï¼Œå› æ­¤åŽç»­æˆ‘ä»¬å¯èƒ½å°±ä½¿ç”¨ç›´æ–¹å›¾æ ¡å‡†çš„æ–¹å¼æ¥è¿›è¡Œé‡åŒ–ã€‚

ä¸‹é¢æˆ‘ä»¬æ¥çœ‹çœ‹ PTQ æ¨¡åž‹çš„å¯¼å‡ºï¼Œå¯¼å‡ºå‡½æ•°å¦‚ä¸‹ï¼š

```python
def export_ptq(model, save_file, device, dynamic_batch = True):
    
    input_dummy = torch.randn(1, 3, 640, 640, device=device)
    
    # æ‰“å¼€ fake ç®—å­
    quant_nn.TensorQuantizer.use_fb_fake_quant = True

    model.eval()

    with torch.no_grad():
        torch.onnx.export(model, input_dummy, save_file, opset_version=13,
                          input_names=['input'], output_names=['output'],
                          dynamic_axes={'input': {0: 'batch'}, 'output': {0: 'batch'}} if dynamic_batch else None)
```

æ‰§è¡ŒåŽæ•ˆæžœå¦‚ä¸‹ï¼š

![9fded8c52fb14152c5445db3ce933bb2](TensorRTé‡åŒ–å®žæˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(äºŒ)/9fded8c52fb14152c5445db3ce933bb2.png)

æˆ‘ä»¬å°†å¯¼å‡ºçš„ PTQ æ¨¡åž‹å’ŒåŽŸå§‹çš„ YOLOv7 æ¨¡åž‹å¯¹æ¯”ï¼Œ

![23a9074455dd319a5c73c8bc4ce233d6](TensorRTé‡åŒ–å®žæˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(äºŒ)/23a9074455dd319a5c73c8bc4ce233d6.png)

å·¦è¾¹æ˜¯æˆ‘ä»¬åŽŸå§‹çš„ ONNXï¼Œå³è¾¹æ˜¯æˆ‘ä»¬ PTQ æ¨¡åž‹çš„ ONNXï¼Œå¯ä»¥çœ‹åˆ°å¯¼å‡ºçš„ PTQ æ¨¡åž‹ä¸­å¤šäº† QDQ èŠ‚ç‚¹çš„æ’å…¥ï¼Œå…¶ä¸­åŒ…å«äº†æ ¡å‡†é‡åŒ–ä¿¡æ¯ scaleã€‚

ä»¥ä¸Šå°±æ˜¯ torch å’Œ PTQ æ¨¡åž‹çš„å¯¹æ¯”ï¼Œä¸‹é¢æˆ‘ä»¬æ¥è¿›è¡Œæ•æ„Ÿå±‚çš„åˆ†æžã€‚

# 3\. æ•æ„Ÿå±‚åˆ†æž

æˆ‘ä»¬å…ˆæ¢³ç†ä¸‹æ•æ„Ÿå±‚åˆ†æžçš„æµç¨‹ï¼š

*   **1.** for å¾ªçŽ¯ model çš„æ¯ä¸€ä¸ª quantizer å±‚
*   **2.** åªå…³é—­è¯¥å±‚çš„é‡åŒ–ï¼Œå…¶ä½™å±‚çš„é‡åŒ–ä¿ç•™
*   **3.** éªŒè¯æ¨¡åž‹çš„ç²¾åº¦ï¼Œevaluate\_coco(), å¹¶ä¿å­˜ç²¾åº¦å€¼
*   **4.** éªŒè¯ç»“æŸï¼Œé‡å¯è¯¥å±‚çš„é‡åŒ–æ“ä½œ
*   **5.** for å¾ªçŽ¯ç»“æŸï¼Œå¾—åˆ°æ‰€æœ‰å±‚çš„ç²¾åº¦å€¼
*   **6.** æŽ’åºï¼Œå¾—åˆ°å‰ 10 ä¸ªå¯¹ç²¾åº¦å½±å“æ¯”è¾ƒå¤§çš„å±‚ï¼Œå°†è¿™äº›å±‚è¿›è¡Œæ‰“å°è¾“å‡º

ç±»ä¼¼äºŽæŽ§åˆ¶å˜é‡æ³•ï¼Œå…³é—­æŸä¸€å±‚çš„é‡åŒ–çœ‹ç²¾åº¦ä¸‹é™å¹…åº¦ï¼Œé€‰å‡ºå¯¹ç²¾åº¦å½±å“æœ€å¤§çš„å‡ ä¸ªå±‚ä½œä¸ºæ•æ„Ÿå±‚ã€‚

æˆ‘ä»¬æ¥æŒ‰ç…§ä¸Šè¿°æµç¨‹ç¼–å†™ä»£ç å³å¯ï¼Œé¦–å…ˆæ˜¯ **sensitive\_analysis** å‡½æ•°çš„å®žçŽ°ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
def sensitive_analysis(model, loader):
    
    save_file = "senstive_analysis.json"

    summary =  SummaryTools(save_file)

    # for å¾ªçŽ¯æ¯ä¸€ä¸ªå±‚
    print(f"Sensitive analysis by each layer...")
    for i in range(0, len(model.model)):
        layer = model.model[i]
        # åˆ¤æ–­ layer æ˜¯å¦æ˜¯é‡åŒ–å±‚
        if have_quantizer(layer):   # å¦‚æžœæ˜¯é‡åŒ–å±‚
            # ä½¿è¯¥å±‚çš„é‡åŒ–å¤±æ•ˆï¼Œä¸è¿›è¡Œ int8 çš„é‡åŒ–ï¼Œä½¿ç”¨ fp16 ç²¾åº¦è¿ç®—
            disable_quantization(layer).apply()

            # è®¡ç®— map å€¼
            ap = evaluate_coco(model, loader )

            # ä¿å­˜ç²¾åº¦å€¼ï¼Œjson æ–‡ä»¶
            summary.append([ap, f"model.{i}"])
            print(f"layer {i} ap: {ap}")

            # é‡å¯å±‚çš„é‡åŒ–ï¼Œè¿˜åŽŸ
            enable_quantization(layer).apply()
            
        else:
            print(f"ignore model.{i} because it is {type(layer)}")

    # å¾ªçŽ¯ç»“æŸï¼Œæ‰“å°å‰ 10 ä¸ªå½±å“æ¯”è¾ƒå¤§çš„å±‚
    summary = sorted(summary.data, key=lambda x: x[0], reverse=True)
    print("Sensitive Summary")
    for n, (ap, name) in enumerate(summary[:10]):
        print(f"Top{n}: Using fp16 {name}, ap = {ap:.5f}")
```

è¯¥å‡½æ•°æ˜¯æ•æ„Ÿå±‚åˆ†æžçš„ä¸»è¦å‡½æ•°ï¼Œå…¶å…·ä½“å®žçŽ°æµç¨‹å¦‚ä¸‹ï¼š

*   å¾ªçŽ¯éåŽ†æ¨¡åž‹çš„æ¯ä¸€å±‚ï¼Œé€šè¿‡ä½¿ç”¨ **have\_quantizer** å‡½æ•°æ¥æ£€æŸ¥å±‚æ˜¯å¦ä¸ºé‡åŒ–å±‚
*   ä½¿ç”¨ **disable\_quantization** å’Œ **enable\_quantization** ç±»æ¥å…³é—­å’Œé‡å¯é‡åŒ–
*   ä½¿ç”¨ä¹‹å‰çš„ **evaluate\_coco** å‡½æ•°æ¥è®¡ç®— mAP å€¼
*   ä½¿ç”¨ **SummaryTools** ç±»æ¥ä¿å­˜æ¯å±‚çš„è¯„ä¼°ç»“æžœ
*   æœ€åŽæ‰“å°å‰ 10 ä¸ªå¯¹ç²¾åº¦å½±å“æœ€å¤§çš„å±‚

ä¸‹é¢æˆ‘ä»¬æ¥çœ‹çœ‹å…¶ä¸­è°ƒç”¨çš„å‡½æ•°å’Œç±»çš„å…·ä½“å®žçŽ°

é¦–å…ˆæ˜¯ **have\_quantizer** å‡½æ•°ï¼Œå…¶å…·ä½“å®žçŽ°å¦‚ä¸‹ï¼š

```python
# åˆ¤æ–­å±‚æ˜¯å¦æ˜¯é‡åŒ–å±‚
def have_quantizer(layer):
    for name, module in layer.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            return True

    return False
```

è¯¥å‡½æ•°çš„åŠŸèƒ½æ˜¯æ£€æŸ¥ä¼ å…¥çš„å±‚æ˜¯å¦ä¸ºé‡åŒ–å±‚ï¼Œé€šè¿‡éåŽ†è¯¥å±‚çš„æ‰€æœ‰æ¨¡å—ï¼Œæ£€æµ‹æ˜¯å¦æœ‰ **quant\_nn.TensorQuantizer** çš„æ¨¡å—ï¼Œå¦‚æžœæœ‰åˆ™è¿”å›ž Trueï¼Œä»£è¡¨è¯¥å±‚ä¸ºé‡åŒ–å±‚ï¼Œå¦åˆ™è¿”å›ž Falseã€‚

ç„¶åŽæ˜¯ **disable\_quantization** å’Œ **enable\_quantization** ç±»ï¼Œå…¶å…·ä½“å®žçŽ°å¦‚ä¸‹ï¼š

```python
class disable_quantization:

    # åˆå§‹åŒ–
    def __init__(self, model):
        self.model = model

    # åº”ç”¨ å…³é—­é‡åŒ–
    def apply(self, disabled=True):
        for name, module in self.model.named_modules():
            if isinstance(module, quant_nn.TensorQuantizer):
                module._disabled = disabled

    def __enter__(self):
        self.apply(disabled=True)
    
    def __exit__(self, *args, **kwargs):
        self.apply(disabled=False)

# é‡å¯é‡åŒ–
class enable_quantization:
    def __init__(self, model):
        self.model = model
    
    def apply(self, enabled=True):
        for name, module in self.model.named_modules():
            if isinstance(module, quant_nn.TensorQuantizer):
                module._disabled = not enabled
            
    def __enter__(self):
        self.apply(enabled=True)
        return self

    def __exit__(self, *args, **kwargs):
        self.apply(enabled=False) 
```

å®ƒä»¬çš„åŠŸèƒ½æ˜¯åˆ†åˆ«ç”¨äºŽä¸´æ—¶å…³é—­å’Œé‡å¯æ¨¡åž‹ä¸­çš„é‡åŒ–æ“ä½œã€‚è¿™ä¸¤ä¸ªç±»åœ¨æž„é€ æ—¶ä¼šæŽ¥æ”¶æ¨¡åž‹å¯¹è±¡ï¼Œå¹¶åœ¨ **apply** æ–¹æ³•ä¸­éåŽ†æ¨¡åž‹çš„æ‰€æœ‰æ¨¡å—ï¼Œæ ¹æ®é‡åŒ–çŠ¶æ€ï¼ˆå¯ç”¨/ç¦ç”¨ï¼‰è®¾ç½® **module.\_disabled** å±žæ€§ã€‚

æœ€åŽæ˜¯ **SummaryTools** ç±»ï¼Œå…¶å®žçŽ°å¦‚ä¸‹ï¼š

```python
import json
class SummaryTools:

    def __init__(self, file):
        self.file = file
        self.data = []
    
    def append(self, item):
        self.data.append(item)
        json.dump(self.data, open(self.file, "w"), indent=4)
```

è¯¥ç±»çš„åŠŸèƒ½æ˜¯ç”¨äºŽä¿å­˜æ¯å±‚çš„ mAP ç»“æžœã€‚åœ¨å…¶ **append** æ–¹æ³•ä¸­ä¼šæ·»åŠ  mAP ç»“æžœåˆ°å†…éƒ¨æ•°æ®åˆ—è¡¨ï¼Œå¹¶å°†è¿™äº›æ•°æ®ä¿å­˜åˆ° JSON æ–‡ä»¶ä¸­ã€‚

å®Œæ•´çš„æ•æ„Ÿå±‚åˆ†æžä»£ç å¦‚ä¸‹ï¼š

```python
import os
import yaml
import test
import torch
import collections
from pathlib import Path
from models.yolo import Model
from pytorch_quantization import calib
from absl import logging as quant_logging
from utils.datasets import create_dataloader
from pytorch_quantization import quant_modules
from pytorch_quantization import nn as quant_nn
from pytorch_quantization.tensor_quant import QuantDescriptor
from pytorch_quantization.nn.modules import _utils as quant_nn_utils

def load_yolov7_model(weight, device='cpu'):
    ckpt  = torch.load(weight, map_location=device)
    model = Model("cfg/training/yolov7.yaml", ch=3, nc=80).to(device)
    state_dict = ckpt['model'].float().state_dict()
    model.load_state_dict(state_dict, strict=False)
    return model

def prepare_val_dataset(cocodir, batch_size=32):
    dataloader = create_dataloader(
        f"{cocodir}/val2017.txt",
        imgsz=640,
        batch_size=batch_size,
        opt=collections.namedtuple("Opt", "single_cls")(False),
        augment=False, hyp=None, rect=True, cache=False, stride=32, pad=0.5, image_weights=False
    )[0]
    return dataloader

def prepare_train_dataset(cocodir, batch_size=32):
    
    with open("data/hyp.scratch.p5.yaml") as f:
        hyp = yaml.load(f, Loader=yaml.SafeLoader)

    dataloader = create_dataloader(
        f"{cocodir}/train2017.txt",
        imgsz=640,
        batch_size=batch_size,
        opt=collections.namedtuple("Opt", "single_cls")(False),
        augment=True, hyp=hyp, rect=True, cache=False, stride=32, pad=0, image_weights=False
    )[0]
    return dataloader

# input: Max ==> Histogram
def initialize():
    quant_desc_input = QuantDescriptor(calib_method='histogram')
    quant_nn.QuantConv2d.set_default_quant_desc_input(quant_desc_input)
    quant_nn.QuantMaxPool2d.set_default_quant_desc_input(quant_desc_input)
    quant_nn.QuantLinear.set_default_quant_desc_input(quant_desc_input)

    quant_logging.set_verbosity(quant_logging.ERROR)

def prepare_model(weight, device):
    # quant_modules.initialize()
    initialize()
    model = load_yolov7_model(weight, device)
    model.float()
    model.eval()
    with torch.no_grad():
        model.fuse()    # conv bn è¿›è¡Œå±‚çš„åˆå¹¶, åŠ é€Ÿ
    return model

def tranfer_torch_to_quantization(nn_instance, quant_module):
    
    quant_instances = quant_module.__new__(quant_module)

    # å±žæ€§èµ‹å€¼
    for k, val in vars(nn_instance).items():
        setattr(quant_instances, k, val)

    # åˆå§‹åŒ–
    def __init__(self):
        # è¿”å›žä¸¤ä¸ª QuantDescriptor çš„å®žä¾‹ self.__class__ æ˜¯ quant_instance çš„ç±», QuantConv2d
        quant_desc_input, quant_desc_weight = quant_nn_utils.pop_quant_desc_in_kwargs(self.__class__)
        if isinstance(self, quant_nn_utils.QuantInputMixin):
            self.init_quantizer(quant_desc_input)
            # åŠ å¿«é‡åŒ–é€Ÿåº¦
            if isinstance(self._input_quantizer._calibrator, calib.HistogramCalibrator):
                self._input_quantizer._calibrator._torch_hist = True
        else:
            self.init_quantizer(quant_desc_input, quant_desc_weight)
            if isinstance(self._input_quantizer._calibrator, calib.HistogramCalibrator):
                self._input_quantizer._calibrator._torch_hist = True
                self._weight_quantizer._calibrator._torch_hist = True

    __init__(quant_instances)
    return quant_instances

import re
def quantization_ignore_match(ignore_layer, path):
    if ignore_layer is None:
        return False
    if isinstance(ignore_layer, str) or isinstance(ignore_layer, list):
        if isinstance(ignore_layer, str):
            ignore_layer = [ignore_layer]
        if path in ignore_layer:
            return True
        for item in ignore_layer:
            if re.match(item, path):
                return True
    return False

def torch_module_find_quant_module(model, module_list, ignore_layer, prefix=''):
    for name in model._modules:
        submodule = model._modules[name]
        path = name if prefix == '' else prefix + '.' + name
        torch_module_find_quant_module(submodule, module_list, ignore_layer, prefix=path) # é€’å½’

        submodule_id = id(type(submodule))
        if submodule_id in module_list:
            ignored = quantization_ignore_match(ignore_layer, path)
            if ignored:
                print(f"Quantization : {path} has ignored.")
                continue
            # è½¬æ¢
            model._modules[name] = tranfer_torch_to_quantization(submodule, module_list[submodule_id])
        
def replace_to_quantization_model(model, ignore_layer=None):
    
    module_list = {}
    
    for entry in quant_modules._DEFAULT_QUANT_MAP:
        module = getattr(entry.orig_mod, entry.mod_name)  # module -> torch.nn.modules.conv.Conv1d
        module_list[id(module)] = entry.replace_mod
    
    torch_module_find_quant_module(model, module_list, ignore_layer)


def evaluate_coco(model, loader, save_dir='', conf_thres=0.001, iou_thres=0.65):
    
    if save_dir and os.path.dirname(save_dir) != "":
        os.makedirs(os.path.dirname(save_dir), exist_ok=True)
    
    return test.test(
        "data/coco.yaml",
        save_dir=Path(save_dir),
        conf_thres=conf_thres,
        iou_thres=iou_thres,
        model=model,
        dataloader=loader,
        is_coco=True,
        plots=False,
        half_precision=True,
        save_json=False
    )[0][3]

def collect_stats(model, data_loader, device, num_batch = 200):
    model.eval()

    # å¼€å¯æ ¡å‡†å™¨
    for name, module in model.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            if module._calibrator is not None:
                module.disable_quant()
                module.enable_calib()
            else:
                module.disable()

    # test
    with torch.no_grad():
        for i, datas in enumerate(data_loader):
            imgs = datas[0].to(device, non_blocking=True).float() / 255.0
            model(imgs)

            if i >= num_batch:
                break
    
    # å…³é—­æ ¡å‡†å™¨
    for name, module in model.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            if module._calibrator is not None:
                module.enable_quant()
                module.disable_calib()
            else:
                module.enable()
            
def compute_amax(model, **kwargs):
    
    for name, module in model.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            if module._calibrator is not None:
                if isinstance(module._calibrator, calib.MaxCalibrator):
                    module.load_calib_amax()
                else:
                    module.load_calib_amax(**kwargs)
                module._amax = module._amax.to(device)


def calibrate_model(model, dataloader, device):

    # æ”¶é›†å‰å‘ä¿¡æ¯
    collect_stats(model, dataloader, device)

    # èŽ·å–åŠ¨æ€èŒƒå›´ï¼Œè®¡ç®— amax å€¼ï¼Œscale å€¼
    compute_amax(model, method = 'mse')

def export_ptq(model, save_file, device, dynamic_batch = True):
    
    input_dummy = torch.randn(1, 3, 640, 640, device=device)
    
    # æ‰“å¼€ fake ç®—å­
    quant_nn.TensorQuantizer.use_fb_fake_quant = True

    model.eval()

    with torch.no_grad():
        torch.onnx.export(model, input_dummy, save_file, opset_version=13,
                          input_names=['input'], output_names=['output'],
                          dynamic_axes={'input': {0: 'batch'}, 'output': {0: 'batch'}} if dynamic_batch else None)

    quant_nn.TensorQuantizer.use_fb_fake_quant = False

# åˆ¤æ–­å±‚æ˜¯å¦æ˜¯é‡åŒ–å±‚
def have_quantizer(layer):
    for name, module in layer.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            return True

    return False

class disable_quantization:

    # åˆå§‹åŒ–
    def __init__(self, model):
        self.model = model

    # åº”ç”¨ å…³é—­é‡åŒ–
    def apply(self, disabled=True):
        for name, module in self.model.named_modules():
            if isinstance(module, quant_nn.TensorQuantizer):
                module._disabled = disabled

    def __enter__(self):
        self.apply(disabled=True)
    
    def __exit__(self, *args, **kwargs):
        self.apply(disabled=False)

# é‡å¯é‡åŒ–
class enable_quantization:
    def __init__(self, model):
        self.model = model
    
    def apply(self, enabled=True):
        for name, module in self.model.named_modules():
            if isinstance(module, quant_nn.TensorQuantizer):
                module._disabled = not enabled
            
    def __enter__(self):
        self.apply(enabled=True)
        return self

    def __exit__(self, *args, **kwargs):
        self.apply(enabled=False)    

import json
class SummaryTools:

    def __init__(self, file):
        self.file = file
        self.data = []
    
    def append(self, item):
        self.data.append(item)
        json.dump(self.data, open(self.file, "w"), indent=4)


def sensitive_analysis(model, loader):
    
    save_file = "senstive_analysis.json"

    summary =  SummaryTools(save_file)

    # for å¾ªçŽ¯æ¯ä¸€ä¸ªå±‚
    print(f"Sensitive analysis by each layer...")
    for i in range(0, len(model.model)):
        layer = model.model[i]
        # åˆ¤æ–­ layer æ˜¯å¦æ˜¯é‡åŒ–å±‚
        if have_quantizer(layer):   # å¦‚æžœæ˜¯é‡åŒ–å±‚
            # ä½¿è¯¥å±‚çš„é‡åŒ–å¤±æ•ˆï¼Œä¸è¿›è¡Œ int8 çš„é‡åŒ–ï¼Œä½¿ç”¨ fp16 ç²¾åº¦è¿ç®—
            disable_quantization(layer).apply()

            # è®¡ç®— map å€¼
            ap = evaluate_coco(model, loader )

            # ä¿å­˜ç²¾åº¦å€¼ï¼Œjson æ–‡ä»¶
            summary.append([ap, f"model.{i}"])
            print(f"layer {i} ap: {ap}")

            # é‡å¯å±‚çš„é‡åŒ–ï¼Œè¿˜åŽŸ
            enable_quantization(layer).apply()
            
        else:
            print(f"ignore model.{i} because it is {type(layer)}")

    # å¾ªçŽ¯ç»“æŸï¼Œæ‰“å°å‰ 10 ä¸ªå½±å“æ¯”è¾ƒå¤§çš„å±‚
    summary = sorted(summary.data, key=lambda x: x[0], reverse=True)
    print("Sensitive Summary")
    for n, (ap, name) in enumerate(summary[:10]):
        print(f"Top{n}: Using fp16 {name}, ap = {ap:.5f}")


if __name__ == "__main__":

    weight = "yolov7.pt"
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    # åŠ è½½æ•°æ®
    print("Evalute Dataset...")
    cocodir = "dataset/coco2017"
    val_dataloader   = prepare_val_dataset(cocodir)
    train_dataloader = prepare_train_dataset(cocodir)

    # åŠ è½½ pth æ¨¡åž‹
    # pth_model = load_yolov7_model(weight, device)
    # pth æ¨¡åž‹éªŒè¯
    # print("Evalute Origin...")
    # ap = evaluate_coco(pth_model, val_dataloader)

    # èŽ·å–ä¼ªé‡åŒ–æ¨¡åž‹(æ‰‹åŠ¨ initial(), æ‰‹åŠ¨æ’å…¥ QDQ)
    model = prepare_model(weight, device)
    replace_to_quantization_model(model)

    # æ¨¡åž‹æ ‡å®š
    calibrate_model(model, train_dataloader, device)

    # æ•æ„Ÿå±‚åˆ†æž
    """
    æµç¨‹:
    1. for å¾ªçŽ¯ model çš„æ¯ä¸€ä¸ª quantizer å±‚
    2. åªå…³é—­è¯¥å±‚çš„é‡åŒ–ï¼Œå…¶ä½™å±‚çš„é‡åŒ–ä¿ç•™
    3. éªŒè¯æ¨¡åž‹çš„ç²¾åº¦, evaluate_coco(), å¹¶ä¿å­˜ç²¾åº¦å€¼
    4. éªŒè¯ç»“æŸï¼Œé‡å¯è¯¥å±‚çš„é‡åŒ–æ“ä½œ
    5. for å¾ªçŽ¯ç»“æŸï¼Œå¾—åˆ°æ‰€æœ‰å±‚çš„ç²¾åº¦å€¼
    6. æŽ’åºï¼Œå¾—åˆ°å‰ 10 ä¸ªå¯¹ç²¾åº¦å½±å“æ¯”è¾ƒå¤§çš„å±‚ï¼Œå°†è¿™äº›å±‚è¿›è¡Œæ‰“å°è¾“å‡º
    """
    sensitive_analysis(model, val_dataloader)
    
    # PTQ æ¨¡åž‹éªŒè¯
    # print("Evaluate PTQ...")
    # ptq_ap = evaluate_coco(model, val_dataloader)

    # PTQ æ¨¡åž‹å¯¼å‡º
    # print("Export PTQ...")

    # export_ptq(model, "ptq_yolov7.onnx", device)
```

åœ¨ä»£ç ä¸­æˆ‘ä»¬å…³é—­äº†æŸäº›ä¸å¿…è¦çš„æ“ä½œï¼Œæ‰§è¡ŒåŽè¿è¡Œæ•ˆæžœå¦‚ä¸‹ï¼š

![9b42b85a0aa80b64c6f0071e7277a486](TensorRTé‡åŒ–å®žæˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(äºŒ)/9b42b85a0aa80b64c6f0071e7277a486.png)

ä»Žä¸Šå›¾ä¸­å¯ä»¥çœ‹å‡ºå®ƒä¼šè®¡ç®—æ¯å±‚å…³é—­é‡åŒ–åŽçš„ mAP å€¼ï¼Œæ¯å±‚çš„ mAP å€¼éƒ½ä¸ä¸€æ ·ï¼Œè¿™è¯´æ˜Žä¸åŒå±‚é‡åŒ–å¯¹æœ€ç»ˆç²¾åº¦å½±å“çš„æ•ˆæžœä¸åŒï¼Œæœ€åŽæˆ‘ä»¬ä¼šå°†æ¯å±‚çš„ mAP å€¼éƒ½ä¿å­˜å¹¶ç»Ÿè®¡å‰ 10 ä¸ªå¯¹ç²¾åº¦å½±å“æœ€å¤§çš„å±‚ã€‚

æ•æ„Ÿå±‚çš„åˆ†æžç­‰å¾…æ—¶é—´ä¼šæ¯”è¾ƒä¹…ï¼Œå› ä¸ºæ¯å±‚éƒ½è¦åŽ»è®¡ç®— mAP å€¼ã€‚ç”±äºŽåšä¸»[ç¡¬ä»¶](https://marketing.csdn.net/p/3127db09a98e0723b83b2914d9256174?pId=2782?utm_source=glcblog&spm=1001.2101.3001.7020)çš„åŽŸå› ï¼Œæ²¡æœ‰è·‘å®Œæ‰€æœ‰å±‚çš„åˆ†æžï¼ŒåŽç»­æ˜¯ç›´æŽ¥é€‰ç”¨è§†é¢‘ä¸­çš„ 10 ä¸ªå±‚ä½œä¸ºæ•æ„Ÿå±‚ã€‚

è§†é¢‘ä¸­åˆ†æžå‡ºæ¥çš„å‰ 10 ä¸ªæ•æ„Ÿå±‚å¦‚ä¸‹ï¼š

```python
ignore_layer = ["model\.104\.(.*)", "model\.37\.(.*)", "model\.2\.(.*)", "model\.1\.(.*)", "model\.77\.(.*)",
                "model\.99\.(.*)", "model\.70\.(.*)", "model\.95\.(.*)", "model\.92\.(.*)", "model\.81\.(.*)"]
```

OKï¼ä¸Šé¢æˆ‘ä»¬å¯¹æ•æ„Ÿå±‚è¿›è¡Œäº†ä¸€ä¸ªåˆ†æžï¼Œå¹¶ä¸”å°†å‰ 10 ä¸ªå¯¹ç²¾åº¦å½±å“æœ€å¤§çš„å±‚è¿›è¡Œäº†æ‰“å°ï¼ŒæŽ¥ä¸‹æ¥æˆ‘ä»¬å°†å¤„ç†æ•æ„Ÿå±‚åˆ†æžå‡ºæ¥çš„ç»“æžœï¼Œå¯¹ç²¾åº¦å½±å“è¾ƒå¤§çš„å±‚å…³é—­å®ƒçš„é‡åŒ–ï¼Œä½¿ç”¨ FP16 è¿›è¡Œè®¡ç®—

æˆ‘ä»¬åœ¨è¿›è¡Œ PTQ é‡åŒ–å‰å°±è¦è¿›è¡Œæ•æ„Ÿå±‚çš„åˆ†æžï¼Œå¾—åˆ°å½±å“æ¯”è¾ƒå¤§çš„å±‚ï¼Œç„¶åŽåœ¨ä½¿ç”¨æ‰‹åŠ¨æ’å…¥ QDQ é‡åŒ–èŠ‚ç‚¹çš„æ—¶å€™å°†è¿™äº›æ•æ„Ÿå±‚ä¼ é€’è¿›æ¥ï¼Œå°†å…¶é‡åŒ–è¿›è¡Œå…³é—­ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬å¯¹æ•æ„Ÿå±‚çš„å¤„ç†ã€‚

å› æ­¤æˆ‘ä»¬åœ¨ä¹‹å‰çš„ **replace\_to\_quantization\_model** å‡½æ•°ä¸­éœ€è¦å¤šä¼ å…¥ä¸€ä¸ªå‚æ•°ï¼Œå³ä¸Šé¢çš„æ•æ„Ÿå±‚åˆ—è¡¨ï¼Œä¿®æ”¹åŽçš„å‡½æ•°å…·ä½“å®žçŽ°å¦‚ä¸‹ï¼š

```python
def replace_to_quantization_model(model, ignore_layer=None):
    
    module_list = {}
    
    for entry in quant_modules._DEFAULT_QUANT_MAP:
        module = getattr(entry.orig_mod, entry.mod_name)  # module -> torch.nn.modules.conv.Conv1d
        module_list[id(module)] = entry.replace_mod
    
    torch_module_find_quant_module(model, module_list, ignore_layer)
```

æŽ¥ç€æˆ‘ä»¬ä¼šå°† **ignore\_layer** åˆ—è¡¨ä¼ å…¥åˆ° **torch\_module\_find\_quant\_module** å‡½æ•°ä¸­ï¼Œåœ¨é‡åŒ–è½¬æ¢æ—¶å¿½ç•¥è¿™äº›å±‚ï¼Œä¿®æ”¹åŽçš„å‡½æ•°å…·ä½“å®žçŽ°å¦‚ä¸‹ï¼š

```python
def torch_module_find_quant_module(model, module_list, ignore_layer, prefix=''):
    for name in model._modules:
        submodule = model._modules[name]
        path = name if prefix == '' else prefix + '.' + name
        torch_module_find_quant_module(submodule, module_list, ignore_layer, prefix=path) # é€’å½’

        submodule_id = id(type(submodule))
        if submodule_id in module_list:
            ignored = quantization_ignore_match(ignore_layer, path)
            if ignored:
                print(f"Quantization : {path} has ignored.")
                continue
            # è½¬æ¢
            model._modules[name] = tranfer_torch_to_quantization(submodule, module_list[submodule_id])
```

è¯¥å‡½æ•°åŠŸèƒ½è¿˜æ˜¯éåŽ†æ¨¡åž‹çš„æ¯ä¸ªå­æ¨¡å—ï¼Œæ£€æŸ¥æ˜¯å¦åº”è¯¥è¿›è¡Œé‡åŒ–è½¬æ¢ã€‚ä½†ä¸Žä¹‹å‰ä¸åŒçš„æ˜¯æˆ‘ä»¬æ–°å¢žäº†ä¸€ä¸ªåˆ¤æ–­ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ **quantization\_ignore\_match** å‡½æ•°æ¥åˆ¤æ–­å½“å‰å­æ¨¡å—æ˜¯å¦åœ¨ **ignore\_layer** åˆ—è¡¨ä¸­ï¼Œå¦‚æžœåœ¨åˆ™è·³è¿‡é‡åŒ–è½¬æ¢å¼€å§‹ä¸‹ä¸€ä¸ªæ¨¡å—ï¼Œå¦‚æžœä¸åœ¨åˆ™æ‰§è¡Œé‡åŒ–è½¬æ¢ã€‚

**quantization\_ignore\_match** çš„å…·ä½“å®žçŽ°å¦‚ä¸‹ï¼š

```python
import re
def quantization_ignore_match(ignore_layer, path):
    if ignore_layer is None:
        return False
    if isinstance(ignore_layer, str) or isinstance(ignore_layer, list):
        if isinstance(ignore_layer, str):
            ignore_layer = [ignore_layer]
        if path in ignore_layer:
            return True
        for item in ignore_layer:
            if re.match(item, path):
                return True
    return False
```

è¯¥å‡½æ•°çš„åŠŸèƒ½æ˜¯åˆ¤æ–­æ¨¡åž‹ä¸­çš„æŸä¸€ä¸ªå±‚æ˜¯å¦åœ¨ **ignore\_layer** åˆ—è¡¨ä¸­ï¼Œå³æ˜¯å¦åº”è¯¥å¿½ç•¥è¯¥å±‚çš„é‡åŒ–ï¼Œè¿”å›žå€¼æ˜¯ä¸€ä¸ªå¸ƒå°”å€¼ã€‚**ignore\_layer** å¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ **re.match** æ¥æ£€æŸ¥ **path** æ˜¯å¦èƒ½å’Œ **ignore\_layer** åˆ—è¡¨ä¸­çš„å…ƒç´ åŒ¹é…ä¸Šã€‚

æˆ‘ä»¬å°†ä¸Šè¿°ä»£ç ä¿®æ”¹å¥½åŽï¼Œå†æ¥æµ‹è¯•ä¸‹ï¼Œçœ‹å¿½ç•¥è¿™äº›å±‚åŽé‡åŒ–èŠ‚ç‚¹çš„æ’å…¥æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼Œæµ‹è¯•çš„è¿è¡Œæ•ˆæžœå¦‚ä¸‹ï¼š

![ba68500dd729d1e17a0d5f6f5e5cd043](TensorRTé‡åŒ–å®žæˆ˜è¯¾YOLOv7é‡åŒ–ï¼šYOLOv7-PTQé‡åŒ–(äºŒ)/ba68500dd729d1e17a0d5f6f5e5cd043.png)

å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æ‰“å°äº†å¿½ç•¥æŸäº›å±‚çš„é‡åŒ–åŽæ’å…¥ QDQ èŠ‚ç‚¹çš„æ¨¡åž‹ç»“æž„ï¼Œæˆ‘ä»¬ä»Žå›¾ä¸­å¯ä»¥çœ‹åˆ° 99 å±‚æ˜¯æˆ‘ä»¬å¿½ç•¥çš„å±‚ï¼Œå®ƒå¹¶æ²¡æœ‰ \_input\_quantizer å’Œ \_weight\_quantizerï¼Œè¯´æ˜Žå®ƒå¹¶æ²¡æœ‰è¢«æ’å…¥é‡åŒ–èŠ‚ç‚¹ï¼Œä½¿ç”¨çš„æ˜¯ FP16 çš„è®¡ç®—ï¼ŒåŒç† 104 å±‚ä¹Ÿæ˜¯å¦‚æ­¤ã€‚

é‚£ä»¥ä¸Šå°±æ˜¯æ•æ„Ÿå±‚çš„åˆ†æžï¼Œä»¥åŠæˆ‘ä»¬æ ¹æ®æ•æ„Ÿå±‚çš„ç»“æžœå¯¹æ•æ„Ÿå±‚çš„é‡åŒ–è¿›è¡Œå…³é—­çš„å†…å®¹äº†ã€‚

ä¸‹é¢æˆ‘ä»¬å†æ¥æ¢³ç†ä¸‹ PTQ é‡åŒ–

## 4\. PTQé‡åŒ–

è¿™èŠ‚æˆ‘ä»¬å°† PTQ çš„ä»£ç è¿›è¡Œå·¥ç¨‹åŒ–

é¦–å…ˆç¼–å†™ä¸€ä¸ª **quantize.py** å°†æˆ‘ä»¬ä¹‹å‰çš„ç¼–å†™çš„å‡½æ•°å’Œç±»æ”¾å…¥å…¶ä¸­ï¼Œå…¶å…·ä½“å†…å®¹å¦‚ä¸‹ï¼š

```python
import os
import yaml
import test
import json
import torch
import collections
from pathlib import Path
from models.yolo import Model
from pytorch_quantization import calib
from absl import logging as quant_logging
from utils.datasets import create_dataloader
from pytorch_quantization import quant_modules
from pytorch_quantization import nn as quant_nn
from pytorch_quantization.tensor_quant import QuantDescriptor
from pytorch_quantization.nn.modules import _utils as quant_nn_utils

def load_yolov7_model(weight, device='cpu'):
    ckpt  = torch.load(weight, map_location=device)
    model = Model("cfg/training/yolov7.yaml", ch=3, nc=80).to(device)
    state_dict = ckpt['model'].float().state_dict()
    model.load_state_dict(state_dict, strict=False)
    return model

def prepare_val_dataset(cocodir, batch_size=32):
    dataloader = create_dataloader(
        f"{cocodir}/val2017.txt",
        imgsz=640,
        batch_size=batch_size,
        opt=collections.namedtuple("Opt", "single_cls")(False),
        augment=False, hyp=None, rect=True, cache=False, stride=32, pad=0.5, image_weights=False
    )[0]
    return dataloader

def prepare_train_dataset(cocodir, batch_size=32):
    
    with open("data/hyp.scratch.p5.yaml") as f:
        hyp = yaml.load(f, Loader=yaml.SafeLoader)

    dataloader = create_dataloader(
        f"{cocodir}/train2017.txt",
        imgsz=640,
        batch_size=batch_size,
        opt=collections.namedtuple("Opt", "single_cls")(False),
        augment=True, hyp=hyp, rect=True, cache=False, stride=32, pad=0, image_weights=False
    )[0]
    return dataloader

# input: Max ==> Histogram
def initialize():
    quant_desc_input = QuantDescriptor(calib_method='histogram')
    quant_nn.QuantConv2d.set_default_quant_desc_input(quant_desc_input)
    quant_nn.QuantMaxPool2d.set_default_quant_desc_input(quant_desc_input)
    quant_nn.QuantLinear.set_default_quant_desc_input(quant_desc_input)

    quant_logging.set_verbosity(quant_logging.ERROR)

def prepare_model(weight, device):
    # quant_modules.initialize()
    initialize()
    model = load_yolov7_model(weight, device)
    model.float()
    model.eval()
    with torch.no_grad():
        model.fuse()    # conv bn è¿›è¡Œå±‚çš„åˆå¹¶, åŠ é€Ÿ
    return model

def tranfer_torch_to_quantization(nn_instance, quant_module):
    
    quant_instances = quant_module.__new__(quant_module)

    # å±žæ€§èµ‹å€¼
    for k, val in vars(nn_instance).items():
        setattr(quant_instances, k, val)

    # åˆå§‹åŒ–
    def __init__(self):
        # è¿”å›žä¸¤ä¸ª QuantDescriptor çš„å®žä¾‹ self.__class__ æ˜¯ quant_instance çš„ç±», QuantConv2d
        quant_desc_input, quant_desc_weight = quant_nn_utils.pop_quant_desc_in_kwargs(self.__class__)
        if isinstance(self, quant_nn_utils.QuantInputMixin):
            self.init_quantizer(quant_desc_input)
            # åŠ å¿«é‡åŒ–é€Ÿåº¦
            if isinstance(self._input_quantizer._calibrator, calib.HistogramCalibrator):
                self._input_quantizer._calibrator._torch_hist = True
        else:
            self.init_quantizer(quant_desc_input, quant_desc_weight)
            if isinstance(self._input_quantizer._calibrator, calib.HistogramCalibrator):
                self._input_quantizer._calibrator._torch_hist = True
                self._weight_quantizer._calibrator._torch_hist = True

    __init__(quant_instances)
    return quant_instances

import re
def quantization_ignore_match(ignore_layer, path):
    if ignore_layer is None:
        return False
    if isinstance(ignore_layer, str) or isinstance(ignore_layer, list):
        if isinstance(ignore_layer, str):
            ignore_layer = [ignore_layer]
        if path in ignore_layer:
            return True
        for item in ignore_layer:
            if re.match(item, path):
                return True
    return False

def torch_module_find_quant_module(model, module_list, ignore_layer, prefix=''):
    for name in model._modules:
        submodule = model._modules[name]
        path = name if prefix == '' else prefix + '.' + name
        torch_module_find_quant_module(submodule, module_list, ignore_layer, prefix=path) # é€’å½’

        submodule_id = id(type(submodule))
        if submodule_id in module_list:
            ignored = quantization_ignore_match(ignore_layer, path)
            if ignored:
                print(f"Quantization : {path} has ignored.")
                continue
            # è½¬æ¢
            model._modules[name] = tranfer_torch_to_quantization(submodule, module_list[submodule_id])
        
def replace_to_quantization_model(model, ignore_layer=None):
    
    module_list = {}
    
    for entry in quant_modules._DEFAULT_QUANT_MAP:
        module = getattr(entry.orig_mod, entry.mod_name)  # module -> torch.nn.modules.conv.Conv1d
        module_list[id(module)] = entry.replace_mod
    
    torch_module_find_quant_module(model, module_list, ignore_layer)


def evaluate_coco(model, loader, save_dir='', conf_thres=0.001, iou_thres=0.65):
    
    if save_dir and os.path.dirname(save_dir) != "":
        os.makedirs(os.path.dirname(save_dir), exist_ok=True)
    
    return test.test(
        "data/coco.yaml",
        save_dir=Path(save_dir),
        conf_thres=conf_thres,
        iou_thres=iou_thres,
        model=model,
        dataloader=loader,
        is_coco=True,
        plots=False,
        half_precision=True,
        save_json=False
    )[0][3]

def collect_stats(model, data_loader, device, num_batch = 200):
    model.eval()

    # å¼€å¯æ ¡å‡†å™¨
    for name, module in model.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            if module._calibrator is not None:
                module.disable_quant()
                module.enable_calib()
            else:
                module.disable()

    # test
    with torch.no_grad():
        for i, datas in enumerate(data_loader):
            imgs = datas[0].to(device, non_blocking=True).float() / 255.0
            model(imgs)

            if i >= num_batch:
                break
    
    # å…³é—­æ ¡å‡†å™¨
    for name, module in model.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            if module._calibrator is not None:
                module.enable_quant()
                module.disable_calib()
            else:
                module.enable()
            
def compute_amax(model, device, **kwargs):

    for name, module in model.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            if module._calibrator is not None:
                if isinstance(module._calibrator, calib.MaxCalibrator):
                    module.load_calib_amax()
                else:
                    module.load_calib_amax(**kwargs)
                module._amax = module._amax.to(device)


def calibrate_model(model, dataloader, device):

    # æ”¶é›†å‰å‘ä¿¡æ¯
    collect_stats(model, dataloader, device)

    # èŽ·å–åŠ¨æ€èŒƒå›´ï¼Œè®¡ç®— amax å€¼ï¼Œscale å€¼
    compute_amax(model, device, method = 'mse')

def export_ptq(model, save_file, device, dynamic_batch = True):
    
    input_dummy = torch.randn(1, 3, 640, 640, device=device)
    
    # æ‰“å¼€ fake ç®—å­
    quant_nn.TensorQuantizer.use_fb_fake_quant = True

    model.eval()

    with torch.no_grad():
        torch.onnx.export(model, input_dummy, save_file, opset_version=13,
                          input_names=['input'], output_names=['output'],
                          dynamic_axes={'input': {0: 'batch'}, 'output': {0: 'batch'}} if dynamic_batch else None)

    quant_nn.TensorQuantizer.use_fb_fake_quant = False

# åˆ¤æ–­å±‚æ˜¯å¦æ˜¯é‡åŒ–å±‚
def have_quantizer(layer):
    for name, module in layer.named_modules():
        if isinstance(module, quant_nn.TensorQuantizer):
            return True

    return False

class disable_quantization:

    # åˆå§‹åŒ–
    def __init__(self, model):
        self.model = model

    # åº”ç”¨ å…³é—­é‡åŒ–
    def apply(self, disabled=True):
        for name, module in self.model.named_modules():
            if isinstance(module, quant_nn.TensorQuantizer):
                module._disabled = disabled

    def __enter__(self):
        self.apply(disabled=True)
    
    def __exit__(self, *args, **kwargs):
        self.apply(disabled=False)

# é‡å¯é‡åŒ–
class enable_quantization:
    def __init__(self, model):
        self.model = model
    
    def apply(self, enabled=True):
        for name, module in self.model.named_modules():
            if isinstance(module, quant_nn.TensorQuantizer):
                module._disabled = not enabled
            
    def __enter__(self):
        self.apply(enabled=True)
        return self

    def __exit__(self, *args, **kwargs):
        self.apply(enabled=False)    

class SummaryTools:

    def __init__(self, file):
        self.file = file
        self.data = []
    
    def append(self, item):
        self.data.append(item)
        json.dump(self.data, open(self.file, "w"), indent=4)


def sensitive_analysis(model, loader):
    
    save_file = "senstive_analysis.json"

    summary =  SummaryTools(save_file)

    # for å¾ªçŽ¯æ¯ä¸€ä¸ªå±‚
    print(f"Sensitive analysis by each layer...")
    for i in range(0, len(model.model)):
        layer = model.model[i]
        # åˆ¤æ–­ layer æ˜¯å¦æ˜¯é‡åŒ–å±‚
        if have_quantizer(layer):   # å¦‚æžœæ˜¯é‡åŒ–å±‚
            # ä½¿è¯¥å±‚çš„é‡åŒ–å¤±æ•ˆï¼Œä¸è¿›è¡Œ int8 çš„é‡åŒ–ï¼Œä½¿ç”¨ fp16 ç²¾åº¦è¿ç®—
            disable_quantization(layer).apply()

            # è®¡ç®— map å€¼
            ap = evaluate_coco(model, loader )

            # ä¿å­˜ç²¾åº¦å€¼ï¼Œjson æ–‡ä»¶
            summary.append([ap, f"model.{i}"])
            print(f"layer {i} ap: {ap}")

            # é‡å¯å±‚çš„é‡åŒ–ï¼Œè¿˜åŽŸ
            enable_quantization(layer).apply()
            
        else:
            print(f"ignore model.{i} because it is {type(layer)}")

    # å¾ªçŽ¯ç»“æŸï¼Œæ‰“å°å‰ 10 ä¸ªå½±å“æ¯”è¾ƒå¤§çš„å±‚
    summary = sorted(summary.data, key=lambda x: x[0], reverse=True)
    print("Sensitive Summary")
    for n, (ap, name) in enumerate(summary[:10]):
        print(f"Top{n}: Using fp16 {name}, ap = {ap:.5f}")
```

è¿™å°±æ˜¯æˆ‘ä»¬ä¹‹å‰ç”¨äºŽ YOLOv7-PTQ é‡åŒ–çš„å„ç§å‡½æ•°å’Œç±»çš„å®žçŽ°ï¼Œè¿™é‡Œä¸å†èµ˜è¿°

å¦å¤–æˆ‘ä»¬æ–°å»ºä¸€ä¸ª **ptq.py** æ–‡ä»¶ï¼Œç”¨äºŽå®žçŽ° YOLOv7 çš„ PTQ é‡åŒ–ï¼Œæˆ‘ä»¬é€šè¿‡ **argparse** æ¨¡å—æ¥ä¼ å…¥ PTQ é‡åŒ–æ‰€éœ€è¦çš„å‚æ•°ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
import argparse

if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    
    parser.add_argument('--weights', type=str, default='yolov7.pt', help='initial weights path')
    parser.add_argument('--cocodir', type=str,  default="dataset/coco2017", help="coco directory")
    parser.add_argument('--batch_size', type=int,  default=8, help="batch size for data loader")
    parser.add_argument('--device', default='0', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    
    parser.add_argument('--sensitive', type=bool, default=True, help="use sensitive analysis or not befor ptq")
    parser.add_argument("--sensitive_summary", type=str, default="sensitive-summary.json", help="summary save file")
    parser.add_argument("--ignore_layers", type=str, default="model\.105\.m\.(.*)", help="regx")
    
    parser.add_argument("--save_ptq", type=bool, default=False, help="file")
    parser.add_argument("--ptq", type=str, default="ptq_yolov7.onnx", help="file")
    
    parser.add_argument("--confidence", type=float, default=0.001, help="confidence threshold")
    parser.add_argument("--nmsthres", type=float, default=0.65, help="nms threshold")
    
    parser.add_argument("--eval_origin", action="store_true", help="do eval for origin model")
    parser.add_argument("--eval_ptq", action="store_true", help="do eval for ptq model")
    
    parser.add_argument("--ptq_summary", type=str, default="ptq_summary.json", help="summary save file")
    
    args = parser.parse_args()
```

ä¼ å…¥çš„å‚æ•°æœ‰æƒé‡ã€æ•°æ®é›†è·¯å¾„çš„æŒ‡å®šï¼Œæ•æ„Ÿå±‚åˆ†æžçš„æŒ‡å®šï¼Œç½®ä¿¡åº¦é˜ˆå€¼çš„æŒ‡å®šç­‰ç­‰

æˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒç”¨ **quantize.py** æ¨¡å—çš„å„ç§å‡½æ•°å’Œç±»æ¥å®žçŽ°çœŸæ­£çš„é‡åŒ–ï¼Œé‡åŒ–ä¸»è¦åˆ†ä¸ºæ•æ„Ÿå±‚åˆ†æžå’Œ PTQ é‡åŒ–ä¸¤ä¸ªéƒ¨åˆ†ï¼Œæˆ‘ä»¬å¯ä»¥åˆ†åˆ«ç¼–å†™ä¸¤ä¸ªå‡½æ•°æ¥è°ƒç”¨å®žçŽ°ï¼Œé¦–å…ˆæ˜¯æ•æ„Ÿå±‚åˆ†æžå‡½æ•°ï¼Œå…¶å®žçŽ°å¦‚ä¸‹ï¼š

```python
def run_SensitiveAnalysis(weight, cocodir, device='cpu'):

    # prepare model
    print("Prepare Model ....")
    model = quantize.prepare_model(weight, device)
    quantize.replace_to_quantization_model(model)

    # prepare dataset
    print("Prepare Dataset ....")
    train_dataloader = quantize.prepare_train_dataset(cocodir)
    val_dataloader = quantize.prepare_val_dataset(cocodir)

    # calibration model
    print("Begining Calibration ....")
    quantize.calibrate_model(model, train_dataloader, device)

    # sensitive analysis
    print("Begining Sensitive Analysis ....")
    quantize.sensitive_analysis(model, val_dataloader, args.sensitive_summary)
```

æˆ‘ä»¬åœ¨å‰é¢å°±è®²è¿‡æ•æ„Ÿå±‚åˆ†æžçš„æµç¨‹ï¼ŒåŒ…æ‹¬æ¨¡åž‹ã€æ•°æ®é›†çš„å‡†å¤‡ã€æ¨¡åž‹çš„æ ‡å®šï¼Œæ•æ„Ÿå±‚çš„åˆ†æžï¼Œéƒ½æ˜¯é€šè¿‡ **quantize.py** æ¨¡å—çš„å„ç§å‡½æ•°å’Œç±»æ¥å®žçŽ°çš„

æˆ‘ä»¬å†æ¥ç¼–å†™ä¸‹è¿è¡Œ PTQ é‡åŒ–çš„å‡½æ•°ï¼Œå…¶å®žçŽ°å¦‚ä¸‹ï¼š

```python
def run_PTQ(args, device='cpu'):

    # prepare model
    print("Prepare Model ....")
    model = quantize.prepare_model(args.weights, device)
    quantize.replace_to_quantization_model(model, args.ignore_layers)

    # prepare dataset
    print("Prepare Dataset ....")
    val_dataloader = quantize.prepare_val_dataset(args.cocodir, batch_size=args.batch_size)
    train_dataloader = quantize.prepare_train_dataset(args.cocodir, batch_size=args.batch_size)
    
    # calibration model
    print("Begining Calibration ....")
    quantize.calibrate_model(model, train_dataloader, device)
    
    summary = quantize.SummaryTool(args.ptq_summary)
    
    if args.eval_origin:
        print("Evaluate Origin...")
        with quantize.disable_quantization(model):
            ap = quantize.evaluate_coco(model, val_dataloader, conf_thres=args.conf_thres, iou_thres=args.iou_thres)
            summary.append(["Origin", ap])
    if args.eval_ptq:
        print("Evaluate PTQ...")
        ap = quantize.evaluate_coco(model, val_dataloader, conf_thres=args.conf_thres, iou_thres=args.iou_thres)
        summary.append(["PTQ", ap])

    if args.save_ptq:
        print("Export PTQ...")
        quantize.export_ptq(model, args.ptq, device)
```

å®žé™…çš„ PTQ é‡åŒ–è¿‡ç¨‹åŒ…æ‹¬æƒé‡ã€æ•°æ®é›†çš„å‡†å¤‡ï¼Œæ ‡å®šï¼ŒåŽç»­ PTQ æ¨¡åž‹æ€§èƒ½çš„éªŒè¯å’Œå¯¼å‡º

é‚£ä»¥ä¸Šå°±æ˜¯ **ptq.py** æ–‡ä»¶ä¸­çš„å…¨éƒ¨å†…å®¹ï¼Œå®Œæ•´çš„å†…å®¹å¦‚ä¸‹ï¼š

```python
import torch
import quantize
import argparse

def run_SensitiveAnalysis(weight, cocodir, device='cpu'):

    # prepare model
    print("Prepare Model ....")
    model = quantize.prepare_model(weight, device)
    quantize.replace_to_quantization_model(model)

    # prepare dataset
    print("Prepare Dataset ....")
    train_dataloader = quantize.prepare_train_dataset(cocodir)
    val_dataloader = quantize.prepare_val_dataset(cocodir)

    # calibration model
    print("Begining Calibration ....")
    quantize.calibrate_model(model, train_dataloader, device)

    # sensitive analysis
    print("Begining Sensitive Analysis ....")
    quantize.sensitive_analysis(model, val_dataloader, args.sensitive_summary)

def run_PTQ(args, device='cpu'):

    # prepare model
    print("Prepare Model ....")
    model = quantize.prepare_model(args.weights, device)
    quantize.replace_to_quantization_model(model, args.ignore_layers)

    # prepare dataset
    print("Prepare Dataset ....")
    val_dataloader = quantize.prepare_val_dataset(args.cocodir, batch_size=args.batch_size)
    train_dataloader = quantize.prepare_train_dataset(args.cocodir, batch_size=args.batch_size)
    
    # calibration model
    print("Begining Calibration ....")
    quantize.calibrate_model(model, train_dataloader, device)
    
    summary = quantize.SummaryTool(args.ptq_summary)
    
    if args.eval_origin:
        print("Evaluate Origin...")
        with quantize.disable_quantization(model):
            ap = quantize.evaluate_coco(model, val_dataloader, conf_thres=args.conf_thres, iou_thres=args.iou_thres)
            summary.append(["Origin", ap])
    if args.eval_ptq:
        print("Evaluate PTQ...")
        ap = quantize.evaluate_coco(model, val_dataloader, conf_thres=args.conf_thres, iou_thres=args.iou_thres)
        summary.append(["PTQ", ap])

    if args.save_ptq:
        print("Export PTQ...")
        quantize.export_ptq(model, args.ptq, device)

if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    
    parser.add_argument('--weights', type=str, default='yolov7.pt', help='initial weights path')
    parser.add_argument('--cocodir', type=str,  default="dataset/coco2017", help="coco directory")
    parser.add_argument('--batch_size', type=int,  default=8, help="batch size for data loader")
    parser.add_argument('--device', default='0', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    
    parser.add_argument('--sensitive', type=bool, default=True, help="use sensitive analysis or not befor ptq")
    parser.add_argument("--sensitive_summary", type=str, default="sensitive-summary.json", help="summary save file")
    parser.add_argument("--ignore_layers", type=str, default="model\.105\.m\.(.*)", help="regx")
    
    parser.add_argument("--save_ptq", type=bool, default=False, help="file")
    parser.add_argument("--ptq", type=str, default="ptq_yolov7.onnx", help="file")
    
    parser.add_argument("--confidence", type=float, default=0.001, help="confidence threshold")
    parser.add_argument("--nmsthres", type=float, default=0.65, help="nms threshold")
    
    parser.add_argument("--eval_origin", action="store_true", help="do eval for origin model")
    parser.add_argument("--eval_ptq", action="store_true", help="do eval for ptq model")
    
    parser.add_argument("--ptq_summary", type=str, default="ptq_summary.json", help="summary save file")
    
    args = parser.parse_args()

    is_cuda = (args.device != "cpu") and torch.cuda.is_available()
    device = torch.device("cuda:0" if is_cuda else 'cpu')

    # æ•æ„Ÿå±‚åˆ†æž
    if args.sensitive:
        print("Sensitive Analysis ...")
        run_SensitiveAnalysis(args.weights, args.cocodir, device)

    # PTQ
    # ignore_layers= ["model\.105\.m\.(.*)", model\.99\.m\.(.*)]
    # args.ignore_layer = ignore_layers
    
    print("Begining PTQ ....")
    run_PTQ(args, device)
    print("PTQ Quantization Has Finished ....")
```

é‚£å…¶å®žè¿™éƒ½æ˜¯æˆ‘ä»¬ä¹‹å‰è®²è¿‡çš„å†…å®¹ï¼Œåªæ˜¯è¿™è¾¹å†é‡æ–°æ•´ç†å¹¶å·¥ç¨‹åŒ–ä¸‹ï¼Œæ–¹ä¾¿æˆ‘ä»¬åŽç»­çš„ä½¿ç”¨ã€‚

OKï¼YOLOv7-PTQ é‡åŒ–çš„å†…å®¹åˆ°è¿™é‡Œå°±ç»“æŸäº†ï¼Œä¸‹èŠ‚å¼€å§‹æˆ‘ä»¬å°†è®²è§£ QAT é‡åŒ–ç›¸å…³çš„çŸ¥è¯†

# æ€»ç»“

> æœ¬æ¬¡è¯¾ç¨‹ä»‹ç»äº† YOLOv7-PTQ é‡åŒ–æµç¨‹ä¸­çš„æ ‡å®šã€æ•æ„Ÿå±‚åˆ†æžï¼Œæ ‡å®šä¸»è¦æ˜¯åˆ©ç”¨æ ‡å®šæ•°æ®æ¥æ”¶é›†æ¨¡åž‹ä¸­å„å±‚çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œå¹¶è®¡ç®—é‡åŒ–å‚æ•°ä¿å­˜åœ¨ QDQ èŠ‚ç‚¹å½“ä¸­ï¼Œæ­¤å¤–æˆ‘ä»¬è¿˜å¯¹æ¯”äº† Max å’Œ ç›´æ–¹å›¾æ ¡å‡†ä¸¤ç§æ–¹æ³•ï¼Œå‘çŽ° Max æ–¹æ³•çš„æ€§èƒ½è¦å·®ä¸€äº›ï¼Œè€Œæ•æ„Ÿå±‚åˆ†æžçš„æµç¨‹åˆ™æ˜¯å¾ªçŽ¯éåŽ†æ‰€æœ‰å±‚ï¼Œå…³é—­æŸå±‚é‡åŒ–æµ‹è¯• mAP æ€§èƒ½ï¼Œæœ€ç»ˆç»Ÿè®¡å¯¹æ¨¡åž‹æ€§èƒ½æœ€å¤§çš„å‡ ä¸ªå±‚ä½œä¸ºæ•æ„Ÿå±‚ï¼Œå…³é—­å…¶é‡åŒ–ä»¥ FP16 çš„æ–¹å¼è¿è¡Œï¼Œé‚£æˆ‘ä»¬åœ¨å®žé™…è¿›è¡Œ PTQ é‡åŒ–ä¹‹å‰å°±è¦åšæ•æ„Ÿå±‚çš„åˆ†æžï¼Œç»Ÿè®¡å‡ºå“ªäº›å±‚æ˜¯æ•æ„Ÿå±‚åŽå†è¿›è¡Œé‡åŒ–ï¼Œè¿™æ ·é‡åŒ–å‡ºçš„æ¨¡åž‹çš„æ€§èƒ½ä¹Ÿä¼šæ›´é«˜ã€‚æœ€åŽ PTQ é‡åŒ–æ¨¡åž‹çš„å¯¼å‡ºè®°å¾—æ‰“å¼€ fake ç®—å­ï¼Œä¹Ÿå°±æ˜¯å°† use\_fb\_fake\_quant è®¾ç½®ä¸º Trueã€‚
> 
> è‡³æ­¤ï¼ŒYOLOv7-PTQ é‡åŒ–çš„å…¨éƒ¨å†…å®¹åˆ°è¿™é‡Œå°±è®²å®Œäº†ï¼Œä¸‹èŠ‚å¼€å§‹æˆ‘ä»¬å°†è¿›å…¥ YOLOv7-QAT é‡åŒ–

æœ¬æ–‡è½¬è‡ª <https://blog.csdn.net/qq_40672115/article/details/134233620>ï¼Œå¦‚æœ‰ä¾µæƒï¼Œè¯·è”ç³»åˆ é™¤ã€‚